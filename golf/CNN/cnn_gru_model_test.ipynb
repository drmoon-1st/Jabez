{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e28f75f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Evaluation Started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:18<00:00,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Evaluation Accuracy: 1.0000\n",
      "âœ… Evaluation Finished\n",
      "ğŸ“ Evaluation results saved to: evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "ê³¨í”„ ìŠ¤ìœ™ ì‹œí€€ìŠ¤ ë°ì´í„°ì…‹ í‰ê°€ ë° ì˜ˆì¸¡/ì •ë‹µ CSV íŒŒì¼ ì €ì¥\n",
    "(í•™ìŠµ ì œì™¸ 20% ì¤‘ 5% ì‚¬ìš©)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from torchvision import transforms\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "class GolfSwingSequenceDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, sequence_length=5):\n",
    "        self.transform = transform\n",
    "        self.sequence_length = sequence_length\n",
    "        self.samples = []\n",
    "\n",
    "        select_task = \"test\"  # tfëŠ” train, testëŠ” test ë°ì´í„°ì…‹ì„ ì˜ë¯¸\n",
    "        true_json_dir = os.path.join(root_dir, select_task, \"true\", \"json\")\n",
    "        false_json_dir = os.path.join(root_dir, select_task, \"false\", \"json\")\n",
    "        true_jpg_dir = os.path.join(root_dir, select_task, \"true\", \"jpg\")\n",
    "        false_jpg_dir = os.path.join(root_dir, select_task, \"false\", \"jpg\")\n",
    "\n",
    "        def collect_sequences(json_dir):\n",
    "            swings = defaultdict(list)\n",
    "            for fname in os.listdir(json_dir):\n",
    "                if not fname.endswith(\".json\"):\n",
    "                    continue\n",
    "                swing_id = fname.split(\"_\")[0]  # ì˜ˆ: 001_0001 -> 001\n",
    "                swings[swing_id].append(fname)\n",
    "            for key in swings:\n",
    "                swings[key] = sorted(swings[key])\n",
    "            return swings\n",
    "\n",
    "        true_swings = collect_sequences(true_json_dir)\n",
    "        false_swings = collect_sequences(false_json_dir)\n",
    "\n",
    "        # âœ… ìµœëŒ€ ìƒ˜í”Œ ìˆ˜: true/false ì¤‘ ì‘ì€ ê°’ ê¸°ì¤€\n",
    "        max_samples = min(len(true_swings), len(false_swings), 20000)\n",
    "\n",
    "        # âœ… ëœë¤í•˜ê²Œ swing_id ì¶”ì¶œ\n",
    "        true_keys = random.sample(list(true_swings.keys()), max_samples)\n",
    "        false_keys = random.sample(list(false_swings.keys()), max_samples)\n",
    "\n",
    "        # âœ… true/false ê°ê° ìˆ˜ì§‘\n",
    "        balanced_samples = []\n",
    "\n",
    "        def collect_samples(swings, json_dir, jpg_dir, label):\n",
    "            sequences = []\n",
    "            for key in swings:\n",
    "                file_names = swings[key]\n",
    "                for i in range(0, len(file_names) - sequence_length + 1):\n",
    "                    sequence = file_names[i:i + sequence_length]\n",
    "                    sequences.append({\n",
    "                        \"label\": label,\n",
    "                        \"files\": [(\n",
    "                            os.path.join(json_dir, f),\n",
    "                            os.path.join(jpg_dir, f.replace(\".json\", \".jpg\"))\n",
    "                        ) for f in sequence]\n",
    "                    })\n",
    "            return sequences\n",
    "\n",
    "        true_samples = collect_samples({k: true_swings[k] for k in true_keys}, true_json_dir, true_jpg_dir, label=1)\n",
    "        false_samples = collect_samples({k: false_swings[k] for k in false_keys}, false_json_dir, false_jpg_dir, label=0)\n",
    "\n",
    "        # âœ… ê°™ì€ ê°œìˆ˜ë¡œ ì„ê¸°\n",
    "        min_len = min(len(true_samples), len(false_samples))\n",
    "        self.samples = true_samples[:min_len] + false_samples[:min_len]\n",
    "\n",
    "        # âœ… ë¬´ì‘ìœ„ë¡œ ì…”í”Œ\n",
    "        random.shuffle(self.samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        images = []\n",
    "        for json_path, img_path in sample[\"files\"]:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            images.append(image)\n",
    "        sequence = torch.stack(images)\n",
    "        label = torch.tensor(sample[\"label\"], dtype=torch.float32)\n",
    "        return sequence, label\n",
    "\n",
    "# âœ… ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì •ì˜\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# âœ… root ë””ë ‰í† ë¦¬ëŠ” tfë³´ë‹¤ ìƒìœ„ ë””ë ‰í† ë¦¬ê¹Œì§€ í¬í•¨\n",
    "root_path = \"D:/golfDataset/ìŠ¤í¬ì¸  ì‚¬ëŒ ë™ì‘ ì˜ìƒ(ê³¨í”„)/Training/Public/male\"\n",
    "\n",
    "# âœ… ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "dataset = GolfSwingSequenceDataset(root_dir=root_path, transform=transform, sequence_length=5)\n",
    "\n",
    "# âœ… ì „ì²´ ë°ì´í„°ì…‹ì„ 80% í•™ìŠµ, 20% í‰ê°€ë¡œ ë¶„í• \n",
    "train_size = int(0 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# âœ… í‰ê°€ ë°ì´í„°ì…‹ì—ì„œ 5%ë§Œ ëœë¤ ì¶”ì¶œ\n",
    "eval_size = int(len(val_dataset))\n",
    "indices = random.sample(range(len(val_dataset)), eval_size)\n",
    "eval_dataset = Subset(val_dataset, indices)\n",
    "\n",
    "# âœ… DataLoader ì •ì˜ (í‰ê°€ ë°ì´í„°ì…‹)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "class CNN_GRU_Classifier(nn.Module):\n",
    "    def __init__(self, hidden_size=128, num_layers=1):\n",
    "        super().__init__()\n",
    "        # CNN encoder\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.flattened_size = 32 * 56 * 56  # assuming input is 224x224\n",
    "        self.gru = nn.GRU(input_size=self.flattened_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):  # x shape: (B, T, C, H, W)\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(B, T, -1)  # reshape for GRU\n",
    "        out, _ = self.gru(x)\n",
    "        out = out[:, -1, :]  # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í… ì¶œë ¥\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# âœ… ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ (ê²½ë¡œëŠ” ì‹¤ì œ ì €ì¥ ê²½ë¡œì™€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.)\n",
    "save_path = r\"D:\\golfDataset\\CNN\\cnn_gru_model.pth\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN_GRU_Classifier().to(device)\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
    "\n",
    "# âœ… í‰ê°€ ì‹œì‘\n",
    "print(\"ğŸš€ Evaluation Started\")\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "all_file_paths = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(eval_loader, desc=\"Evaluating\"):\n",
    "        x_batch, y_batch = batch\n",
    "        x_batch = x_batch.to(device)  # ë°°ì¹˜ ë°ì´í„°ë¥¼ ëª¨ë¸ê³¼ ê°™ì€ ì¥ì¹˜ë¡œ ì´ë™\n",
    "        y_batch = y_batch.to(device)\n",
    "        outputs = model(x_batch)\n",
    "        probabilities = torch.sigmoid(outputs).cpu().numpy()\n",
    "        predictions = probabilities.round().astype(int)\n",
    "        labels = y_batch.cpu().numpy().astype(int)\n",
    "\n",
    "        all_predictions.extend(predictions)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "        # íŒŒì¼ ê²½ë¡œ ìˆ˜ì§‘\n",
    "        for i_batch in range(x_batch.size(0)): # ê° ë°°ì¹˜ ë‚´ì˜ ì‹œí€€ìŠ¤\n",
    "            file_paths_in_sequence = []\n",
    "            # í˜„ì¬ ë°°ì¹˜ ë‚´ì—ì„œì˜ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ Subsetì˜ ì›ë³¸ ì¸ë±ìŠ¤ ì ‘ê·¼\n",
    "            batch_offset = i_batch\n",
    "            global_index_in_subset = batch_offset\n",
    "            if global_index_in_subset < len(eval_dataset.indices):\n",
    "                original_index = eval_dataset.indices[global_index_in_subset]\n",
    "                sample = dataset.samples[original_index]\n",
    "                file_paths_in_sequence.append([os.path.basename(f[1]) for f in sample[\"files\"]])\n",
    "            all_file_paths.append(file_paths_in_sequence)\n",
    "\n",
    "\n",
    "# âœ… ì •í™•ë„ ê³„ì‚°\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "print(f\"ğŸ¯ Evaluation Accuracy: {accuracy:.4f}\")\n",
    "print(\"âœ… Evaluation Finished\")\n",
    "\n",
    "# âœ… ì˜ˆì¸¡ê³¼ ì •ë‹µì„ DataFrameìœ¼ë¡œ ë§Œë“¤ê¸°\n",
    "eval_df = pd.DataFrame({\n",
    "    'file_paths': all_file_paths,\n",
    "    'true_label': all_labels,\n",
    "    'predicted_label': all_predictions\n",
    "})\n",
    "\n",
    "# âœ… CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "csv_save_path = \"evaluation_results.csv\"\n",
    "eval_df.to_csv(csv_save_path, index=False)\n",
    "print(f\"ğŸ“ Evaluation results saved to: {csv_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "golfCNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
