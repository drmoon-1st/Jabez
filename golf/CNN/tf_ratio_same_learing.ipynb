{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf비율 맞춰서 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GolfSwingSequenceDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, sequence_length=5):\n",
    "        self.transform = transform\n",
    "        self.sequence_length = sequence_length\n",
    "        self.samples = []\n",
    "\n",
    "        true_json_dir = os.path.join(root_dir, \"tf\", \"true\", \"json\")\n",
    "        false_json_dir = os.path.join(root_dir, \"tf\", \"false\", \"json\")\n",
    "        true_jpg_dir = os.path.join(root_dir, \"tf\", \"true\", \"jpg\")\n",
    "        false_jpg_dir = os.path.join(root_dir, \"tf\", \"false\", \"jpg\")\n",
    "\n",
    "        # ✅ 스윙 ID 단위로 그룹화\n",
    "        def collect_sequences(json_dir):\n",
    "            swings = defaultdict(list)\n",
    "            for fname in os.listdir(json_dir):\n",
    "                if not fname.endswith(\".json\"):\n",
    "                    continue\n",
    "                swing_id = fname.split(\"_\")[0]  # 예: 001_0001 -> 001\n",
    "                swings[swing_id].append(fname)\n",
    "            # 정렬\n",
    "            for key in swings:\n",
    "                swings[key] = sorted(swings[key])\n",
    "            return swings\n",
    "\n",
    "        true_swings = collect_sequences(true_json_dir)\n",
    "        false_swings = collect_sequences(false_json_dir)\n",
    "\n",
    "        # ✅ 최대 샘플 개수 조절\n",
    "        max_samples = min(len(true_swings), len(false_swings), 20000)\n",
    "\n",
    "        true_keys = list(true_swings.keys())[:max_samples]\n",
    "        false_keys = list(false_swings.keys())[:max_samples]\n",
    "\n",
    "        # ✅ true 데이터 수집\n",
    "        for key in true_keys:\n",
    "            file_names = true_swings[key]\n",
    "            for i in range(0, len(file_names) - sequence_length + 1):\n",
    "                sequence = file_names[i:i+sequence_length]\n",
    "                self.samples.append({\n",
    "                    \"label\": 1,\n",
    "                    \"files\": [(\n",
    "                        os.path.join(true_json_dir, f),\n",
    "                        os.path.join(true_jpg_dir, f.replace(\".json\", \".jpg\"))\n",
    "                    ) for f in sequence]\n",
    "                })\n",
    "\n",
    "        # ✅ false 데이터 수집\n",
    "        for key in false_keys:\n",
    "            file_names = false_swings[key]\n",
    "            for i in range(0, len(file_names) - sequence_length + 1):\n",
    "                sequence = file_names[i:i+sequence_length]\n",
    "                self.samples.append({\n",
    "                    \"label\": 0,\n",
    "                    \"files\": [(\n",
    "                        os.path.join(false_json_dir, f),\n",
    "                        os.path.join(false_jpg_dir, f.replace(\".json\", \".jpg\"))\n",
    "                    ) for f in sequence]\n",
    "                })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        images = []\n",
    "        for json_path, img_path in sample[\"files\"]:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            images.append(image)\n",
    "        sequence = torch.stack(images)\n",
    "        label = torch.tensor(sample[\"label\"], dtype=torch.float32)\n",
    "        return sequence, label\n",
    "    \n",
    "    # ✅ 이미지 전처리 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# ✅ root 디렉토리는 tf보다 상위 디렉토리까지 포함\n",
    "root_path = \"D:/golfDataset/스포츠 사람 동작 영상(골프)/Training/Public/male\"\n",
    "\n",
    "# ✅ 수정된 파라미터명: sequence_length\n",
    "dataset = GolfSwingSequenceDataset(root_dir=root_path, transform=transform, sequence_length=5)\n",
    "\n",
    "# ✅ 데이터셋 분할 (train 80%, val 20%)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# ✅ DataLoader 정의\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN_GRU_Classifier(nn.Module):\n",
    "    def __init__(self, hidden_size=128, num_layers=1):\n",
    "        super().__init__()\n",
    "        # CNN encoder\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.flattened_size = 32 * 56 * 56  # assuming input is 224x224\n",
    "        self.gru = nn.GRU(input_size=self.flattened_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):  # x shape: (B, T, C, H, W)\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(B, T, -1)  # reshape for GRU\n",
    "        out, _ = self.gru(x)\n",
    "        out = out[:, -1, :]  # 마지막 타임스텝 출력\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌀 Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 30675/30675 [5:29:58<00:00,  1.55it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟢 Train Loss: 0.0291\n",
      "🌀 Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 30675/30675 [5:31:12<00:00,  1.54it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟢 Train Loss: 0.0005\n",
      "🌀 Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 30675/30675 [5:30:01<00:00,  1.55it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟢 Train Loss: 0.0009\n",
      "🌀 Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 30675/30675 [5:32:28<00:00,  1.54it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟢 Train Loss: 0.0006\n",
      "🌀 Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 30675/30675 [5:05:13<00:00,  1.67it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟢 Train Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN_GRU_Classifier().to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(5):\n",
    "    print(f\"🌀 Epoch {epoch+1}/5\")\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for x_batch, y_batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device).unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    print(f\"🟢 Train Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모델이 저장되었습니다: D:\\golfDataset\\CNN\\cnn_gru_model.pth\n"
     ]
    }
   ],
   "source": [
    "# ✅ 저장 경로 지정\n",
    "save_path = r\"D:\\golfDataset\\CNN\\cnn_gru_model.pth\"\n",
    "\n",
    "# ✅ 모델 저장\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"✅ 모델이 저장되었습니다: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 일부 디렉토리 학습"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "golfCNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
