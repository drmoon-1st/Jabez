# src/compute_metrics.py
# -*- coding: utf-8 -*-
import argparse
from pathlib import Path
import pandas as pd
import numpy as np
import cv2
import glob
import re

try:
    import yaml
except ImportError:
    yaml = None

from .utils_io import natural_key, ensure_dir

# =========================================================
# ìœ í‹¸ & ì»¬ëŸ¼ ìœ ì—° ë§¤ì¹­ (Nose_x / Nose__x / Nose_____x ëª¨ë‘ í—ˆìš©)
# =========================================================
_SUFFIXES = ("x", "y", "z", "c")
_COL_RE = re.compile(r"^(?P<name>.+?)_+(?P<suf>[xyzc])$")  # ë°‘ì¤„ 1ê°œ ì´ìƒ í—ˆìš©

def split_base_suffix(col: str):
    m = _COL_RE.match(col)
    if not m:
        return None, None
    return m.group("name"), m.group("suf")

def find_col(df_or_row, base: str, suf: str) -> str | None:
    suf = suf.lower()
    if suf not in _SUFFIXES:
        return None
    cols = df_or_row.columns if isinstance(df_or_row, pd.DataFrame) else df_or_row.index
    for col in cols:
        b, s = split_base_suffix(col)
        if b == base and s == suf:
            return col
    return None

def require_cols_flex(df: pd.DataFrame, bases: list[str], sufs: str | tuple[str, ...], msg=""):
    if isinstance(sufs, str):
        sufs = tuple(sufs)
    missing = []
    for base in bases:
        for suf in sufs:
            col = find_col(df, base, suf)
            if col is None:
                # í‘œì‹œìš©ì€ ê´€ë¡€ì ìœ¼ë¡œ __ ì‚¬ìš©
                missing.append(f"{base}__{suf}")
    if missing:
        raise KeyError(f"í•„ìˆ˜ ì»¬ëŸ¼ ì—†ìŒ: {missing}. {msg}")

def get_xyz_cols(df: pd.DataFrame, name: str):
    cols = [find_col(df, name, s) for s in ("x", "y", "z")]
    return df[cols].to_numpy(float)

def get_xyz_row(row: pd.Series, name: str):
    out = []
    for s in ("x", "y", "z"):
        col = find_col(row.to_frame().T, name, s)
        out.append(row.get(col, np.nan))
    return np.array(out, dtype=float)

def deep_merge(a: dict, b: dict | None):
    if not b:
        return a
    out = {**a}
    for k, v in b.items():
        if isinstance(v, dict) and k in out and isinstance(out[k], dict):
            out[k] = deep_merge(out[k], v)
        else:
            out[k] = v
    return out

def find_3d_landmark(df: pd.DataFrame, candidates):
    """candidates ì¤‘ *_x,*_y,*_z ì„¸ ì»¬ëŸ¼ì´ ëª¨ë‘ ìˆëŠ” ì²« ë²ˆì§¸ ì´ë¦„ ë°˜í™˜"""
    for name in candidates:
        if all(find_col(df, name, s) for s in ("x", "y", "z")):
            return name
    return None

# =========================================================
# ë©”íŠ¸ë¦­ ê³„ì‚° (ëª¨ë‘ 3D ê¸°ì¤€)
# =========================================================
def speed_3d(points_xyz: np.ndarray, fps: float | int | None):
    """
    points_xyz: (N,3) mm ë‹¨ìœ„
    ë°˜í™˜: v(N,), unit = mm/frame ë˜ëŠ” mm/s (fps ì£¼ì–´ì§€ë©´)
    ë‚´ë¶€ NaNì€ ffill, ì²« í”„ë ˆì„ NaNì€ 0ìœ¼ë¡œ.
    """
    N = len(points_xyz)
    v = np.full(N, np.nan, dtype=float)
    for i in range(1, N):
        a, b = points_xyz[i-1], points_xyz[i]
        if np.any(np.isnan(a)) or np.any(np.isnan(b)):
            continue
        v[i] = float(np.linalg.norm(b - a))  # mm/frame
    if fps and fps > 0:
        v = v * float(fps)
        unit = "mm/s"
    else:
        unit = "mm/frame"
    v = pd.Series(v).fillna(method="ffill").fillna(0).to_numpy()
    return v, unit

def compute_head_speed_3d(df: pd.DataFrame, landmark: str, fps=None):
    require_cols_flex(df, [landmark], "xyz", "Head 3D ì†ë„ìš©")
    pts = get_xyz_cols(df, landmark)
    return speed_3d(pts, fps)

def compute_xfactor_fn(sL: str, sR: str, hL: str, hR: str):
    """
    X-Factor (deg) ê³„ì‚° í•¨ìˆ˜ ë°˜í™˜.
    ì •ì˜: x-z í‰ë©´ì—ì„œ (R-L) ì–´ê¹¨ë²¡í„°ì™€ (R-L) ê³¨ë°˜ë²¡í„°ì˜ yaw ê°ë„ ì°¨ì˜ ì ˆëŒ€ê°’(0~180).
    """
    def _xf(row: pd.Series):
        ls = get_xyz_row(row, sL); rs = get_xyz_row(row, sR)
        lh = get_xyz_row(row, hL); rh = get_xyz_row(row, hR)
        if np.any(np.isnan(ls)) or np.any(np.isnan(rs)) or np.any(np.isnan(lh)) or np.any(np.isnan(rh)):
            return np.nan
        shoulder_vec = rs - ls
        hip_vec      = rh - lh
        sh_yaw = np.degrees(np.arctan2(shoulder_vec[0], shoulder_vec[2]))  # atan2(x, z)
        hp_yaw = np.degrees(np.arctan2(hip_vec[0],      hip_vec[2]))
        d = abs(sh_yaw - hp_yaw)
        d = (d + 180) % 360
        return 360 - d if d > 180 else d  # 0~180
    return _xf

def compute_com_points_3d(df: pd.DataFrame):
    """
    í”„ë ˆì„ë³„ 3D COM(mm) ê³„ì‚°.
    - *_x,*_y,*_zê°€ ëª¨ë‘ ìˆëŠ” ê´€ì ˆë§Œ ì‚¬ìš©
    - *_c(ì‹ ë¢°ë„)ê°€ ìˆìœ¼ë©´ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš© (ì—†ìœ¼ë©´ 1.0)
    """
    # 3Dê°€ ìˆëŠ” ê´€ì ˆ ì´ë¦„ ìˆ˜ì§‘
    names = []
    for c in df.columns:
        base, suf = split_base_suffix(c)
        if base and suf == "x":
            if find_col(df, base, "y") and find_col(df, base, "z"):
                names.append(base)
    names = sorted(set(names))

    N = len(df)
    com = np.full((N, 3), np.nan, dtype=float)
    for i in range(N):
        row = df.iloc[i]
        acc = []
        weights = []
        for n in names:
            cx, cy, cz = find_col(df, n, "x"), find_col(df, n, "y"), find_col(df, n, "z")
            if cx is None or cy is None or cz is None:
                continue
            x, y, z = row.get(cx, np.nan), row.get(cy, np.nan), row.get(cz, np.nan)
            if np.any(np.isnan([x, y, z])):
                continue
            cc = find_col(df, n, "c")
            w = float(row.get(cc, 1.0)) if cc else 1.0
            acc.append([float(x), float(y), float(z)])
            weights.append(w)
        if acc:
            acc = np.array(acc, dtype=float)
            w = np.array(weights, dtype=float)
            w = np.clip(w, 1e-6, None)
            com[i] = (acc * w[:, None]).sum(axis=0) / w.sum()
    return com  # (N,3)

def compute_grip_points_3d(df: pd.DataFrame, wrist_r: str, wrist_l: str):
    """
    í”„ë ˆì„ë³„ 3D Grip(mm) ì¢Œí‘œ = ë‘ ì†ëª© ì¤‘ì 
    """
    require_cols_flex(df, [wrist_r, wrist_l], "xyz", "Grip/Swing 3Dìš©")
    R = get_xyz_cols(df, wrist_r)
    L = get_xyz_cols(df, wrist_l)
    return (R + L) / 2.0

# =========================================================
# ì„¤ì •
# =========================================================
def load_cfg(p: Path):
    if p.suffix.lower() in (".yml", ".yaml"):
        if yaml is None:
            raise RuntimeError("pip install pyyaml")
        return yaml.safe_load(p.read_text(encoding="utf-8"))
    raise ValueError("Use YAML for analyze config.")

# === (ì¶”ê°€) 2D ê´€ì ˆ í—¬í¼: ì´ì¤‘ ë°‘ì¤„ ëŒ€ì‘ ===
def get_xyc_row(row: pd.Series, name: str):
    cx = find_col(row.to_frame().T, name, "x")
    cy = find_col(row.to_frame().T, name, "y")
    cc = find_col(row.to_frame().T, name, "c")
    x = row.get(cx, np.nan) if cx else np.nan
    y = row.get(cy, np.nan) if cy else np.nan
    c = row.get(cc, np.nan) if cc else np.nan
    return x, y, c

def list_kp_names_2d(df: pd.DataFrame):
    """*_xì™€ *_yê°€ ëª¨ë‘ ìˆëŠ” ê´€ì ˆ ë² ì´ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸(ì´ì¤‘ ë°‘ì¤„ í¬í•¨)"""
    bases_x = {split_base_suffix(c)[0] for c in df.columns if split_base_suffix(c)[1] == "x"}
    bases_y = {split_base_suffix(c)[0] for c in df.columns if split_base_suffix(c)[1] == "y"}
    return sorted(bases_x & bases_y)

def build_edges(kp_names: list[str]):
    """OpenPose Body25 ìŠ¤íƒ€ì¼(ì¼ë¶€). ì¡´ì¬í•˜ëŠ” í‚¤ë§Œ ì—°ê²°"""
    E, have = [], set(kp_names)
    def add(a,b):
        if a in have and b in have: E.append((a,b))
    # ìƒì²´
    add("Neck","RShoulder"); add("RShoulder","RElbow"); add("RElbow","RWrist")
    add("Neck","LShoulder"); add("LShoulder","LElbow"); add("LElbow","LWrist")
    add("Neck","MidHip")
    # í•˜ì²´
    add("MidHip","RHip"); add("RHip","RKnee"); add("RKnee","RAnkle")
    add("MidHip","LHip"); add("LHip","LKnee"); add("LKnee","LAnkle")
    # ë°œ
    add("RAnkle","RHeel"); add("RHeel","RBigToe"); add("RBigToe","RSmallToe")
    add("LAnkle","LHeel"); add("LHeel","LBigToe"); add("LBigToe","LSmallToe")
    # ë¨¸ë¦¬
    add("Neck","Nose")
    return E

def detect_2d_normalized(df: pd.DataFrame, sample_names: list[str] | None = None, sample_rows: int = 200) -> bool:
    """
    2D ì¢Œí‘œê°€ ì •ê·œí™”(0~1)ì¸ì§€ ëŒ€ëµ ê°ì§€.
    - x,yì˜ ìµœëŒ€ê°’ì´ 2 ë¯¸ë§Œì´ë©´ ì •ê·œí™”ë¡œ íŒë‹¨.
    """
    if sample_names is None:
        # 2D í‚¤í¬ì¸íŠ¸ ìë™ ìˆ˜ì§‘
        names = list_kp_names_2d(df)
    else:
        names = sample_names
    n = min(len(df), sample_rows)
    xmax = ymax = -np.inf
    for i in range(n):
        row = df.iloc[i]
        for name in names[:50]:  # ë„ˆë¬´ ë§ì´ ë³¼ í•„ìš” ì—†ìŒ
            x, y, _ = get_xyc_row(row, name)
            if not np.isnan(x): xmax = max(xmax, float(x))
            if not np.isnan(y): ymax = max(ymax, float(y))
    # ì¢Œí‘œê°€ ì „ë°˜ì ìœ¼ë¡œ 0~1 ê·¼ì²˜ì´ë©´ ì •ê·œí™”ë¡œ ê°„ì£¼
    return (xmax <= 2.0 and ymax <= 2.0)


# =========================================================
# ì˜¤ë²„ë ˆì´ (PNG í”„ë ˆì„ + HUD 4ì¤„)
# =========================================================
def overlay_video(img_dir: Path, df: pd.DataFrame, df_metrics: pd.DataFrame, out_mp4: Path, fps: int, codec: str, draw_opts: dict):
    images = sorted(glob.glob(str(img_dir / "*.png")), key=natural_key)
    if not images:
        raise RuntimeError(f"No PNG in {img_dir}")

    first = cv2.imread(images[0]); h, w = first.shape[:2]
    ensure_dir(out_mp4.parent)
    writer = cv2.VideoWriter(str(out_mp4), cv2.VideoWriter_fourcc(*codec), fps, (w, h))
    if not writer.isOpened():
        raise RuntimeError(f"VideoWriter open failed: {out_mp4} (codec={codec})")

    draw_defaults = {
        "skeleton": {"line_bgr": [0, 255, 255], "line_thick": 1, "dot_bgr": [0, 0, 255], "dot_radius": 2},
        "hud": {"font_scale": 0.45, "thickness": 1, "color_bgr": [0, 255, 0]},
    }
    draw = deep_merge(draw_defaults, draw_opts or {})
    line_col = tuple(draw["skeleton"]["line_bgr"])
    line_th  = int(draw["skeleton"]["line_thick"])
    dot_col  = tuple(draw["skeleton"]["dot_bgr"])
    dot_r    = int(draw["skeleton"]["dot_radius"])
    fsc      = float(draw["hud"]["font_scale"])
    fth      = int(draw["hud"]["thickness"])
    fclr     = tuple(draw["hud"]["color_bgr"])

    # 2D ê´€ì ˆ ì´ë¦„ê³¼ ì—°ê²°ì„ 
    kp_names = list_kp_names_2d(df)
    edges = build_edges(kp_names)

    # ğŸ” 2D ì •ê·œí™” ì—¬ë¶€ ìë™ íŒë‹¨
    is_norm = detect_2d_normalized(df, sample_names=kp_names)

    def scale_xy(x, y):
        if np.isnan(x) or np.isnan(y):
            return np.nan, np.nan
        if is_norm:
            return x * (w - 1), y * (h - 1)  # 0~1 â†’ í”½ì…€
        return x, y  # ì´ë¯¸ í”½ì…€

    for i, p in enumerate(images):
        if i >= len(df): break
        frame = cv2.imread(p)
        row = df.iloc[i]

        # --- ìŠ¤ì¼ˆë ˆí†¤ ì„  ---
        for a, b in edges:
            ax, ay, _ = get_xyc_row(row, a)
            bx, by, _ = get_xyc_row(row, b)
            ax, ay = scale_xy(ax, ay)
            bx, by = scale_xy(bx, by)
            if not (np.isnan(ax) or np.isnan(ay) or np.isnan(bx) or np.isnan(by)):
                cv2.line(frame, (int(ax), int(ay)), (int(bx), int(by)), line_col, line_th)

        # --- ê´€ì ˆ ì  ---
        for name in kp_names:
            x, y, _ = get_xyc_row(row, name)
            x, y = scale_xy(x, y)
            if not (np.isnan(x) or np.isnan(y)):
                cv2.circle(frame, (int(x), int(y)), dot_r, dot_col, -1)

        # --- HUD 4ì¤„ ---
        vals = {
            "xfactor": df_metrics.loc[i, "xfactor_deg"] if i < len(df_metrics) else np.nan,
            "com":     df_metrics.loc[i, "com_speed"]   if i < len(df_metrics) else np.nan,
            "swing":   df_metrics.loc[i, "swing_speed"] if i < len(df_metrics) else np.nan,
            "head":    df_metrics.loc[i, "head_speed"]  if i < len(df_metrics) else np.nan,
        }
        units = {
            "xfactor": "deg",
            "com":     df_metrics.attrs.get("com_unit",   "mm/s"),
            "swing":   df_metrics.attrs.get("swing_unit", "mm/s"),
            "head":    df_metrics.attrs.get("head_unit",  "mm/s"),
        }
        hud_texts = [
            f"X-Factor: {vals['xfactor']:.1f} {units['xfactor']}" if not np.isnan(vals['xfactor']) else "X-Factor: -",
            f"COM Speed: {vals['com']:.2f} {units['com']}"        if not np.isnan(vals['com']) else "COM Speed: -",
            f"Swing Speed: {vals['swing']:.2f} {units['swing']}"  if not np.isnan(vals['swing']) else "Swing Speed: -",
            f"Head Speed: {vals['head']:.2f} {units['head']}"     if not np.isnan(vals['head']) else "Head Speed: -",
        ]
        y0 = 22
        for k, text in enumerate(hud_texts):
            cv2.putText(frame, text, (16, y0 + k*18),
                        cv2.FONT_HERSHEY_SIMPLEX, fsc, fclr, fth, cv2.LINE_AA)

        writer.write(frame)

    writer.release()

# =========================================================
# main
# =========================================================
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("-c", "--config", default=str(Path(__file__).parent.parent / "config" / "analyze.yaml"))
    args = ap.parse_args()
    cfg = load_cfg(Path(args.config))

    csv_path  = Path(cfg["csv_path"])
    img_dir   = Path(cfg["img_dir"])
    out_csv   = Path(cfg["metrics_csv"])
    make_ov   = bool(cfg.get("make_overlay", True))
    out_mp4   = Path(cfg["overlay_mp4"])
    fps       = int(cfg.get("fps", 30))
    codec     = str(cfg.get("codec", "mp4v"))
    draw_opts = cfg.get("draw", {})

    # 1) CSV ë¡œë“œ
    df = pd.read_csv(csv_path)

    # 2) ëœë“œë§ˆí¬ ì´ë¦„: ì„¤ì • â†’ ìë™íƒìƒ‰(ë°±ì—…)
    lm_cfg = cfg.get("landmarks", {}) or {}
    head_name   = lm_cfg.get("head")
    if not head_name:
        head_name = find_3d_landmark(df, ["Head","HeadTop","MidHead","Nose","HeadCenter"])
        if not head_name:
            avail = sorted({c[:-2] for c in df.columns if c.endswith("_z") or c.endswith("__z")})
            raise KeyError(
                "3D ë¨¸ë¦¬ ëœë“œë§ˆí¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. config/analyze.yaml -> landmarks.head ë¥¼ ì„¤ì •í•˜ì„¸ìš”. "
                f"ì˜ˆ: {avail[:20]}"
            )

    shoulder_l  = lm_cfg.get("shoulder_left",  "LShoulder")
    shoulder_r  = lm_cfg.get("shoulder_right", "RShoulder")
    hip_l       = lm_cfg.get("hip_left",       "LHip")
    hip_r       = lm_cfg.get("hip_right",      "RHip")
    wrist_l     = lm_cfg.get("wrist_left",     "LWrist")
    wrist_r     = lm_cfg.get("wrist_right",    "RWrist")

    # 3) 3D í•„ìˆ˜ ì»¬ëŸ¼ ìœ ì—°ê²€ì‚¬
    require_cols_flex(df, [head_name], "xyz", "Head speed 3Dìš©")
    require_cols_flex(df, [shoulder_l, shoulder_r, hip_l, hip_r], "xyz", "X-Factor 3Dìš©")
    require_cols_flex(df, [wrist_r, wrist_l], "xyz", "Grip/Swing 3Dìš©")

    # 4) í¬ì¸íŠ¸ ì‹œí€€ìŠ¤
    com_pts   = compute_com_points_3d(df)                       # (N,3)
    grip_pts  = compute_grip_points_3d(df, wrist_r, wrist_l)    # (N,3)
    head_pts  = get_xyz_cols(df, head_name)                     # (N,3)

    # 5) ì†ë„(mm/s ë˜ëŠ” mm/frame)
    com_v,  com_unit   = speed_3d(com_pts,  fps)
    swing_v, swing_unit = speed_3d(grip_pts, fps)  # Swing = Grip speed
    head_v, head_unit  = speed_3d(head_pts, fps)

    # 6) X-Factor (deg)
    xfactor_fn = compute_xfactor_fn(shoulder_l, shoulder_r, hip_l, hip_r)
    xfactor = df.apply(xfactor_fn, axis=1)

    # 7) ë©”íŠ¸ë¦­ í”„ë ˆì„
    metrics = pd.DataFrame(index=df.index)
    metrics["frame"]        = range(len(df))
    metrics["xfactor_deg"]  = xfactor
    metrics["com_speed"]    = com_v
    metrics["swing_speed"]  = swing_v
    metrics["head_speed"]   = head_v

    # ë‹¨ìœ„ ë©”íƒ€ (ì˜¤ë²„ë ˆì´ì—ì„œ ì‚¬ìš©)
    metrics.attrs["com_unit"]   = com_unit
    metrics.attrs["swing_unit"] = swing_unit
    metrics.attrs["head_unit"]  = head_unit

    ensure_dir(out_csv.parent)
    metrics.to_csv(out_csv, index=False)
    print(f"[OK] metrics saved: {out_csv}")

    # 8) (ì„ íƒ) ì˜¤ë²„ë ˆì´: PNG í”„ë ˆì„ + HUD 4ì¤„
    if make_ov:
        overlay_video(img_dir, df, metrics, out_mp4, fps, codec, draw_opts)
        print(f"[OK] overlay saved: {out_mp4}")

if __name__ == "__main__":
    main()
