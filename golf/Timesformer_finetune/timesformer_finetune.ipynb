{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c5a0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 436 samples found in D:\\golfDataset\\스포츠 사람 동작 영상(골프)\\Training\\Public\\male\\train\n",
      "🔁 Loading checkpoint from checkpoint.pth\n",
      "✅ Resuming from epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████████████████| 393/393 [10:46<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train acc: 90.941%\n",
      "💾 Checkpoint saved to checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████████████████| 393/393 [10:45<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train acc: 89.567%\n",
      "💾 Checkpoint saved to checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████████████████| 393/393 [10:45<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train acc: 92.265%\n",
      "💾 Checkpoint saved to checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████████████████| 393/393 [10:46<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train acc: 92.163%\n",
      "💾 Checkpoint saved to checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████████████████| 393/393 [10:48<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train acc: 92.774%\n",
      "💾 Checkpoint saved to checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Test]: 100%|█████████████████████████| 43/43 [01:09<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Test Video Accuracy : 74.419%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"D:\\timesformer\")  # timesformer 경로를 python 모듈 경로에 추가\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "from decord import VideoReader\n",
    "from tqdm import tqdm\n",
    "from timesformer.models.vit import TimeSformer\n",
    "\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "def preprocess_tensor(img_tensor):  # img_tensor: (3, H, W)\n",
    "    img = F.resize(img_tensor, 256, interpolation=InterpolationMode.BICUBIC)\n",
    "    img = F.center_crop(img, IMG_SIZE)\n",
    "    img = F.normalize(img, [0.45]*3, [0.225]*3)\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "# ----------------- 하이퍼파라미터 ----------------------------\n",
    "ROOT          = Path(r\"D:\\golfDataset\\스포츠 사람 동작 영상(골프)\\Training\\Public\\male\\train\")\n",
    "PRETRAIN_PYTH = Path(r\"D:\\timesformer\\pretrained\\TimeSformer_divST_96x4_224_K600.pyth\")\n",
    "NUM_FRAMES    = 32\n",
    "CLIPS_PER_VID = 5\n",
    "IMG_SIZE      = 224\n",
    "BATCH         = 4\n",
    "LR            = 1e-3\n",
    "EPOCHS        = 10\n",
    "SEED          = 42\n",
    "TEST_RATIO    = 0.1     # 테스트셋 비율\n",
    "\n",
    "# ----------------- 재현성 ----------------------------\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "device = \"cuda\"  # 무조건 gpu 사용 안되면 오류 내버리기\n",
    "\n",
    "# ----------------- 전처리 ----------------------------\n",
    "base_tf = T.Compose([\n",
    "    T.Resize(256, interpolation=InterpolationMode.BICUBIC),\n",
    "    T.CenterCrop(IMG_SIZE),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.45]*3, [0.225]*3),\n",
    "])\n",
    "\n",
    "def uniform_sample(L, N):\n",
    "    if L >= N:\n",
    "        return np.linspace(0, L-1, N).astype(int)\n",
    "    return np.pad(np.arange(L), (0, N-L), mode='edge')\n",
    "\n",
    "def load_clip(path: Path):  # 비디오를 timesformer 입력에 맞게 전처리\n",
    "    vr = VideoReader(str(path))\n",
    "    L = len(vr)\n",
    "    seg_edges = np.linspace(0, L, CLIPS_PER_VID + 1, dtype=int)\n",
    "    clips = []\n",
    "    for s0, s1 in zip(seg_edges[:-1], seg_edges[1:]):\n",
    "        idx = uniform_sample(s1 - s0, NUM_FRAMES) + s0\n",
    "        arr = vr.get_batch(idx).asnumpy().astype(np.uint8)              # (T, H, W, 3)\n",
    "        clip = torch.from_numpy(arr).permute(0, 3, 1, 2).float() / 255.0  # (T, 3, H, W)\n",
    "        clip = torch.stack([preprocess_tensor(f) for f in clip])         # (T, 3, H, W)\n",
    "        clips.append(clip.permute(1, 0, 2, 3))                            # (3, T, H, W)\n",
    "    return clips  # list of (3, T, H, W)\n",
    "\n",
    "\n",
    "# ----------------- 데이터셋 ----------------------------\n",
    "class SwingDataset(Dataset):\n",
    "    def __init__(self, root: Path):\n",
    "        self.samples = []\n",
    "        for lbl, sub in enumerate((\"balanced_true\", \"false\")):\n",
    "            for p in (root/sub/\"crop_video\").glob(\"*.mp4\"):\n",
    "                self.samples.append((p, lbl))\n",
    "        print(f\"\\u2705 {len(self.samples)} samples found in {root}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        path, lbl = self.samples[i]\n",
    "        clips = load_clip(path)\n",
    "        return torch.stack(clips), torch.tensor(lbl)\n",
    "\n",
    "# ----------------- 데이터 로더 ----------------------------\n",
    "ds_full = SwingDataset(ROOT)\n",
    "n_test = int(len(ds_full)*TEST_RATIO)\n",
    "n_train = len(ds_full) - n_test\n",
    "train_ds, test_ds = random_split(ds_full, [n_train, n_test])\n",
    "train_ld = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=0, pin_memory=True)\n",
    "test_ld  = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)\n",
    "# num_workers는 CPU 코어수, 4개로 하니 오류생겨서 일단 0개로 설정\n",
    "\n",
    "# ----------------- Checkpoint 설정 ----------------------------\n",
    "checkpoint_path = Path(\"checkpoint.pth\")  # 🔧 체크포인트 저장 경로\n",
    "\n",
    "start_epoch = 0  # 🔧 기본값\n",
    "\n",
    "# ----------------- 모델 ----------------------------\n",
    "model = TimeSformer(img_size=IMG_SIZE, num_frames=NUM_FRAMES,\n",
    "                    num_classes=2, attention_type='divided_space_time',\n",
    "                    pretrained_model=str(PRETRAIN_PYTH)).to(device)\n",
    "\n",
    "# 분류 레이어만 학습하도록 설정\n",
    "def get_trainable_params(model):\n",
    "    trainable = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if any(x in name for x in ('head', 'cls_head')):\n",
    "            param.requires_grad = True\n",
    "            trainable.append(param)\n",
    "        else:\n",
    "            param.requires_grad = False\n",
    "    return trainable\n",
    "\n",
    "opt = optim.AdamW(get_trainable_params(model), lr=LR, weight_decay=0.02)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "# 🔧 Checkpoint가 존재하면 불러오기\n",
    "if checkpoint_path.exists():\n",
    "    print(f\"🔁 Loading checkpoint from {checkpoint_path}\")\n",
    "    ckpt = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    opt.load_state_dict(ckpt[\"opt\"])\n",
    "    start_epoch = ckpt[\"epoch\"] + 1\n",
    "    print(f\"✅ Resuming from epoch {start_epoch}\")\n",
    "\n",
    "# ----------------- 학습 ----------------------------\n",
    "for ep in range(start_epoch, EPOCHS):\n",
    "    model.train()\n",
    "    tot = correct = 0\n",
    "    for clips, lab in tqdm(train_ld, desc=f\"Epoch {ep}\", ncols=70):\n",
    "        vids = clips.squeeze(0).to(device)  # (5,3,T,H,W)\n",
    "        labs = lab.repeat(CLIPS_PER_VID).to(device)\n",
    "        outs = model(vids)  # (5,2)\n",
    "        loss = crit(outs, labs)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        tot += labs.size(0); correct += (outs.argmax(1) == labs).sum().item()\n",
    "    print(f\"  train acc: {correct/tot:.3%}\")\n",
    "\n",
    "    # 🔧 체크포인트 저장\n",
    "    torch.save({\n",
    "        \"epoch\": ep,\n",
    "        \"model\": model.state_dict(),\n",
    "        \"opt\": opt.state_dict(),\n",
    "    }, checkpoint_path)\n",
    "    print(f\"💾 Checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "# ----------------- 평가 ----------------------------\n",
    "model.eval(); tot = correct = 0\n",
    "with torch.no_grad():\n",
    "    for clips, lab in tqdm(test_ld, desc=\"[Test]\", ncols=70):\n",
    "        vids = clips.squeeze(0).to(device)\n",
    "        probs = model(vids).softmax(1).mean(0, keepdim=True)  # 평균 ensemble\n",
    "        pred = probs.argmax(1)\n",
    "        tot += 1; correct += (pred.cpu() == lab).item()\n",
    "print(f\"\\n✅ Test Video Accuracy : {correct/tot:.3%}\")\n",
    "\n",
    "# 🔧 최종 학습된 모델 저장\n",
    "final_model_path = Path(\"timesformer_finetuned.pth\")\n",
    "torch.save({\n",
    "    \"epoch\": EPOCHS - 1,\n",
    "    \"model\": model.state_dict(),\n",
    "    \"opt\": opt.state_dict(),\n",
    "}, final_model_path)\n",
    "print(f\"\\n✅ Final model saved to {final_model_path}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timesformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
