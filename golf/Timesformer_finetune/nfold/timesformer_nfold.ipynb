{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58e4f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 2404 samples found in D:\\golfDataset\\dataset\\train (balanced=True)\n",
      "✅ 295 samples found in D:\\golfDataset\\dataset\\test (balanced=False)\n",
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 1 [Train]:   5%|▍       | 24/481 [01:20<27:02,  3.55s/it]"
     ]
    }
   ],
   "source": [
    "# Timesformer n-fold cross-validation (train/val 완전 분리)\n",
    "\n",
    "import sys\n",
    "sys.path.append(r\"D:\\\\timesformer\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import functional as F, InterpolationMode\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "from decord import VideoReader\n",
    "from tqdm import tqdm\n",
    "from timesformer.models.vit import TimeSformer\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# ----------------- 하이퍼파라미터 및 경로 ----------------------------\n",
    "TRAIN_ROOT = Path(r\"D:\\golfDataset\\dataset\\train\")\n",
    "TEST_ROOT  = Path(r\"D:\\golfDataset\\dataset\\test\")\n",
    "PRETRAIN_PTH = Path(r\"D:\\timesformer\\pretrained\\TimeSformer_divST_8x32_224_K600.pyth\")\n",
    "NUM_FRAMES = 8\n",
    "IMG_SIZE = 224\n",
    "# ----------------- 조정 가능 파라미터 ----------------------------\n",
    "CLIPS_PER_VIDEO = 1\n",
    "BATCH_SIZE = 4\n",
    "LR = 5e-5\n",
    "WEIGHT_DECAY = 0.1\n",
    "DROPOUT = 0.5\n",
    "EPOCHS = 5\n",
    "SEED = 42\n",
    "\n",
    "N_FOLDS = 5\n",
    "EPOCHS_DIR = Path(\"epochs\")\n",
    "EPOCHS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ----------------- 재현성 ----------------------------\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ----------------- 전처리 ----------------------------\n",
    "def preprocess_tensor(img_tensor):\n",
    "    img = F.resize(img_tensor, 256, interpolation=InterpolationMode.BICUBIC)\n",
    "    img = F.center_crop(img, IMG_SIZE)\n",
    "    img = F.normalize(img, [0.45]*3, [0.225]*3)\n",
    "    return img\n",
    "\n",
    "def uniform_sample(L, N):\n",
    "    if L >= N:\n",
    "        return np.linspace(0, L-1, N).astype(int)\n",
    "    return np.pad(np.arange(L), (0, N-L), mode='edge')\n",
    "\n",
    "def load_clip(path: Path):\n",
    "    vr = VideoReader(str(path))\n",
    "    L = len(vr)\n",
    "    seg_edges = np.linspace(0, L, CLIPS_PER_VIDEO + 1, dtype=int)\n",
    "    clips = []\n",
    "    for s0, s1 in zip(seg_edges[:-1], seg_edges[1:]):\n",
    "        idx = uniform_sample(s1 - s0, NUM_FRAMES) + s0\n",
    "        arr = vr.get_batch(idx).asnumpy().astype(np.uint8)\n",
    "        clip = torch.from_numpy(arr).permute(0, 3, 1, 2).float() / 255.0\n",
    "        clip = torch.stack([preprocess_tensor(f) for f in clip])\n",
    "        clips.append(clip.permute(1, 0, 2, 3))\n",
    "    return clips\n",
    "\n",
    "# ----------------- 모델 ----------------------------\n",
    "class TimeSformerWithDropout(nn.Module):\n",
    "    def __init__(self, base_model, dropout_p=DROPOUT):\n",
    "        super().__init__()\n",
    "        self.base = base_model\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.head = base_model.model.head\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.base.model.forward_features(x)\n",
    "        out = self.dropout(feats)\n",
    "        return self.head(out)\n",
    "\n",
    "# ----------------- 데이터셋 ----------------------------\n",
    "class GolfSwingDataset(Dataset):\n",
    "    def __init__(self, root: Path, balance):\n",
    "        self.samples = []\n",
    "        true_samples = []\n",
    "        false_samples = []\n",
    "        for label, sub in [(1, \"balanced_true\"), (0, \"false\")]:\n",
    "            for p in (root/sub/\"crop_video\").glob(\"*.mp4\"):\n",
    "                if label == 1:\n",
    "                    true_samples.append((p, 1))\n",
    "                else:\n",
    "                    false_samples.append((p, 0))\n",
    "        if balance:\n",
    "            n_true = len(true_samples)\n",
    "            n_false = len(false_samples)\n",
    "            if n_false > 0 and n_true > n_false:\n",
    "                factor = n_true // n_false\n",
    "                remainder = n_true % n_false\n",
    "                false_samples = false_samples * factor + false_samples[:remainder]\n",
    "        self.samples = true_samples + false_samples\n",
    "        random.shuffle(self.samples)\n",
    "        print(f\"✅ {len(self.samples)} samples found in {root} (balanced={balance})\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        clips = load_clip(path)\n",
    "        return torch.stack(clips), torch.tensor(label)\n",
    "\n",
    "# ----------------- train/test 완전 분리 n-fold ----------------------------\n",
    "train_dataset = GolfSwingDataset(TRAIN_ROOT, balance=True)\n",
    "test_dataset  = GolfSwingDataset(TEST_ROOT, balance=False)\n",
    "\n",
    "indices = np.arange(len(train_dataset))\n",
    "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(indices)):\n",
    "    print(f\"\\n=== Fold {fold+1}/{N_FOLDS} ===\")\n",
    "    train_subset = Subset(train_dataset, train_idx)\n",
    "    val_subset   = Subset(train_dataset, val_idx)\n",
    "    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_subset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    base_model = TimeSformer(img_size=IMG_SIZE, num_frames=NUM_FRAMES,\n",
    "                             num_classes=2, attention_type='divided_space_time',\n",
    "                             pretrained_model=str(PRETRAIN_PTH)).to(DEVICE)\n",
    "    model = TimeSformerWithDropout(base_model, dropout_p=DROPOUT).to(DEVICE)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.tensor([1.5, 1.0]).to(DEVICE))\n",
    "\n",
    "    best_val_acc = 0\n",
    "    best_model_state = None\n",
    "    for epoch in range(EPOCHS):\n",
    "        # --- Training ---\n",
    "        model.train()\n",
    "        total = correct = total_loss = 0\n",
    "        for clips, label in tqdm(train_loader, desc=f\"Fold {fold+1} Epoch {epoch+1} [Train]\", ncols=70, leave=False):\n",
    "            B = clips.shape[0]\n",
    "            clips = clips.view(-1, *clips.shape[2:]).to(DEVICE)\n",
    "            labs = label.repeat(CLIPS_PER_VIDEO).to(DEVICE)\n",
    "            outs = model(clips)\n",
    "            loss = criterion(outs, labs)\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            total += labs.size(0)\n",
    "            correct += (outs.argmax(1) == labs).sum().item()\n",
    "        train_acc = correct / total\n",
    "        avg_loss = total_loss / total\n",
    "        print(f\"  train acc: {train_acc:.3%}, loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        val_total = val_correct = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for clips, label in tqdm(val_loader, desc=f\"Fold {fold+1} Epoch {epoch+1} [Val]\", ncols=70, leave=False):\n",
    "                B = clips.shape[0]\n",
    "                vids = clips.view(-1, *clips.shape[2:]).to(DEVICE)\n",
    "                labs = label.repeat(CLIPS_PER_VIDEO).to(DEVICE)\n",
    "                probs = model(vids).softmax(1)\n",
    "                pred = probs.argmax(1)\n",
    "                val_total += pred.size(0)\n",
    "                val_correct += (pred.cpu() == labs.cpu()).sum().item()\n",
    "                all_preds.extend(pred.cpu().numpy())\n",
    "                all_labels.extend(labs.cpu().numpy())\n",
    "        val_acc = val_correct / val_total if val_total > 0 else 0\n",
    "        print(f\"  val  acc: {val_acc:.3%}\")\n",
    "\n",
    "        # Confusion matrix 출력\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"False\", \"True\"])\n",
    "        disp.plot(cmap=\"Blues\")\n",
    "        plt.title(f\"Confusion Matrix (Fold {fold+1} Epoch {epoch+1})\")\n",
    "        plt.show()\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "    # --- Fold별 best 모델로 test set 평가 ---\n",
    "    model.load_state_dict(best_model_state)\n",
    "    model.eval()\n",
    "    test_total = test_correct = 0\n",
    "    all_test_preds = []\n",
    "    all_test_labels = []\n",
    "    with torch.no_grad():\n",
    "        for clips, label in tqdm(test_loader, desc=f\"Fold {fold+1} [Test]\", ncols=70, leave=False):\n",
    "            B = clips.shape[0]\n",
    "            vids = clips.view(-1, *clips.shape[2:]).to(DEVICE)\n",
    "            labs = label.repeat(CLIPS_PER_VIDEO).to(DEVICE)\n",
    "            probs = model(vids).softmax(1)\n",
    "            pred = probs.argmax(1)\n",
    "            test_total += pred.size(0)\n",
    "            test_correct += (pred.cpu() == labs.cpu()).sum().item()\n",
    "            all_test_preds.extend(pred.cpu().numpy())\n",
    "            all_test_labels.extend(labs.cpu().numpy())\n",
    "    test_acc = test_correct / test_total if test_total > 0 else 0\n",
    "    print(f\"✔ Fold {fold+1} test acc: {test_acc:.3%}\")\n",
    "\n",
    "    # Confusion matrix (test)\n",
    "    cm = confusion_matrix(all_test_labels, all_test_preds)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"False\", \"True\"])\n",
    "    disp.plot(cmap=\"Blues\")\n",
    "    plt.title(f\"Test Confusion Matrix (Fold {fold+1})\")\n",
    "    plt.show()\n",
    "\n",
    "    fold_results.append(test_acc)\n",
    "\n",
    "print(f\"\\n=== KFold 평균 test acc: {np.mean(fold_results):.3%} ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timesformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
