"""
# src/xfactor.py
# -*- coding: utf-8 -*-
X-Factor ì „ìš© ë¶„ì„ê¸°

ìš”ì²­ëœ ë‹¨ê³„ë³„ ê·œì¹™ì„ ê·¸ëŒ€ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤:
 1) 3D ì¢Œí‘œ ì½ê¸° (L/R Shoulder, L/R Hip)
 2) ì–´ê¹¨ì„ /ê³¨ë°˜ì„  ë²¡í„° ìƒì„± (ì˜¤ë¥¸ìª½-ì™¼ìª½)
 3) í”„ë ˆì„ë³„ ë²¡í„° ë°©í–¥ ì¼ê´€í™” (dot<0ì´ë©´ ë¶€í˜¸ ë°˜ì „)
 4) 3ê°œ í‰ë©´(X-Z, X-Y, Y-Z)ì—ì„œ íšŒì „ê° ê³„ì‚°(atan2)
 5) ê°ë„ ì–¸ë©(np.unwrap)
 6) X-Factor = shoulder_angle - pelvis_angle
 7) ìŠ¤ë¬´ë”©(Median5 + Moving5)
 8) í´ë¦¬í•‘([-90, 90])
 9) ì„íŒ©íŠ¸ íƒì§€ (RWrist_X3Dê°€ stance_midë¥¼ +ë°©í–¥ìœ¼ë¡œ êµì°¨í•˜ëŠ” ì²« í”„ë ˆì„)
10) ì„íŒ©íŠ¸ ì „ ìµœëŒ€ê°’/í”„ë ˆì„, ì„íŒ©íŠ¸ ì‹œ ê°’
11) ìµœì  í‰ë©´ ìë™ ì„ íƒ: 5<median<80 í›„ë³´ ì¤‘ IQR(q90-q10) ìµœì†Œ
12) ê²°ê³¼ ì €ì¥(JSON) ë° íƒ€ì„ì‹œë¦¬ì¦ˆ CSV
"""
import argparse
from pathlib import Path
import pandas as pd
import numpy as np
import cv2
import glob
from typing import Optional, Dict, List
import json

try:
    import yaml
except ImportError:
    yaml = None

# ê³µí†µ ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸
import sys
sys.path.append(str(Path(__file__).parent))
from utils_io import natural_key, ensure_dir

# =========================================================
# ê³µí†µ: ì»¬ëŸ¼ ë§¤í•‘/ì¢Œí‘œ ì ‘ê·¼ ìœ í‹¸
# =========================================================
def load_cfg(p: Path):
    if p.suffix.lower() in (".yml", ".yaml"):
        if yaml is None:
            raise RuntimeError("pip install pyyaml")
        return yaml.safe_load(p.read_text(encoding="utf-8"))
    raise ValueError("Use YAML for analyze config.")

def parse_joint_axis_map_from_columns(columns, prefer_2d: bool = False) -> Dict[str, Dict[str, str]]:
    cols = list(columns)
    mapping: Dict[str, Dict[str, str]] = {}
    if prefer_2d:
        axis_patterns = [
            ('_x', '_y', '_z'),
            ('__x', '__y', '__z'),
            ('_X', '_Y', '_Z'),
            ('_X3D', '_Y3D', '_Z3D'),
        ]
    else:
        axis_patterns = [
            ('_X3D', '_Y3D', '_Z3D'),
            ('__x', '__y', '__z'),
            ('_X', '_Y', '_Z'),
            ('_x', '_y', '_z'),
        ]
    col_set = set(cols)
    for col in cols:
        if col.lower() in ('frame', 'time', 'timestamp'):
            continue
        for x_pat, y_pat, z_pat in axis_patterns:
            if col.endswith(x_pat):
                joint = col[:-len(x_pat)]
                x_col = joint + x_pat
                y_col = joint + y_pat
                z_col = joint + z_pat
                if x_col in col_set and y_col in col_set:
                    mapping.setdefault(joint, {})['x'] = x_col
                    mapping.setdefault(joint, {})['y'] = y_col
                    if z_col in col_set:
                        mapping[joint]['z'] = z_col
                    break
    return mapping

def get_xyz_row(row: pd.Series, name: str):
    cols_map = parse_joint_axis_map_from_columns(row.index, prefer_2d=False)
    x = y = z = np.nan
    if name in cols_map:
        m = cols_map[name]
        x = row.get(m.get('x', ''), np.nan)
        y = row.get(m.get('y', ''), np.nan)
        z = row.get(m.get('z', ''), np.nan)
    return np.array([x, y, z], dtype=float)

def get_xyz_cols(df: pd.DataFrame, name: str) -> np.ndarray:
    cmap = parse_joint_axis_map_from_columns(df.columns, prefer_2d=False)
    m = cmap.get(name, {})
    cx, cy, cz = m.get('x'), m.get('y'), m.get('z')
    if cx in df.columns and cy in df.columns and cz in df.columns:
        return df[[cx, cy, cz]].astype(float).to_numpy()
    # fallback to strict X3D headers
    cols = [f"{name}_X3D", f"{name}_Y3D", f"{name}_Z3D"]
    if all(c in df.columns for c in cols):
        return df[cols].astype(float).to_numpy()
    return np.full((len(df), 3), np.nan, dtype=float)

def get_xyc_row(row: pd.Series, name: str):
    cols_map = parse_joint_axis_map_from_columns(row.index, prefer_2d=True)
    x = y = np.nan
    if name in cols_map:
        m = cols_map[name]
        x = row.get(m.get('x', ''), np.nan)
        y = row.get(m.get('y', ''), np.nan)
    c = 1.0
    return x, y, c

# =========================================================
# 2D ì¢Œí‘œ ìŠ¤ë¬´ë”© ìœ í‹¸ (com_speedì™€ ë™ì¼ ì˜µì…˜)
# =========================================================
def _ema(series: pd.Series, alpha: float) -> pd.Series:
    a = alpha if alpha is not None else 0.2
    a = 0.2 if a <= 0 or a >= 1 else a
    return series.ewm(alpha=a, adjust=False).mean()

def _moving(series: pd.Series, window: int) -> pd.Series:
    w = max(int(window or 5), 1)
    return series.rolling(window=w, min_periods=1).mean()

def _median(series: pd.Series, window: int) -> pd.Series:
    w = max(int(window or 5), 1)
    return series.rolling(window=w, min_periods=1).median()

def _gaussian_kernel(window: int, sigma: Optional[float] = None) -> np.ndarray:
    w = int(window or 5)
    if w % 2 == 0:
        w += 1
    if w < 3:
        w = 3
    s = float(sigma) if sigma and sigma > 0 else max(w / 3.0, 1.0)
    r = w // 2
    x = np.arange(-r, r + 1)
    k = np.exp(-0.5 * (x / s) ** 2)
    k /= np.sum(k)
    return k

def _gaussian(series: pd.Series, window: int, sigma: Optional[float]) -> pd.Series:
    vals = series.to_numpy(dtype=float, copy=True)
    mask = np.isnan(vals)
    tmp = pd.Series(vals).fillna(method='ffill').fillna(method='bfill').to_numpy()
    k = _gaussian_kernel(window, sigma)
    sm = np.convolve(tmp, k, mode='same')
    sm[mask] = np.nan
    return pd.Series(sm, index=series.index)

def _hampel(series: pd.Series, window: int, n_sigma: float = 3.0) -> pd.Series:
    w = max(int(window or 7), 1)
    if w % 2 == 0:
        w += 1
    x = series.astype(float)
    med = x.rolling(window=w, center=True, min_periods=1).median()
    diff = (x - med).abs()
    mad = diff.rolling(window=w, center=True, min_periods=1).median()
    thresh = 1.4826 * mad * float(n_sigma if n_sigma and n_sigma > 0 else 3.0)
    out = x.copy()
    out[diff > thresh] = med[diff > thresh]
    return out

def _one_euro(series: pd.Series, fps: float, min_cutoff: float = 1.0, beta: float = 0.007, d_cutoff: float = 1.0) -> pd.Series:
    vals = series.to_numpy(dtype=float, copy=True)
    mask = np.isnan(vals)
    tmp = pd.Series(vals).fillna(method='ffill').fillna(method='bfill').to_numpy()
    dt = 1.0 / float(fps) if fps and fps > 0 else 1.0
    def alpha(cutoff):
        tau = 1.0 / (2.0 * np.pi * float(cutoff)) if cutoff and cutoff > 0 else 1.0
        return 1.0 / (1.0 + tau / dt)
    x_hat = np.zeros_like(tmp)
    dx_hat = 0.0
    a_d = alpha(d_cutoff)
    x_hat[0] = tmp[0]
    prev_x = tmp[0]
    for i in range(1, len(tmp)):
        x = tmp[i]
        dx = (x - prev_x) / dt
        dx_hat = a_d * dx + (1 - a_d) * dx_hat
        cutoff = float(min_cutoff) + float(beta) * abs(dx_hat)
        a = alpha(cutoff)
        x_hat[i] = a * x + (1 - a) * x_hat[i - 1]
        prev_x = x
    x_hat[mask] = np.nan
    return pd.Series(x_hat, index=series.index)

def smooth_df_2d(
    df: pd.DataFrame,
    prefer_2d: bool = True,
    method: str = 'ema',
    window: int = 5,
    alpha: float = 0.2,
    fps: Optional[float] = None,
    gaussian_sigma: Optional[float] = None,
    hampel_sigma: Optional[float] = 3.0,
    oneeuro_min_cutoff: float = 1.0,
    oneeuro_beta: float = 0.007,
    oneeuro_d_cutoff: float = 1.0,
) -> pd.DataFrame:
    cols_map = parse_joint_axis_map_from_columns(df.columns, prefer_2d=prefer_2d)
    out = df.copy()
    m = (method or 'ema').lower()
    for j, axes in cols_map.items():
        cx, cy = axes.get('x'), axes.get('y')
        if not cx or not cy or cx not in out.columns or cy not in out.columns:
            continue
        sx = out[cx].astype(float)
        sy = out[cy].astype(float)
        if m == 'moving':
            out[cx] = _moving(sx, window); out[cy] = _moving(sy, window)
        elif m == 'median':
            out[cx] = _median(sx, window); out[cy] = _median(sy, window)
        elif m == 'gaussian':
            out[cx] = _gaussian(sx, window, gaussian_sigma); out[cy] = _gaussian(sy, window, gaussian_sigma)
        elif m == 'hampel_ema':
            hx = _hampel(sx, window, hampel_sigma); hy = _hampel(sy, window, hampel_sigma)
            out[cx] = _ema(hx, alpha); out[cy] = _ema(hy, alpha)
        elif m == 'oneeuro':
            out[cx] = _one_euro(sx, fps=fps, min_cutoff=oneeuro_min_cutoff, beta=oneeuro_beta, d_cutoff=oneeuro_d_cutoff)
            out[cy] = _one_euro(sy, fps=fps, min_cutoff=oneeuro_min_cutoff, beta=oneeuro_beta, d_cutoff=oneeuro_d_cutoff)
        else:
            out[cx] = _ema(sx, alpha); out[cy] = _ema(sy, alpha)
    print(f"âœ¨ 2D ìŠ¤ë¬´ë”© ì ìš©(xfactor): method={m}, window={window}, alpha={alpha}")
    return out

# =========================================================
"""
ë‹¨ê³„ë³„ ì•Œê³ ë¦¬ì¦˜ ë³´ì¡° í•¨ìˆ˜ë“¤ (3~11)
"""
def ensure_direction_continuity(V: np.ndarray) -> np.ndarray:
    out = V.copy()
    for i in range(1, len(out)):
        a, b = out[i-1], out[i]
        if not (np.any(np.isnan(a)) or np.any(np.isnan(b))):
            if float(np.dot(b, a)) < 0:
                out[i] = -b
    return out

def angles_deg_for_plane(V: np.ndarray, axis_a: int, axis_b: int) -> np.ndarray:
    va, vb = V[:, axis_a], V[:, axis_b]
    ang_unwrapped = np.unwrap(np.arctan2(vb, va))
    return np.degrees(ang_unwrapped)

def smooth_median_then_moving(x: np.ndarray, w: int = 5) -> np.ndarray:
    s = pd.Series(x)
    med = s.rolling(w, center=True, min_periods=1).median()
    sm = med.rolling(w, center=True, min_periods=1).mean()
    return sm.to_numpy()

def detect_impact_by_crossing(df: pd.DataFrame) -> int:
    RW = get_xyz_cols(df, 'RWrist'); rW = RW[:, 0]
    RA = get_xyz_cols(df, 'RAnkle'); LA = get_xyz_cols(df, 'LAnkle')
    stance_mid = (RA[:, 0] + LA[:, 0]) / 2.0
    vel_x = np.diff(rW, prepend=rW[0])
    for i in range(len(rW)):
        if np.isnan(rW[i]) or np.isnan(stance_mid[i]):
            continue
        if (rW[i] >= stance_mid[i]) and (vel_x[i] > 0):
            return int(i)
    with np.errstate(invalid='ignore'):
        return int(np.nanargmax(rW)) if np.any(~np.isnan(rW)) else len(rW) - 1

def compute_xfactor(df: pd.DataFrame) -> Dict[str, any]:
    # 1) ì¢Œí‘œ ì½ê¸°
    Ls = get_xyz_cols(df, 'LShoulder')
    Rs = get_xyz_cols(df, 'RShoulder')
    Lh = get_xyz_cols(df, 'LHip')
    Rh = get_xyz_cols(df, 'RHip')

    # 2) ë²¡í„° ìƒì„± (ì˜¤ë¥¸ìª½-ì™¼ìª½)
    shoulder_vec = Rs - Ls
    pelvis_vec   = Rh - Lh

    # 3) ë°©í–¥ ì¼ê´€í™”
    shoulder_vec = ensure_direction_continuity(shoulder_vec)
    pelvis_vec   = ensure_direction_continuity(pelvis_vec)

    # 4~6) í‰ë©´ë³„ ê°ë„/ì–¸ë© â†’ X-Factor
    planes = [("X-Z", 0, 2), ("X-Y", 0, 1), ("Y-Z", 1, 2)]
    xf_by_plane: Dict[str, np.ndarray] = {}
    for name, ax_a, ax_b in planes:
        shoulder_angle = angles_deg_for_plane(shoulder_vec, ax_a, ax_b)
        pelvis_angle   = angles_deg_for_plane(pelvis_vec, ax_a, ax_b)
        xf_raw = shoulder_angle - pelvis_angle
        # 7) ìŠ¤ë¬´ë”©
        xf_smooth = smooth_median_then_moving(xf_raw, w=5)
        # 8) í´ë¦¬í•‘
        xf_smooth = np.clip(xf_smooth, -90.0, 90.0)
        xf_by_plane[name] = xf_smooth

    # 9) ì„íŒ©íŠ¸ í”„ë ˆì„ íƒì§€
    impact_idx = detect_impact_by_crossing(df)

    # 10) ì„íŒ©íŠ¸ ì „ ìµœëŒ€/í”„ë ˆì„, ì„íŒ©íŠ¸ ì‹œ ê°’ (í‰ë©´ë³„ í†µê³„)
    stats: Dict[str, Dict[str, float]] = {}
    for name, xf in xf_by_plane.items():
        upto = max(min(impact_idx, len(xf) - 1), 0)
        pre = np.abs(xf[:upto+1])
        if pre.size == 0 or np.all(np.isnan(pre)):
            xf_max = np.nan; xf_max_frame = 0
        else:
            xf_max = float(np.nanmax(pre))
            xf_max_frame = int(np.nanargmax(pre))
        xf_at_impact = float(xf[impact_idx]) if 0 <= impact_idx < len(xf) else np.nan
        stats[name] = {
            'xfactor_max_deg': xf_max,
            'xfactor_max_frame': xf_max_frame,
            'xfactor_at_impact_deg': xf_at_impact,
        }

    # 11) ìµœì  í‰ë©´ ìë™ ì„ íƒ
    best_plane = None
    best_spread = None
    for name, xf in xf_by_plane.items():
        upto = max(min(impact_idx, len(xf) - 1), 0)
        pre_vals = np.abs(xf[:upto+1])
        if pre_vals.size == 0 or np.all(np.isnan(pre_vals)):
            continue
        q10, q90 = np.nanpercentile(pre_vals, [10, 90])
        med = np.nanmedian(pre_vals)
        if not (5 < med < 80):
            continue
        spread = q90 - q10
        if best_spread is None or spread < best_spread:
            best_spread = spread
            best_plane = name
    if best_plane is None:
        best_plane = 'X-Z'

    result = {
        'chosen_plane': best_plane,
        'xfactor_max_deg': stats[best_plane]['xfactor_max_deg'],
        'xfactor_max_frame': stats[best_plane]['xfactor_max_frame'],
        'xfactor_at_impact_deg': stats[best_plane]['xfactor_at_impact_deg'],
        'impact_frame': int(impact_idx),
    }

    return result, xf_by_plane

def categorize_xfactor(deg: float) -> Dict[str, object]:
    """X-Factor ë“±ê¸‰ ë° ì½”ë©˜íŠ¸ ìƒì„± (ê¸°ì¤€: ì„íŒ©íŠ¸ ì „ ìµœëŒ€ê°’)
    êµ¬ê°„:
      - < 25Â° (ë‚®ìŒ)
      - 25Â°â€“40Â° (ì ì •)
      - 40Â°â€“50Â° (ë†’ìŒ)
      - > 50Â° (ê³¼ë„)
    """
    if deg is None or not np.isfinite(deg):
        return {
            'range': 'N/A',
            'label': 'ì •ë³´ ì—†ìŒ',
            'messages': [
                'X-Factor ê°’ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì…ë ¥ ë°ì´í„°(ì–´ê¹¨/ê³¨ë°˜ 3D)ì™€ ì„íŒ©íŠ¸ ê²€ì¶œì„ í™•ì¸í•˜ì„¸ìš”.'
            ]
        }

    if deg < 25:
        return {
            'range': '< 25Â°',
            'label': 'ë‚®ìŒ',
            'messages': [
                'ìƒì²´ì™€ í•˜ì²´ì˜ íšŒì „ ì°¨ì´ê°€ ì‘ì•„ íŒŒì›Œ ì†ì‹¤ì´ ìˆìŠµë‹ˆë‹¤. ì–´ê¹¨ íšŒì „ì„ ë” í¬ê²Œ ê°€ì ¸ê°€ ë³´ì„¸ìš”.',
                'ë°±ìŠ¤ìœ™ ì‹œ ìƒì²´ê°€ ê³¨ë°˜ë³´ë‹¤ ë” ë§ì´ ëŒì•„ê°€ë„ë¡ ì—°ìŠµí•´ ë³´ì„¸ìš”.'
            ]
        }
    elif 25 <= deg <= 40:
        return {
            'range': '25Â°â€“40Â°',
            'label': 'ì ì •',
            'messages': [
                'ì´ìƒì ì¸ X-Factor ë²”ìœ„ì…ë‹ˆë‹¤. ìƒì²´Â·í•˜ì²´ ë¶„ë¦¬ íšŒì „ì´ ì˜ ì´ë£¨ì–´ì ¸ íŒŒì›Œ ì „ë‹¬ì´ íš¨ìœ¨ì ì´ì—ìš”.'
            ]
        }
    elif 40 < deg <= 50:
        return {
            'range': '40Â°â€“50Â°',
            'label': 'ë†’ìŒ',
            'messages': [
                'ì¶©ë¶„í•œ ê¼¬ì„ìœ¼ë¡œ ë¹„ê±°ë¦¬ í–¥ìƒì— ìœ ë¦¬í•©ë‹ˆë‹¤. ë‹¤ë§Œ í—ˆë¦¬Â·ì½”ì–´ì˜ ë¶€ë‹´ì´ ì»¤ì§ˆ ìˆ˜ ìˆìœ¼ë‹ˆ ìœ ì—°ì„± í›ˆë ¨ì„ ë³‘í–‰í•˜ì„¸ìš”.'
            ]
        }
    else:  # > 50
        return {
            'range': '> 50Â°',
            'label': 'ê³¼ë„',
            'messages': [
                'ìƒì²´ ê¼¬ì„ì´ ê³¼ë„í•˜ì—¬ ì„íŒ©íŠ¸ íƒ€ì´ë°ì´ í”ë“¤ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°±ìŠ¤ìœ™ì„ ì¡°ê¸ˆ ì¤„ì—¬ ë³´ì„¸ìš”.',
                'í—ˆë¦¬ì™€ ê³¨ë°˜ì´ ë”°ë¡œ ë…¸ëŠ” ëŠë‚Œì´ ê°•í•˜ë©´, íšŒì „ ë²”ìœ„ë¥¼ ì¡°ì ˆí•´ ì•ˆì •ê°ì„ ì°¾ì•„ë³´ì„¸ìš”.'
            ]
        }

def get_xfactor_joints_2d(df_overlay: pd.DataFrame, joints: List[str]) -> List[str]:
    cols_map = parse_joint_axis_map_from_columns(df_overlay.columns, prefer_2d=True)
    have = []
    for j in joints:
        axes = cols_map.get(j, {})
        if 'x' in axes and 'y' in axes:
            have.append(j)
    print(f"ğŸ”— X-Factor ê´€ë ¨ ê´€ì ˆ(2D): {have}")
    return have

def build_xfactor_edges(kp_names: List[str]):
    E, have = [], set(kp_names)
    def add(a, b):
        if a in have and b in have:
            E.append((a, b))
    add("LShoulder", "RShoulder")
    add("LHip", "RHip")
    add("LShoulder", "LHip")
    add("RShoulder", "RHip")
    print(f"ğŸ”— X-Factorìš© ì—°ê²°ì„ : {len(E)}ê°œ")
    return E

# =========================================================
# X-Factor ì‹œê°í™” (HUD ì—†ìŒ, ì†Œí˜•ë²”ìœ„ ìë™ë§¤í•‘)
# =========================================================
def overlay_xfactor_video(
    img_dir: Path,
    df_overlay: pd.DataFrame,
    xfactor_values: np.ndarray,
    shoulder_angles: np.ndarray,
    hip_angles: np.ndarray,
    out_mp4: Path,
    fps: int,
    codec: str,
    joints: List[str],
):
    images = sorted(glob.glob(str(img_dir / "*.png")), key=natural_key)
    if not images:
        images = sorted(glob.glob(str(img_dir / "*.jpg")), key=natural_key)
    if not images:
        images = sorted(glob.glob(str(img_dir / "*.jpeg")), key=natural_key)
    if not images:
        raise RuntimeError(f"No images (*.png|*.jpg|*.jpeg) in {img_dir}")

    first = cv2.imread(images[0])
    h, w = first.shape[:2]
    ensure_dir(out_mp4.parent)
    writer = cv2.VideoWriter(str(out_mp4), cv2.VideoWriter_fourcc(*codec), fps, (w, h))
    if not writer.isOpened():
        raise RuntimeError(f"VideoWriter open failed: {out_mp4}")

    kp_names = get_xfactor_joints_2d(df_overlay, joints)
    cols_map = parse_joint_axis_map_from_columns(df_overlay.columns, prefer_2d=True)
    edges = build_xfactor_edges(kp_names)

    # ì†Œí˜• ë²”ìœ„(ì •ê·œí™”) ì—¬ë¶€ íŒë‹¨ ë° ì „ì²´ ë²”ìœ„ ê³„ì‚°
    xs, ys = [], []
    for name in kp_names:
        ax = cols_map.get(name, {})
        cx = ax.get('x'); cy = ax.get('y')
        if cx in df_overlay.columns:
            xs.extend(df_overlay[cx].dropna().tolist())
        if cy in df_overlay.columns:
            ys.extend(df_overlay[cy].dropna().tolist())
    is_small = False
    x_min = x_max = y_min = y_max = None
    if xs and ys:
        x_min, x_max, y_min, y_max = min(xs), max(xs), min(ys), max(ys)
        if abs(x_min) <= 2.0 and abs(x_max) <= 2.0 and abs(y_min) <= 2.0 and abs(y_max) <= 2.0:
            is_small = True
        print(f"ğŸ“Š overlay ì¢Œí‘œ ë²”ìœ„(xfactor): X({x_min:.4f}~{x_max:.4f}) Y({y_min:.4f}~{y_max:.4f}) smallRange={is_small}")

    margin = 0.1
    def scale_xy(x, y):
        if np.isnan(x) or np.isnan(y):
            return np.nan, np.nan
        try:
            xf = float(x); yf = float(y)
        except Exception:
            return np.nan, np.nan
        if is_small and (x_max is not None):
            dx = x_max - x_min if (x_max - x_min) != 0 else 1.0
            dy = y_max - y_min if (y_max - y_min) != 0 else 1.0
            x_norm = (xf - x_min) / dx
            y_norm = (yf - y_min) / dy
            sx = (margin + x_norm * (1 - 2 * margin)) * w
            sy = (margin + y_norm * (1 - 2 * margin)) * h
            return sx, sy
        return xf, yf

    # ì²« í”„ë ˆì„ ìƒ˜í”Œ
    if len(df_overlay) > 0 and kp_names:
        sr = df_overlay.iloc[0]
        sj = kp_names[0]
        axm = cols_map.get(sj, {})
        sx = sr.get(axm.get('x', ''), np.nan)
        sy = sr.get(axm.get('y', ''), np.nan)
        sx2, sy2 = scale_xy(sx, sy)
        print(f"ğŸ”§ ì¢Œí‘œ ë³€í™˜ ìƒ˜í”Œ(xfactor {sj}): ({sx} , {sy}) â†’ ({sx2} , {sy2}) | screen {w}x{h}")

    n_img = len(images)
    n_df = len(df_overlay)
    if n_img != n_df:
        print(f"âš ï¸ í”„ë ˆì„ ê°œìˆ˜ ë¶ˆì¼ì¹˜(xfactor): images={n_img}, overlay_rows={n_df}. ì´ë¯¸ì§€ ê¸¸ì´ì— ë§ì¶° ë Œë”ë§í•˜ê³  CSV ë¶€ì¡±ë¶„ì€ ë§ˆì§€ë§‰ ê°’ì„ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.")

    for i, p in enumerate(images):
        frame = cv2.imread(p)
        row_idx = i if i < n_df else (n_df - 1 if n_df > 0 else -1)
        row = df_overlay.iloc[row_idx] if row_idx >= 0 else None

        # ì„  ê·¸ë¦¬ê¸°
        for a, b in edges:
            axm = cols_map.get(a, {}); bxm = cols_map.get(b, {})
            ax = row.get(axm.get('x', ''), np.nan)
            ay = row.get(axm.get('y', ''), np.nan)
            bx = row.get(bxm.get('x', ''), np.nan)
            by = row.get(bxm.get('y', ''), np.nan)
            ax, ay = scale_xy(ax, ay); bx, by = scale_xy(bx, by)
            if not (np.isnan(ax) or np.isnan(ay) or np.isnan(bx) or np.isnan(by)):
                if (a == 'LShoulder' and b == 'RShoulder'):
                    color, thickness = (255, 0, 0), 3
                elif (a == 'LHip' and b == 'RHip'):
                    color, thickness = (0, 0, 255), 3
                else:
                    color, thickness = (0, 255, 255), 2
                cv2.line(frame, (int(ax), int(ay)), (int(bx), int(by)), color, thickness)

        # ì  ê·¸ë¦¬ê¸°
        for name in kp_names:
            m = cols_map.get(name, {})
            x = row.get(m.get('x', ''), np.nan)
            y = row.get(m.get('y', ''), np.nan)
            x, y = scale_xy(x, y)
            if not (np.isnan(x) or np.isnan(y)):
                if 'Shoulder' in name:
                    cv2.circle(frame, (int(x), int(y)), 8, (255, 0, 0), -1)
                    cv2.circle(frame, (int(x), int(y)), 12, (255, 255, 255), 2)
                elif 'Hip' in name:
                    cv2.circle(frame, (int(x), int(y)), 8, (0, 0, 255), -1)
                    cv2.circle(frame, (int(x), int(y)), 12, (255, 255, 255), 2)

        # HUD/í…ìŠ¤íŠ¸/ê²Œì´ì§€ ì—†ìŒ
        writer.write(frame)

    writer.release()

# =========================================================
# run_from_context (í”„ë¡œê·¸ë¨ì  ì‹¤í–‰ ì§„ì…ì )
# =========================================================
def run_from_context(ctx: dict):
    """Programmatic runner for xfactor module (3D í•„ìˆ˜, 2DëŠ” ì˜¤ë²„ë ˆì´ ì „ìš©).

    ctx(dict) ì˜ˆìƒ í‚¤(ì„ íƒ í¬í•¨):
      - dest_dir: ì¶œë ¥ ë£¨íŠ¸ (ê¸°ë³¸ '.')
      - job_id | job: ì‘ì—… ì‹ë³„ì
      - wide3: 3D DataFrame (í•„ìˆ˜: L/R Shoulder, L/R Hip, L/R Ankle, R/L Wrist ì¤‘ ì¼ë¶€)
      - wide2: 2D DataFrame (ìˆìœ¼ë©´ ì˜¤ë²„ë ˆì´ ë Œë”ë§ìš©)
      - img_dir: í”„ë ˆì„ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
      - fps: ê¸°ë³¸ 30
      - codec: ê¸°ë³¸ 'mp4v'
      - draw.smoothing: ì˜¤ë²„ë ˆì´ 2D ìŠ¤ë¬´ë”© ì„¤ì •

    ë°˜í™˜(dict):
      - summary: X-Factor ìš”ì•½(ì„ íƒ í‰ë©´, ì„íŒ©íŠ¸ ì „ ìµœëŒ€/í”„ë ˆì„, ì„íŒ©íŠ¸ ì‹œ ê°’, ì„íŒ©íŠ¸ í”„ë ˆì„, ì¹´í…Œê³ ë¦¬ ë“±)
      - timeseries_csv: ì„ íƒ í‰ë©´ íƒ€ì„ì‹œë¦¬ì¦ˆ CSV ê²½ë¡œ (ì„ íƒ)
      - overlay_mp4: ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ê²½ë¡œ (2Dê°€ ìˆì„ ë•Œ)
      - dimension: '3d'
      - errors: {'metrics': str?, 'overlay': str?}
    """
    try:
        dest = Path(ctx.get('dest_dir', '.'))
        job_id = str(ctx.get('job_id', ctx.get('job', 'job')))
        fps = int(ctx.get('fps', 30))
        codec = str(ctx.get('codec', 'mp4v'))
        wide3 = ctx.get('wide3')
        wide2 = ctx.get('wide2')
        img_dir = Path(ctx.get('img_dir', dest))
        ensure_dir(dest)

        out = {'summary': {}, 'timeseries_csv': None, 'overlay_mp4': None, 'dimension': '3d', 'errors': {}}

        if wide3 is None:
            out['errors']['metrics'] = 'wide3 (3D DataFrame) is required for xfactor.'
            return out

        # 1~12 ë‹¨ê³„ ìˆ˜í–‰ (ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©)
        try:
            result, xf_by_plane = compute_xfactor(wide3)
            cat = categorize_xfactor(result.get('xfactor_max_deg'))
            result.update({
                'xfactor_range': cat['range'],
                'xfactor_category': cat['label'],
                'xfactor_advice': cat['messages'],
            })
            out['summary'] = result
        except Exception as e:
            out['errors']['metrics'] = str(e)

        # ì„ íƒ í‰ë©´ íƒ€ì„ì‹œë¦¬ì¦ˆ CSV ì €ì¥ (ì„ íƒ)
        try:
            chosen = out['summary'].get('chosen_plane') or 'X-Z'
            series = xf_by_plane.get(chosen)
            if series is not None:
                csv_path = dest / f"{job_id}_xfactor_timeseries.csv"
                pd.DataFrame({'frame': range(len(series)), 'xfactor_deg': series}).to_csv(csv_path, index=False)
                out['timeseries_csv'] = str(csv_path)
        except Exception as e:
            out['errors']['timeseries'] = str(e)

        # 2D ì˜¤ë²„ë ˆì´ (ìˆì„ ë•Œë§Œ)
        try:
            if wide2 is not None:
                # ìŠ¤ë¬´ë”© ì˜µì…˜
                draw_cfg = ctx.get('draw', {}) or {}
                smooth_cfg = (draw_cfg.get('smoothing') or {}) if isinstance(draw_cfg.get('smoothing'), dict) else {}
                if smooth_cfg.get('enabled', False):
                    method = smooth_cfg.get('method', 'ema')
                    window = int(smooth_cfg.get('window', 5))
                    alpha = float(smooth_cfg.get('alpha', 0.2))
                    gaussian_sigma = smooth_cfg.get('gaussian_sigma')
                    hampel_sigma = smooth_cfg.get('hampel_sigma', 3.0)
                    oneeuro_min_cutoff = smooth_cfg.get('oneeuro_min_cutoff', 1.0)
                    oneeuro_beta = smooth_cfg.get('oneeuro_beta', 0.007)
                    oneeuro_d_cutoff = smooth_cfg.get('oneeuro_d_cutoff', 1.0)
                    df_overlay_sm = smooth_df_2d(
                        wide2,
                        prefer_2d=True,
                        method=method,
                        window=window,
                        alpha=alpha,
                        fps=fps,
                        gaussian_sigma=gaussian_sigma,
                        hampel_sigma=hampel_sigma,
                        oneeuro_min_cutoff=oneeuro_min_cutoff,
                        oneeuro_beta=oneeuro_beta,
                        oneeuro_d_cutoff=oneeuro_d_cutoff,
                    )
                else:
                    df_overlay_sm = wide2
                # ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ìƒì„±
                chosen = out['summary'].get('chosen_plane') or 'X-Z'
                xfactor_vals = xf_by_plane.get(chosen, np.zeros(len(df_overlay_sm)))
                out_mp4 = dest / f"{job_id}_xfactor_overlay.mp4"
                overlay_xfactor_video(
                    img_dir=img_dir,
                    df_overlay=df_overlay_sm,
                    xfactor_values=xfactor_vals,
                    shoulder_angles=np.zeros(len(df_overlay_sm)),
                    hip_angles=np.zeros(len(df_overlay_sm)),
                    out_mp4=out_mp4,
                    fps=fps,
                    codec=codec,
                    joints=["LShoulder","RShoulder","LHip","RHip"],
                )
                out['overlay_mp4'] = str(out_mp4)
        except Exception as e:
            out['errors']['overlay'] = str(e)

        return out
    except Exception as e:
        return {'error': str(e)}
    finally:
        # Attempt to also write the rich JSON summary matching main() when possible
        try:
            if 'result' in locals() and 'xf_by_plane' in locals():
                chosen = result.get('chosen_plane') or 'X-Z'
                xfactor_series = xf_by_plane.get(chosen, [])
                frames_obj = {str(i): {"xfactor_deg": (float(v) if np.isfinite(v) else None)} for i, v in enumerate(xfactor_series)}
                job_id_local = job_id if 'job_id' in locals() else None
                out_obj = {
                    "job_id": job_id_local,
                    "dimension": "3d",
                    "metrics": {
                        "xfactor": {
                            "summary": {
                                "chosen_plane": result.get("chosen_plane"),
                                "xfactor_max_deg": result.get("xfactor_max_deg"),
                                "xfactor_max_frame": result.get("xfactor_max_frame"),
                                "xfactor_at_impact_deg": result.get("xfactor_at_impact_deg"),
                                "impact_frame": result.get("impact_frame"),
                                "xfactor_range": result.get("xfactor_range"),
                                "xfactor_category": result.get("xfactor_category"),
                                "xfactor_advice": result.get("xfactor_advice", []),
                                "unit": "deg"
                            },
                            "metrics_data": {
                                "xfactor_timeseries": frames_obj
                            }
                        }
                    }
                }
                try:
                    out_json = Path(dest) / "xfactor_metric_result.json"
                    out_json.write_text(json.dumps(out_obj, ensure_ascii=False, indent=2), encoding='utf-8')
                except Exception:
                    pass
        except Exception:
            pass
# =========================================================
# ë©”ì¸
# =========================================================
def main():
    ap = argparse.ArgumentParser(description="X-Factor ì „ìš© ë¶„ì„ê¸°")
    ap.add_argument("-c", "--config", default=str(Path(__file__).parent.parent / "config" / "analyze.yaml"))
    args = ap.parse_args()

    cfg = load_cfg(Path(args.config))

    # CSV ê²½ë¡œ (3D í•„ìˆ˜)
    overlay_csv = None
    metrics_csv = None
    if "overlay_csv_path" in cfg:
        overlay_csv = Path(cfg["overlay_csv_path"]) ; print(f"ğŸ“Š Overlay(2D) CSV(xfactor): {overlay_csv}")
    elif "csv_path" in cfg:
        overlay_csv = Path(cfg["csv_path"]) ; print(f"ğŸ“Š Overlay(2D) CSV (fallback)(xfactor): {overlay_csv}")
    if "metrics_csv_path" in cfg:
        metrics_csv = Path(cfg["metrics_csv_path"]) ; print(f"ğŸ“Š Metrics(3D) CSV(xfactor): {metrics_csv}")
    elif "csv_path" in cfg:
        metrics_csv = Path(cfg["csv_path"]) ; print(f"ğŸ“Š Metrics(3D) CSV (fallback)(xfactor): {metrics_csv}")

    if metrics_csv is None or not metrics_csv.exists():
        raise RuntimeError("metrics_csv_path ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    df_metrics = pd.read_csv(metrics_csv)

    # 1~12 ë‹¨ê³„ ìˆ˜í–‰
    result, xf_by_plane = compute_xfactor(df_metrics)

    # ë²”ìœ„ë³„ ì½”ë©˜íŠ¸ ìƒì„±(ì„íŒ©íŠ¸ ì „ ìµœëŒ€ê°’ ê¸°ì¤€)
    cat = categorize_xfactor(result.get('xfactor_max_deg'))
    result.update({
        'xfactor_range': cat['range'],
        'xfactor_category': cat['label'],
        'xfactor_advice': cat['messages'],
    })

    # ê²°ê³¼ ì €ì¥ ê²½ë¡œ (JSON ë‹¨ì¼ íŒŒì¼, summary + per-frame timeseries)
    out_dir = Path(cfg.get("metrics_csv", metrics_csv)).parent
    ensure_dir(out_dir)
    out_json = out_dir / "xfactor_metric_result.json"

    # ì„ íƒ í‰ë©´ íƒ€ì„ì‹œë¦¬ì¦ˆ(JSON í˜•ì‹ìœ¼ë¡œ í¬í•¨)
    chosen = result['chosen_plane']
    xfactor_series = xf_by_plane[chosen]
    frames_obj = {str(i): {"xfactor_deg": (float(v) if np.isfinite(v) else None)} for i, v in enumerate(xfactor_series)}

    # ì°¸ì¡°ìš© ë©”íƒ€
    job_id = cfg.get("job_id")
    dimension = "3d"

    out_obj = {
        "job_id": job_id,
        "dimension": dimension,
        "metrics": {
            "xfactor": {
                # CSV ì‚°ì¶œì„ ì¤‘ë‹¨í–ˆì§€ë§Œ, ìŠ¤í‚¤ë§ˆ í˜¸í™˜ì„ ìœ„í•´ í‚¤ëŠ” ìœ ì§€(ê°’ì€ None)
                "summary": {
                    "chosen_plane": result.get("chosen_plane"),
                    "xfactor_max_deg": result.get("xfactor_max_deg"),
                    "xfactor_max_frame": result.get("xfactor_max_frame"),
                    "xfactor_at_impact_deg": result.get("xfactor_at_impact_deg"),
                    "impact_frame": result.get("impact_frame"),
                    "xfactor_range": result.get("xfactor_range"),
                    "xfactor_category": result.get("xfactor_category"),
                    "xfactor_advice": result.get("xfactor_advice", []),
                    "unit": "deg"
                },
                "metrics_data": {
                    # ì°¸ê³  JSONì˜ êµ¬ì¡°ë¥¼ ë”°ë¥´ê¸° ìœ„í•´ íŒŒì¼ëª… ìœ ì‚¬ í‚¤ í•˜ìœ„ì— í”„ë ˆì„ ì‚¬ì „ì„ ë‘¡ë‹ˆë‹¤.
                    "xfactor_timeseries": frames_obj
                }
            }
        }
    }

    # JSON ì €ì¥ (ë‹¨ì¼ íŒŒì¼, CSVëŠ” ìƒì„±í•˜ì§€ ì•ŠìŒ)
    out_json.write_text(json.dumps(out_obj, ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"âœ… X-Factor JSON ì €ì¥: {out_json}")

    # ì„ íƒì ìœ¼ë¡œ 2D ì˜¤ë²„ë ˆì´ë„ ìœ ì§€ (ìˆìœ¼ë©´)
    try:
        img_dir = Path(cfg["img_dir"]) ; fps = int(cfg.get("fps", 30)) ; codec = str(cfg.get("codec", "mp4v"))
        if overlay_csv is not None and overlay_csv.exists():
            df_overlay = pd.read_csv(overlay_csv)
            draw_cfg = cfg.get('draw', {}) or {}
            smooth_cfg = (draw_cfg.get('smoothing') or {}) if isinstance(draw_cfg.get('smoothing'), dict) else {}
            if smooth_cfg.get('enabled', False):
                method = smooth_cfg.get('method', 'ema'); window = int(smooth_cfg.get('window', 5)); alpha = float(smooth_cfg.get('alpha', 0.2))
                gaussian_sigma = smooth_cfg.get('gaussian_sigma'); hampel_sigma = smooth_cfg.get('hampel_sigma', 3.0)
                oneeuro_min_cutoff = smooth_cfg.get('oneeuro_min_cutoff', 1.0); oneeuro_beta = smooth_cfg.get('oneeuro_beta', 0.007); oneeuro_d_cutoff = smooth_cfg.get('oneeuro_d_cutoff', 1.0)
                df_overlay_sm = smooth_df_2d(
                    df_overlay,
                    prefer_2d=True,
                    method=method,
                    window=window,
                    alpha=alpha,
                    fps=fps,
                    gaussian_sigma=gaussian_sigma,
                    hampel_sigma=hampel_sigma,
                    oneeuro_min_cutoff=oneeuro_min_cutoff,
                    oneeuro_beta=oneeuro_beta,
                    oneeuro_d_cutoff=oneeuro_d_cutoff,
                )
            else:
                df_overlay_sm = df_overlay
            out_mp4 = Path(cfg["overlay_mp4"]).parent / "xfactor_analysis.mp4"
            # ê¸°ì¡´ ì˜¤ë²„ë ˆì´ í•¨ìˆ˜ ì¬ì‚¬ìš© (xfactor ê°’ ìì²´ëŠ” ì˜ìƒì—” ë°˜ì˜í•˜ì§€ ì•ŠìŒ)
            overlay_xfactor_video(img_dir, df_overlay_sm, xf_by_plane[chosen], np.zeros(len(df_overlay_sm)), np.zeros(len(df_overlay_sm)), out_mp4, fps, codec, ["LShoulder","RShoulder","LHip","RHip"])
    except Exception as e:
        print(f"â„¹ï¸ ì˜¤ë²„ë ˆì´ ìƒëµ/ì‹¤íŒ¨: {e}")

    # ì½˜ì†”: ê²°ê³¼ ìš”ì•½ ì¶œë ¥ + ì½”ë©˜íŠ¸
    print(json.dumps(result, ensure_ascii=False, indent=2))
    try:
        print(f"ğŸ“ X-Factor í‰ê°€: {result['xfactor_range']} {result['xfactor_category']}")
        for msg in result.get('xfactor_advice', [])[:2]:
            print(f"  - {msg}")
    except Exception:
        pass

if __name__ == "__main__":
    main()