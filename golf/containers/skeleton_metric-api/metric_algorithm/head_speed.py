# src/head_speed.py
# -*- coding: utf-8 -*-
"""
Head Speed ì „ìš© ë¶„ì„ê¸°

ê³¨í”„ ìŠ¤ìœ™ ì‹œ ë¨¸ë¦¬(Head)ì˜ ì›€ì§ì„ê³¼ ì†ë„ë¥¼ ë¶„ì„í•˜ëŠ” ì „ìš© ë„êµ¬ì…ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. Head Speed ê³„ì‚°
   - 3D ì¢Œí‘œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì‹¤ì‹œê°„ ë¨¸ë¦¬ ì´ë™ ì†ë„ ì¸¡ì •
   - mm/s ë˜ëŠ” mm/frame ë‹¨ìœ„ë¡œ ì†ë„ í‘œì‹œ
   
2. ë¨¸ë¦¬ ì•ˆì •ì„± ë¶„ì„
   - ìŠ¤ìœ™ ì¤‘ ë¨¸ë¦¬ì˜ ì¢Œìš° í¸ì°¨(deviation) ê³„ì‚°
   - ê³¨í”„ì—ì„œ ì¤‘ìš”í•œ 'í—¤ë“œì—…' ë°©ì§€ë¥¼ ìœ„í•œ ì§€í‘œ ì œê³µ
   
3. ì‹œê°í™” ê¸°ëŠ¥
   - ë¨¸ë¦¬ ìœ„ì¹˜ë¥¼ ì›í˜•ìœ¼ë¡œ í‘œì‹œ
   - ë¨¸ë¦¬ ì´ë™ ê¶¤ì  ì¶”ì  (ìµœê·¼ 50í”„ë ˆì„)
   - ì‹¤ì‹œê°„ ì†ë„ ë° ì•ˆì •ì„± ì§€í‘œ í‘œì‹œ

ê³¨í”„ ìŠ¤ìœ™ì—ì„œ ë¨¸ë¦¬ì˜ ì•ˆì •ì„±ì€ ì •í™•í•œ ì„íŒ©íŠ¸ì™€ ì¼ê´€ì„± ìˆëŠ” ìŠ¤ìœ™ì„ ìœ„í•´ 
ë§¤ìš° ì¤‘ìš”í•œ ìš”ì†Œì…ë‹ˆë‹¤. ì´ ë¶„ì„ê¸°ëŠ” ì´ëŸ¬í•œ ì›€ì§ì„ì„ ì •ëŸ‰ì ìœ¼ë¡œ ì¸¡ì •í•©ë‹ˆë‹¤.
"""
import argparse
from pathlib import Path
import pandas as pd
import numpy as np
import cv2
import glob
import re
from typing import Optional, Tuple, Dict, List, Union

try:
    import yaml
except ImportError:
    yaml = None

# ê³µí†µ ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent))
from utils_io import natural_key, ensure_dir

# =========================================================
# ê³µí†µ ìœ í‹¸ë¦¬í‹°/ë§¤í•‘ í•¨ìˆ˜ë“¤ (ìœ ì—°í•œ í—¤ë” ì§€ì›)
# =========================================================
def parse_joint_axis_map_from_columns(columns, prefer_2d: bool = False) -> Dict[str, Dict[str, str]]:
    cols = list(columns)
    mapping: Dict[str, Dict[str, str]] = {}
    if prefer_2d:
        axis_patterns = [
            ('_x', '_y', '_z'),
            ('__x', '__y', '__z'),
            ('_X', '_Y', '_Z'),
            ('_X3D', '_Y3D', '_Z3D'),
        ]
    else:
        axis_patterns = [
            ('_X3D', '_Y3D', '_Z3D'),
            ('__x', '__y', '__z'),
            ('_X', '_Y', '_Z'),
            ('_x', '_y', '_z'),
        ]
    col_set = set(cols)
    for col in cols:
        if col.lower() in ('frame', 'time', 'timestamp'):
            continue
        for x_pat, y_pat, z_pat in axis_patterns:
            if col.endswith(x_pat):
                joint = col[:-len(x_pat)]
                x_col = joint + x_pat
                y_col = joint + y_pat
                z_col = joint + z_pat
                if x_col in col_set and y_col in col_set:
                    mapping.setdefault(joint, {})['x'] = x_col
                    mapping.setdefault(joint, {})['y'] = y_col
                    if z_col in col_set:
                        mapping[joint]['z'] = z_col
                    break
    return mapping

def get_xyz_cols(df: pd.DataFrame, name: str):
    cols_map = parse_joint_axis_map_from_columns(df.columns, prefer_2d=False)
    if name in cols_map and all(a in cols_map[name] for a in ('x','y','z')):
        m = cols_map[name]
        return df[[m['x'], m['y'], m['z']]].astype(float).to_numpy()
    return np.full((len(df), 3), np.nan, dtype=float)

def get_xyc_row(row: pd.Series, name: str):
    """ê´€ì ˆì˜ 2D ì¢Œí‘œ ì¶”ì¶œ (ì‹ ë¢°ë„ëŠ” 1.0 ê³ ì •)"""
    cols_map = parse_joint_axis_map_from_columns(row.index, prefer_2d=True)
    x = row.get(cols_map.get(name, {}).get('x',''), np.nan)
    y = row.get(cols_map.get(name, {}).get('y',''), np.nan)
    return x, y, 1.0

def speed_3d(points_xyz, fps):
    """
    3D ê³µê°„ì—ì„œì˜ ì†ë„ ê³„ì‚°
    
    ì—°ì†ëœ 3D ì¢Œí‘œ í¬ì¸íŠ¸ë“¤ ì‚¬ì´ì˜ ìœ í´ë¦¬ë“œ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ì—¬ 
    í”„ë ˆì„ë‹¹ ë˜ëŠ” ì´ˆë‹¹ ì´ë™ ì†ë„ë¥¼ êµ¬í•©ë‹ˆë‹¤.
    
    Args:
        points_xyz (np.ndarray): (N, 3) í˜•íƒœì˜ 3D ì¢Œí‘œ ë°°ì—´ (mm ë‹¨ìœ„)
        fps (float/int/None): í”„ë ˆì„ ë ˆì´íŠ¸. Noneì´ë©´ mm/frame, ê°’ì´ ìˆìœ¼ë©´ mm/s
        
    Returns:
        tuple: (ì†ë„ ë°°ì—´, ë‹¨ìœ„ ë¬¸ìì—´)
               ì†ë„ëŠ” (N,) í˜•íƒœì˜ numpy array
               
    ì²˜ë¦¬ ê³¼ì •:
        1. ì—°ì† í”„ë ˆì„ ê°„ 3D ê±°ë¦¬ ê³„ì‚°: ||P(t+1) - P(t)||
        2. NaN ê°’ ì²˜ë¦¬: forward fill í›„ 0ìœ¼ë¡œ ì´ˆê¸°í™”
        3. fpsê°€ ì£¼ì–´ì§€ë©´ frame ë‹¨ìœ„ë¥¼ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜
    """
    N = len(points_xyz)
    v = np.full(N, np.nan, dtype=float)
    for i in range(1, N):
        a, b = points_xyz[i-1], points_xyz[i]
        if np.any(np.isnan(a)) or np.any(np.isnan(b)):
            continue
        v[i] = float(np.linalg.norm(b - a))
    if fps and fps > 0:
        v = v * float(fps)
        unit = "mm/s"
    else:
        unit = "mm/frame"
    v = pd.Series(v).fillna(method="ffill").fillna(0).to_numpy()
    return v, unit

def load_cfg(p: Path):
    if p.suffix.lower() in (".yml", ".yaml"):
        if yaml is None:
            raise RuntimeError("pip install pyyaml")
        return yaml.safe_load(p.read_text(encoding="utf-8"))
    raise ValueError("Use YAML for analyze config.")

# =========================================================
# 2D ì¢Œí‘œ ìŠ¤ë¬´ë”© ìœ í‹¸ë¦¬í‹° (com_speedì™€ ë™ì¼ ì˜µì…˜)
# =========================================================
def _ema(series: pd.Series, alpha: float) -> pd.Series:
    a = alpha if alpha is not None else 0.2
    a = 0.2 if a <= 0 or a >= 1 else a
    return series.ewm(alpha=a, adjust=False).mean()

def _moving(series: pd.Series, window: int) -> pd.Series:
    w = max(int(window or 5), 1)
    return series.rolling(window=w, min_periods=1).mean()

def _median(series: pd.Series, window: int) -> pd.Series:
    w = max(int(window or 5), 1)
    return series.rolling(window=w, min_periods=1).median()

def _gaussian_kernel(window: int, sigma: Optional[float] = None) -> np.ndarray:
    w = int(window or 5)
    if w % 2 == 0:
        w += 1
    if w < 3:
        w = 3
    s = float(sigma) if sigma and sigma > 0 else max(w / 3.0, 1.0)
    r = w // 2
    x = np.arange(-r, r + 1)
    k = np.exp(-0.5 * (x / s) ** 2)
    k /= np.sum(k)
    return k

def _gaussian(series: pd.Series, window: int, sigma: Optional[float]) -> pd.Series:
    vals = series.to_numpy(dtype=float, copy=True)
    mask = np.isnan(vals)
    tmp = pd.Series(vals).fillna(method='ffill').fillna(method='bfill').to_numpy()
    k = _gaussian_kernel(window, sigma)
    sm = np.convolve(tmp, k, mode='same')
    sm[mask] = np.nan
    return pd.Series(sm, index=series.index)

def _hampel(series: pd.Series, window: int, n_sigma: float = 3.0) -> pd.Series:
    w = max(int(window or 7), 1)
    if w % 2 == 0:
        w += 1
    x = series.astype(float)
    med = x.rolling(window=w, center=True, min_periods=1).median()
    diff = (x - med).abs()
    mad = diff.rolling(window=w, center=True, min_periods=1).median()
    thresh = 1.4826 * mad * float(n_sigma if n_sigma and n_sigma > 0 else 3.0)
    out = x.copy()
    out[diff > thresh] = med[diff > thresh]
    return out

def _one_euro(series: pd.Series, fps: float, min_cutoff: float = 1.0, beta: float = 0.007, d_cutoff: float = 1.0) -> pd.Series:
    vals = series.to_numpy(dtype=float, copy=True)
    mask = np.isnan(vals)
    tmp = pd.Series(vals).fillna(method='ffill').fillna(method='bfill').to_numpy()
    dt = 1.0 / float(fps) if fps and fps > 0 else 1.0
    def alpha(cutoff):
        tau = 1.0 / (2.0 * np.pi * float(cutoff)) if cutoff and cutoff > 0 else 1.0
        return 1.0 / (1.0 + tau / dt)
    x_hat = np.zeros_like(tmp)
    dx_hat = 0.0
    a_d = alpha(d_cutoff)
    x_hat[0] = tmp[0]
    prev_x = tmp[0]
    for i in range(1, len(tmp)):
        x = tmp[i]
        dx = (x - prev_x) / dt
        dx_hat = a_d * dx + (1 - a_d) * dx_hat
        cutoff = float(min_cutoff) + float(beta) * abs(dx_hat)
        a = alpha(cutoff)
        x_hat[i] = a * x + (1 - a) * x_hat[i - 1]
        prev_x = x
    x_hat[mask] = np.nan
    return pd.Series(x_hat, index=series.index)

def smooth_df_2d(
    df: pd.DataFrame,
    prefer_2d: bool = True,
    method: str = 'ema',
    window: int = 5,
    alpha: float = 0.2,
    fps: Optional[float] = None,
    gaussian_sigma: Optional[float] = None,
    hampel_sigma: Optional[float] = 3.0,
    oneeuro_min_cutoff: float = 1.0,
    oneeuro_beta: float = 0.007,
    oneeuro_d_cutoff: float = 1.0,
) -> pd.DataFrame:
    cols_map = parse_joint_axis_map_from_columns(df.columns, prefer_2d=prefer_2d)
    out = df.copy()
    m = (method or 'ema').lower()
    for j, axes in cols_map.items():
        cx, cy = axes.get('x'), axes.get('y')
        if not cx or not cy or cx not in out.columns or cy not in out.columns:
            continue
        sx = out[cx].astype(float)
        sy = out[cy].astype(float)
        if m == 'moving':
            out[cx] = _moving(sx, window); out[cy] = _moving(sy, window)
        elif m == 'median':
            out[cx] = _median(sx, window); out[cy] = _median(sy, window)
        elif m == 'gaussian':
            out[cx] = _gaussian(sx, window, gaussian_sigma); out[cy] = _gaussian(sy, window, gaussian_sigma)
            
        elif m == 'hampel_ema':
            hx = _hampel(sx, window, hampel_sigma); hy = _hampel(sy, window, hampel_sigma)
            out[cx] = _ema(hx, alpha); out[cy] = _ema(hy, alpha)
        elif m == 'oneeuro':
            out[cx] = _one_euro(sx, fps=fps, min_cutoff=oneeuro_min_cutoff, beta=oneeuro_beta, d_cutoff=oneeuro_d_cutoff)
            out[cy] = _one_euro(sy, fps=fps, min_cutoff=oneeuro_min_cutoff, beta=oneeuro_beta, d_cutoff=oneeuro_d_cutoff)
        else:
            out[cx] = _ema(sx, alpha); out[cy] = _ema(sy, alpha)
    print(f"âœ¨ 2D ìŠ¤ë¬´ë”© ì ìš©(head): method={m}, window={window}, alpha={alpha}")
    return out
# =========================================================
# Head Speed ì „ìš© ê³„ì‚° í•¨ìˆ˜
# =========================================================
def _get_axis_series(df: pd.DataFrame, joint: str, axis: str, prefer_2d: bool = False) -> pd.Series:
    """ì¡°ì¸íŠ¸-ì¶•ì— í•´ë‹¹í•˜ëŠ” ì‹œë¦¬ì¦ˆë¥¼ ë°˜í™˜. ì—†ìœ¼ë©´ NaN ì‹œë¦¬ì¦ˆ ë°˜í™˜"""
    cmap = parse_joint_axis_map_from_columns(df.columns, prefer_2d=prefer_2d)
    col = (cmap.get(joint, {}) or {}).get(axis)
    if col and col in df.columns:
        return df[col].astype(float)
    return pd.Series([np.nan] * len(df), index=df.index, dtype=float)

def _median_ignore_nan(arr: np.ndarray) -> float:
    vals = np.asarray(arr, dtype=float)
    vals = vals[~np.isnan(vals)]
    if len(vals) == 0:
        return np.nan
    return float(np.median(vals))

def _first_valid_index(mask: np.ndarray) -> int:
    idx = np.where(mask)[0]
    return int(idx[0]) if idx.size > 0 else -1

def compute_head_movement_preimpact(df: pd.DataFrame, head_joint: str = "Nose", skip_ratio: float = 0.2):
    """
    ì„íŒ©íŠ¸ ì „ ë¨¸ë¦¬ ì›€ì§ì„(í”„ë ˆì„0 ëŒ€ë¹„ Î”x,Î”y) ì¸¡ì • ë° % ì •ê·œí™”

    ê·œì¹™(ìš”ì²­ ì‚¬ì–‘):
    - ë¨¸ë¦¬ ëŒ€í‘œ: Nose (3D x,y ì‚¬ìš©)
    - ê¸°ì¤€ í”„ë ˆì„: 0 (ì–´ë“œë ˆìŠ¤)
    - ìŠ¤íƒ ìŠ¤ ì¤‘ì•™: stance_mid_x = (RAnkle_x + LAnkle_x)/2 (í”„ë ˆì„ë³„)
    - ì†ëª© ì„ íƒ: í›„ë°˜ë¶€ X ì¶”ì„¸(slope)ê°€ ë” +ì¸ ì†ëª©ì„ ì„ íƒ
    - ì„íŒ©íŠ¸: ìŠ¤ìœ™ ì´ˆë°˜ 20% ê±´ë„ˆë›°ê³ , Wrist_X >= stance_mid_x and Î”Wrist_X>0 ìµœì´ˆ í”„ë ˆì„
    - ì„íŒ©íŠ¸ ì „ êµ¬ê°„ì—ì„œ ë¨¸ë¦¬ ì´ ë³€ìœ„(max, RMS) ê³„ì‚°
    - ì •ê·œí™”: ìŠ¤íƒ ìŠ¤ í­ ì¤‘ì•™ê°’(|RAnkle_x - LAnkle_x|ì˜ median)ë¡œ ë‚˜ëˆ  %
    """
    N = len(df)
    if N == 0:
        return {
            'impact_frame': -1, 'stance_width_med': np.nan, 'grade': None,
            'disp_max_pct': np.nan, 'disp_rms_pct': np.nan,
            'head_dx': np.array([]), 'head_dy': np.array([]), 'head_disp': np.array([]), 'head_disp_pct': np.array([]),
            'selected_wrist': None,
        }

    # 3D ì¶• ì‹œê³„ì—´
    nose_x = _get_axis_series(df, head_joint, 'x', prefer_2d=False).to_numpy()
    nose_y = _get_axis_series(df, head_joint, 'y', prefer_2d=False).to_numpy()
    la_x = _get_axis_series(df, 'LAnkle', 'x', prefer_2d=False).to_numpy()
    ra_x = _get_axis_series(df, 'RAnkle', 'x', prefer_2d=False).to_numpy()
    lw_x = _get_axis_series(df, 'LWrist', 'x', prefer_2d=False).to_numpy()
    rw_x = _get_axis_series(df, 'RWrist', 'x', prefer_2d=False).to_numpy()

    # ê¸°ì¤€ í”„ë ˆì„(0) ì¢Œí‘œ
    x0 = nose_x[0] if not np.isnan(nose_x[0]) else np.nan
    y0 = nose_y[0] if not np.isnan(nose_y[0]) else np.nan

    # Î”x, Î”y ë° ë³€ìœ„
    head_dx = nose_x - x0
    head_dy = nose_y - y0
    head_disp = np.sqrt(head_dx**2 + head_dy**2)

    # ìŠ¤íƒ ìŠ¤ ì¤‘ì•™ ë° í­
    stance_mid_x = (ra_x + la_x) / 2.0
    stance_width = np.abs(ra_x - la_x)
    stance_width_med = _median_ignore_nan(stance_width)

    # ì†ëª© ì„ íƒ: í›„ë°˜ë¶€(ì˜ˆ: 50%~100%) êµ¬ê°„ì—ì„œ ì„ í˜• ì¶”ì„¸ ê¸°ìš¸ê¸° ë¹„êµ
    start_slope = int(N * max(skip_ratio, 0.2))
    start_slope = min(start_slope, max(N - 3, 0))
    xs = np.arange(start_slope, N, dtype=float)
    def slope_of(arr):
        yy = arr[start_slope:]
        if len(xs) != len(yy) or len(yy) < 2:
            return np.nan
        # NaN ì²˜ë¦¬: ì„ í˜• ë³´ê°„ í›„ íšŒê·€
        yy2 = pd.Series(yy).interpolate(limit_direction='both').to_numpy()
        try:
            k, b = np.polyfit(xs, yy2, 1)
            return float(k)
        except Exception:
            return np.nan
    slope_L = slope_of(lw_x)
    slope_R = slope_of(rw_x)
    selected_wrist = 'RWrist' if (np.nan_to_num(slope_R, nan=-1e9) >= np.nan_to_num(slope_L, nan=-1e9)) else 'LWrist'
    wrist_x = rw_x if selected_wrist == 'RWrist' else lw_x

    # ì„íŒ©íŠ¸ í”„ë ˆì„ íƒì§€
    start = int(N * max(skip_ratio, 0.2))
    impact = -1
    for i in range(max(1, start), N):
        if np.isnan(wrist_x[i]) or np.isnan(wrist_x[i-1]) or np.isnan(stance_mid_x[i]):
            continue
        cond_cross = wrist_x[i] >= stance_mid_x[i]
        cond_vel = (wrist_x[i] - wrist_x[i-1]) > 0
        if cond_cross and cond_vel:
            impact = i
            break
    if impact == -1:
        # fallback: ì†ëª© Xê°€ ìµœëŒ€ì¸ í”„ë ˆì„
        with np.errstate(invalid='ignore'):
            impact = int(np.nanargmax(wrist_x)) if np.any(~np.isnan(wrist_x)) else N-1

    # ì„íŒ©íŠ¸ ì „ êµ¬ê°„ ë³€ìœ„ í†µê³„
    upto = max(min(impact, N-1), 0)
    seg = head_disp[:upto+1]
    if np.all(np.isnan(seg)):
        disp_max = np.nan; disp_rms = np.nan
    else:
        seg2 = seg[~np.isnan(seg)]
        disp_max = float(np.max(seg2)) if seg2.size > 0 else np.nan
        disp_rms = float(np.sqrt(np.mean(seg2**2))) if seg2.size > 0 else np.nan

    # % ì •ê·œí™”
    if stance_width_med and not np.isnan(stance_width_med) and stance_width_med > 0:
        disp_max_pct = disp_max / stance_width_med * 100.0 if not np.isnan(disp_max) else np.nan
        disp_rms_pct = disp_rms / stance_width_med * 100.0 if not np.isnan(disp_rms) else np.nan
        head_disp_pct = head_disp / stance_width_med * 100.0
    else:
        disp_max_pct = np.nan; disp_rms_pct = np.nan
        head_disp_pct = np.full_like(head_disp, np.nan, dtype=float)

    # ë“±ê¸‰ íŒì •
    def grade_of(pct):
        if np.isnan(pct):
            return None
        if pct < 5:
            return 'Excellent'
        if pct < 10:
            return 'Good'
        if pct < 15:
            return 'Caution'
        return 'Excessive'
    grade = grade_of(disp_max_pct)

    return {
        'impact_frame': int(impact),
        'stance_width_med': stance_width_med,
        'disp_max_pct': disp_max_pct,
        'disp_rms_pct': disp_rms_pct,
        'grade': grade,
        'head_dx': head_dx,
        'head_dy': head_dy,
        'head_disp': head_disp,
        'head_disp_pct': head_disp_pct,
        'selected_wrist': selected_wrist,
    }
def compute_head_speed_3d(df: pd.DataFrame, landmark: str, fps=None):
    """
    ë°ì´í„°í”„ë ˆì„ì—ì„œ íŠ¹ì • ëœë“œë§ˆí¬ì˜ Head Speed ê³„ì‚°
    
    ê³¨í”„ ìŠ¤ìœ™ ë¶„ì„ì—ì„œ ë¨¸ë¦¬ ì›€ì§ì„ ì†ë„ë¥¼ ì¸¡ì •í•˜ëŠ” í•µì‹¬ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    
    Args:
        df (pd.DataFrame): ê´€ì ˆ ì¢Œí‘œ ë°ì´í„°ê°€ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„
        landmark (str): ë¶„ì„í•  ê´€ì ˆ ì´ë¦„ (ì˜ˆ: "Nose", "Head")
        fps (int/float, optional): í”„ë ˆì„ ë ˆì´íŠ¸. Noneì´ë©´ frame ë‹¨ìœ„, ê°’ì´ ìˆìœ¼ë©´ ì´ˆ ë‹¨ìœ„
        
    Returns:
        tuple: (ì†ë„ ë°°ì—´, ë‹¨ìœ„ ë¬¸ìì—´)
        
    ì²˜ë¦¬ ê³¼ì •:
        1. í•„ìˆ˜ ì»¬ëŸ¼(x, y, z) ì¡´ì¬ í™•ì¸
        2. 3D ì¢Œí‘œ ì¶”ì¶œ
        3. speed_3d() í•¨ìˆ˜ë¡œ ì†ë„ ê³„ì‚°
        
    ê³¨í”„ ë¶„ì„ ì˜ë¯¸:
        - ë¹ ë¥¸ ë¨¸ë¦¬ ì›€ì§ì„: ìŠ¤ìœ™ì˜ ë¶ˆì•ˆì •ì„± ì§€í‘œ
        - ëŠë¦° ë¨¸ë¦¬ ì›€ì§ì„: ì•ˆì •ì ì¸ ìŠ¤ìœ™ ì§€í‘œ
    """
    print(f"ğŸ¯ Head Speed ê³„ì‚°ìš© ê´€ì ˆ: [{landmark}]")
    
    pts = get_xyz_cols(df, landmark)
    head_speed, head_unit = speed_3d(pts, fps)
    
    # ë¨¸ë¦¬ ì›€ì§ì„ ì•ˆì •ì„± ë¶„ì„
    head_deviations = []
    for i in range(len(pts)):
        if i > 0 and not np.any(np.isnan(pts[i])) and not np.any(np.isnan(pts[i-1])):
            deviation = np.linalg.norm(pts[i] - pts[i-1])
            head_deviations.append(deviation)
        else:
            head_deviations.append(0.0)
    
    head_deviations = np.array(head_deviations)
    
    # ì•ˆì •ì„± ë©”íŠ¸ë¦­
    stability_metrics = {
        "avg_deviation": np.mean(head_deviations) if len(head_deviations) > 0 else 0.0,
        "max_deviation": np.max(head_deviations) if len(head_deviations) > 0 else 0.0,
        "stability_score": 1.0 / (1.0 + np.std(head_deviations)) if len(head_deviations) > 0 else 1.0
    }
    
    return pts, head_speed, head_deviations, stability_metrics, head_unit

def calculate_data_range(df: pd.DataFrame) -> tuple:
    """
    ë°ì´í„°ì…‹ ì „ì²´ì—ì„œ ì‹¤ì œ x,y ì¢Œí‘œ ë²”ìœ„ë¥¼ ë™ì ìœ¼ë¡œ ê³„ì‚°
    
    3D ì¢Œí‘œë¥¼ 2D í™”ë©´ì— ë§¤í•‘í•˜ê¸° ìœ„í•´ ì‹¤ì œ ë°ì´í„°ì˜ ìµœì†Œ/ìµœëŒ€ê°’ì„ êµ¬í•©ë‹ˆë‹¤.
    ê³ ì •ëœ ë²”ìœ„ ëŒ€ì‹  ë™ì  ê³„ì‚°ìœ¼ë¡œ ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì— ëŒ€ì‘í•©ë‹ˆë‹¤.
    
    Args:
        df (pd.DataFrame): ì¢Œí‘œ ë°ì´í„°ê°€ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„
        
    Returns:
        tuple: (x_min, x_max, y_min, y_max) - ì‹¤ì œ ì¢Œí‘œ ë²”ìœ„
        
    ì²˜ë¦¬ ê³¼ì •:
        1. '__x', '__y' ì ‘ë¯¸ì‚¬ë¥¼ ê°€ì§„ ëª¨ë“  ì»¬ëŸ¼ ê²€ìƒ‰
        2. NaN ê°’ ì œê±° í›„ ì „ì²´ ìµœì†Œ/ìµœëŒ€ê°’ ê³„ì‚°
        3. ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ë°˜í™˜
        
    ìš©ë„:
        - ì¢Œí‘œ ì •ê·œí™”ë¥¼ ìœ„í•œ ë²”ìœ„ ì„¤ì •
        - í™”ë©´ ë§¤í•‘ì„ ìœ„í•œ ìŠ¤ì¼€ì¼ ê³„ì‚°
        - ì‹œê°í™” ë²”ìœ„ ìë™ ì¡°ì •
    """
    x_cols = [col for col in df.columns if col.endswith('__x') or col.endswith('_x')]
    y_cols = [col for col in df.columns if col.endswith('__y') or col.endswith('_y')]
    
    all_x = []
    all_y = []
    
    for col in x_cols:
        vals = df[col].dropna()
        if len(vals) > 0:
            all_x.extend(vals.tolist())
    
    for col in y_cols:
        vals = df[col].dropna()  
        if len(vals) > 0:
            all_y.extend(vals.tolist())
    
    if all_x and all_y:
        x_min, x_max = min(all_x), max(all_x)
        y_min, y_max = min(all_y), max(all_y)
        print(f"ğŸ“Š ë™ì  ê³„ì‚°ëœ ì „ì²´ ë²”ìœ„: X({x_min:.6f}~{x_max:.6f}), Y({y_min:.6f}~{y_max:.6f})")
        return x_min, x_max, y_min, y_max
    else:
        print("âš ï¸ ì¢Œí‘œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©")
        return -1.0, 1.0, -1.0, 1.0

# =========================================================
# Head Speed ì‹œê°í™” ì „ìš© ì˜¤ë²„ë ˆì´
# =========================================================
def overlay_head_video(img_dir: Path, df: pd.DataFrame, head_points: np.ndarray, 
                      head_speed: np.ndarray, head_deviations: np.ndarray, 
                      stability_metrics: dict, head_unit: str, head_name: str,
                      out_mp4: Path, fps: int, codec: str):
    """Head ê´€ì ˆ ì‹œê°í™”

    ë³€ê²½ ì‚¬í•­: ë¨¸ë¦¬ë¥¼ ì¸ì‹í•œ ë’¤, ì²« ìœ íš¨ ì¢Œí‘œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê³ ì •ëœ ë¹¨ê°„ìƒ‰ ì›ì„
    ëª¨ë“  í”„ë ˆì„ì— ë™ì¼ ìœ„ì¹˜ë¡œ í‘œì‹œí•©ë‹ˆë‹¤(íŠ¸ë ˆì¼/ë™ì  ê°±ì‹  ì œê±°).
    """
    images = sorted(glob.glob(str(img_dir / "*.png")), key=natural_key)
    if not images:
        images = sorted(glob.glob(str(img_dir / "*.jpg")), key=natural_key)
    if not images:
        images = sorted(glob.glob(str(img_dir / "*.jpeg")), key=natural_key)
    if not images:
        raise RuntimeError(f"No images (*.png|*.jpg|*.jpeg) in {img_dir}")

    first = cv2.imread(images[0])
    h, w = first.shape[:2]
    ensure_dir(out_mp4.parent)
    writer = cv2.VideoWriter(str(out_mp4), cv2.VideoWriter_fourcc(*codec), fps, (w, h))
    
    if not writer.isOpened():
        raise RuntimeError(f"VideoWriter open failed: {out_mp4}")

    # ì†Œí˜• ë²”ìœ„(ì •ê·œí™”) íŒë‹¨ì„ ìœ„í•œ ë°ì´í„° ë²”ìœ„
    cols_map = parse_joint_axis_map_from_columns(df.columns, prefer_2d=True)
    xs, ys = [], []
    if head_name in cols_map:
        cx = cols_map[head_name].get('x'); cy = cols_map[head_name].get('y')
        if cx in df.columns: xs.extend(df[cx].dropna().tolist())
        if cy in df.columns: ys.extend(df[cy].dropna().tolist())
    is_small = False
    x_min = x_max = y_min = y_max = None
    if xs and ys:
        x_min, x_max, y_min, y_max = min(xs), max(xs), min(ys), max(ys)
        if abs(x_min) <= 2.0 and abs(x_max) <= 2.0 and abs(y_min) <= 2.0 and abs(y_max) <= 2.0:
            is_small = True
        print(f"ğŸ“Š overlay ì¢Œí‘œ ë²”ìœ„(head): X({x_min:.4f}~{x_max:.4f}) Y({y_min:.4f}~{y_max:.4f}) smallRange={is_small}")

    margin = 0.1
    def scale_xy(x, y):
        if np.isnan(x) or np.isnan(y):
            return np.nan, np.nan
        try:
            xf = float(x); yf = float(y)
        except Exception:
            return np.nan, np.nan
        if is_small and (x_max is not None):
            dx = x_max - x_min if (x_max - x_min) != 0 else 1.0
            dy = y_max - y_min if (y_max - y_min) != 0 else 1.0
            x_norm = (xf - x_min) / dx
            y_norm = (yf - y_min) / dy
            sx = (margin + x_norm * (1 - 2 * margin)) * w
            sy = (margin + y_norm * (1 - 2 * margin)) * h
            return sx, sy
        return xf, yf
    
    # ê³ ì • ë¨¸ë¦¬ ì¢Œí‘œ(ì°¸ì¡° ìœ„ì¹˜) ê³„ì‚°: ì²« ìœ íš¨ ì¢Œí‘œë¥¼ ì‚¬ìš©
    ref_head = None
    if len(df) > 0:
        for i in range(len(df)):
            row0 = df.iloc[i]
            hx0, hy0, _ = get_xyc_row(row0, head_name)
            hx0, hy0 = scale_xy(hx0, hy0)
            if not (np.isnan(hx0) or np.isnan(hy0)):
                ref_head = (int(hx0), int(hy0))
                break

    # ìŠ¤íƒ ìŠ¤ ì¤‘ì•™ x ì¢Œí‘œ(í”½ì…€) ê³ ì •: ì²« ìœ íš¨ í”„ë ˆì„ì˜ L/RAnkleë¡œ ê³„ì‚°í•˜ì—¬ ì´í›„ í”„ë ˆì„ì—ì„œ ì¬ì‚¬ìš©
    stance_mid_xpix = None
    if len(df) > 0:
        for i in range(len(df)):
            rowi = df.iloc[i]
            lax, lay, _ = get_xyc_row(rowi, 'LAnkle')
            rax, ray, _ = get_xyc_row(rowi, 'RAnkle')
            if not (np.isnan(lax) or np.isnan(rax)):
                mid_x_raw = (float(lax) + float(rax)) / 2.0
                # yëŠ” ìŠ¤ì¼€ì¼ í•¨ìˆ˜ ìš”êµ¬ì‚¬í•­ ë•Œë¬¸ì— ì „ë‹¬ (ì •ê·œí™” ìŠ¤ì¼€ì¼ ì‹œ í•„ìš”)
                hxi, hyi, _ = get_xyc_row(rowi, head_name)
                y_ref = hyi if not np.isnan(hyi) else (lay if not np.isnan(lay) else (ray if not np.isnan(ray) else 0.0))
                mid_x_scaled, _ = scale_xy(mid_x_raw, y_ref)
                if not np.isnan(mid_x_scaled):
                    stance_mid_xpix = int(mid_x_scaled)
                    break

    # Nose ê¶¤ì (íŒŒë€ìƒ‰) ì €ì¥
    nose_trail = []
    
    n_img = len(images)
    n_df = len(df)
    if n_img != n_df:
        print(f"âš ï¸ í”„ë ˆì„ ê°œìˆ˜ ë¶ˆì¼ì¹˜(head): images={n_img}, overlay_rows={n_df}. ì´ë¯¸ì§€ ê¸¸ì´ì— ë§ì¶° ë Œë”ë§í•˜ë©° CSV ë¶€ì¡±ë¶„ì€ ë§ˆì§€ë§‰ ê°’ì„ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.")

    for i, p in enumerate(images):
        frame = cv2.imread(p)
        row_idx = i if i < n_df else (n_df - 1 if n_df > 0 else -1)
        row = df.iloc[row_idx] if row_idx >= 0 else None

        # --- ë¨¸ë¦¬ ê³ ì • í‘œì‹œ(ë¹¨ê°„ìƒ‰ ë¹ˆ ì›, í¬ê²Œ) ---
        if ref_head is not None:
            cv2.circle(frame, ref_head, 35, (0, 0, 255), 2)  # ë¹¨ê°„ìƒ‰ ë¹ˆ ì›(ë‘ê»˜ 2)

        # --- Nose ê¶¤ì (íŒŒë€ìƒ‰) ---
        hx, hy, _ = get_xyc_row(row, head_name)
        hx, hy = scale_xy(hx, hy)
        if not (np.isnan(hx) or np.isnan(hy)):
            pt = (int(hx), int(hy))
            nose_trail.append(pt)
            if len(nose_trail) > 50:
                nose_trail.pop(0)
            # íŒŒë€ìƒ‰ ì„ ìœ¼ë¡œ ê¶¤ì  ì—°ê²° (ì¡°ê¸ˆ í¬ë¯¸í•˜ê²Œ: ì–‡ê²Œ ê·¸ë¦° í›„ ì•ŒíŒŒ ë¸”ë Œë”©)
            overlay_blue = frame.copy()
            for j in range(1, len(nose_trail)):
                cv2.line(overlay_blue, nose_trail[j-1], nose_trail[j], (255, 0, 0), 2)
            blue_alpha = 0.70
            frame = cv2.addWeighted(overlay_blue, blue_alpha, frame, 1.0 - blue_alpha, 0)

        # --- ìŠ¤íƒ ìŠ¤ ì¤‘ì•™ ì„¸ë¡œ ì ì„ (ê³ ì •, ë” ì´˜ì´˜í•˜ê³  ì•½ê°„ ë” ì§„í•˜ê²Œ) ---
        if stance_mid_xpix is not None:
            overlay = frame.copy()
            dash_len, gap = 12, 8  # ë” ì´˜ì´˜í•˜ê²Œ
            thickness = 1
            y0 = 0
            while y0 < h:
                y1 = min(y0 + dash_len, h - 1)
                cv2.line(overlay, (stance_mid_xpix, y0), (stance_mid_xpix, y1), (0, 0, 255), thickness)
                y0 = y1 + gap
            # ì•ŒíŒŒ ì†Œí­ ìƒí–¥í•˜ì—¬ ë” ì§„í•˜ê²Œ
            alpha = 0.70
            frame = cv2.addWeighted(overlay, alpha, frame, 1.0 - alpha, 0)

        # (HUD/í…ìŠ¤íŠ¸/ê²Œì´ì§€ ì œê±°) ì˜ìƒì—ëŠ” ìˆ˜ì¹˜/ë¬¸ìë¥¼ í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

        writer.write(frame)

    writer.release()

# =========================================================
# ë©”ì¸ í•¨ìˆ˜
# =========================================================
def main():
    ap = argparse.ArgumentParser(description="Head Speed ì „ìš© ë¶„ì„ê¸°")
    ap.add_argument("-c", "--config", default=str(Path(__file__).parent.parent / "config" / "analyze.yaml"))
    args = ap.parse_args()
    
    cfg = load_cfg(Path(args.config))

    # CSV ë¶„ë¦¬: overlay(2D) vs metrics(3D)
    overlay_csv = None
    metrics_csv = None
    if "overlay_csv_path" in cfg:
        overlay_csv = Path(cfg["overlay_csv_path"]); print(f"ğŸ“Š Overlay(2D) CSV ì‚¬ìš©(head): {overlay_csv}")
    elif "csv_path" in cfg:
        overlay_csv = Path(cfg["csv_path"]); print(f"ğŸ“Š Overlay(2D) CSV (fallback)(head): {overlay_csv}")
    if "metrics_csv_path" in cfg:
        metrics_csv = Path(cfg["metrics_csv_path"]); print(f"ğŸ“Š Metrics(3D) CSV ì‚¬ìš©(head): {metrics_csv}")
    elif "csv_path" in cfg:
        metrics_csv = Path(cfg["csv_path"]); print(f"ğŸ“Š Metrics(3D) CSV (fallback)(head): {metrics_csv}")
    img_dir = Path(cfg["img_dir"])
    fps = int(cfg.get("fps", 30))
    codec = str(cfg.get("codec", "mp4v"))
    
    # ë¨¸ë¦¬ ê´€ì ˆ ì´ë¦„
    lm_cfg = cfg.get("landmarks", {}) or {}
    head_name = lm_cfg.get("head", "Nose")
    
    # ì¶œë ¥ ê²½ë¡œ (Head ì „ìš©)
    out_csv = Path(cfg["metrics_csv"]).parent / "head_speed_metrics.csv"
    out_mp4 = Path(cfg["overlay_mp4"]).parent / "head_speed_analysis.mp4"

    # 1) CSV ë¡œë“œ
    if metrics_csv is None or not metrics_csv.exists():
        raise RuntimeError("metrics_csv_path ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    if overlay_csv is None or not overlay_csv.exists():
        raise RuntimeError("overlay_csv_path ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    df_metrics = pd.read_csv(metrics_csv)
    df_overlay = pd.read_csv(overlay_csv)
    # ì…ë ¥ í¬ê¸° ë“± ë¶ˆí•„ìš” ë¡œê·¸ ì œê±°

    # 2) ì„íŒ©íŠ¸ ì „ ë¨¸ë¦¬ ì›€ì§ì„(%) ê³„ì‚° (ìš”ì²­ ì‚¬ì–‘)
    pre = compute_head_movement_preimpact(df_metrics, head_name, skip_ratio=0.2)

    # 3) ê²°ê³¼ ì €ì¥: ìš”ì²­ëœ ì»¬ëŸ¼ë§Œ ì €ì¥
    N = len(df_metrics)
    nose_x = _get_axis_series(df_metrics, head_name, 'x', prefer_2d=False)
    nose_y = _get_axis_series(df_metrics, head_name, 'y', prefer_2d=False)
    nose_z = _get_axis_series(df_metrics, head_name, 'z', prefer_2d=False)
    lw_x = _get_axis_series(df_metrics, 'LWrist', 'x', prefer_2d=False)
    lw_y = _get_axis_series(df_metrics, 'LWrist', 'y', prefer_2d=False)
    lw_z = _get_axis_series(df_metrics, 'LWrist', 'z', prefer_2d=False)
    rw_x = _get_axis_series(df_metrics, 'RWrist', 'x', prefer_2d=False)
    rw_y = _get_axis_series(df_metrics, 'RWrist', 'y', prefer_2d=False)
    rw_z = _get_axis_series(df_metrics, 'RWrist', 'z', prefer_2d=False)

    metrics = pd.DataFrame({
        'frame': range(N),
        # ë¨¸ë¦¬(Nose) ì¢Œí‘œ
        'nose_x': nose_x,
        'nose_y': nose_y,
        'nose_z': nose_z,
        # ì†ëª© ì¢Œí‘œ (ì¢Œ/ìš°)
        'lwrist_x': lw_x,
        'lwrist_y': lw_y,
        'lwrist_z': lw_z,
        'rwrist_x': rw_x,
        'rwrist_y': rw_y,
        'rwrist_z': rw_z,
        # í”„ë ˆì„ë³„ ë³€ìœ„ ê°’ë“¤ (ì–´ë“œë ˆìŠ¤ ëŒ€ë¹„)
        'head_dx_addr': pre['head_dx'],
        'head_dy_addr': pre['head_dy'],
        'head_disp_addr': pre['head_disp'],
        'head_disp_pct': pre['head_disp_pct'],
    })
    
    ensure_dir(out_csv.parent)
    metrics.to_csv(out_csv, index=False)
    # ì €ì¥ ë¡œê·¸ ì¶œë ¥ ìƒëµ (ìš”ì²­ì— ë”°ë¼ ì½˜ì†”ì€ ìµœì†Œí™”)

    # 4) ë¹„ë””ì˜¤ ì˜¤ë²„ë ˆì´ (ì´ì „ ë™ì‘ ìœ ì§€)
    # 2D ìŠ¤ë¬´ë”© ì ìš© ê°€ëŠ¥
    draw_cfg = cfg.get('draw', {}) or {}
    smooth_cfg = (draw_cfg.get('smoothing') or {}) if isinstance(draw_cfg.get('smoothing'), dict) else {}
    if smooth_cfg.get('enabled', False):
        method = smooth_cfg.get('method', 'ema')
        window = int(smooth_cfg.get('window', 5))
        alpha = float(smooth_cfg.get('alpha', 0.2))
        gaussian_sigma = smooth_cfg.get('gaussian_sigma')
        hampel_sigma = smooth_cfg.get('hampel_sigma', 3.0)
        oneeuro_min_cutoff = smooth_cfg.get('oneeuro_min_cutoff', 1.0)
        oneeuro_beta = smooth_cfg.get('oneeuro_beta', 0.007)
        oneeuro_d_cutoff = smooth_cfg.get('oneeuro_d_cutoff', 1.0)
        df_overlay_sm = smooth_df_2d(
            df_overlay,
            prefer_2d=True,
            method=method,
            window=window,
            alpha=alpha,
            fps=fps,
            gaussian_sigma=gaussian_sigma,
            hampel_sigma=hampel_sigma,
            oneeuro_min_cutoff=oneeuro_min_cutoff,
            oneeuro_beta=oneeuro_beta,
            oneeuro_d_cutoff=oneeuro_d_cutoff,
        )
    else:
        df_overlay_sm = df_overlay

    # ì˜¤ë²„ë ˆì´ì— í•„ìš”í•œ ìµœì†Œ ë©”íŠ¸ë¦­ ê³„ì‚°(í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ ì¶©ì¡±)
    head_pts, head_speed, head_deviations, stability_metrics, head_unit = compute_head_speed_3d(df_metrics, head_name, fps)
    overlay_head_video(img_dir, df_overlay_sm, head_pts, head_speed, head_deviations,
                       stability_metrics, head_unit, head_name, out_mp4, fps, codec)
    
    # 5) ì½˜ì†” ì¶œë ¥: ìš”ì²­í•œ 4ì¤„ë§Œ ì¶œë ¥
    print(f"ì„íŒ©íŠ¸ í”„ë ˆì„: {pre['impact_frame']} (ì„ íƒ ì†ëª©: {pre['selected_wrist']})")
    print(f"   ìµœëŒ€ ë³€ìœ„: {pre['disp_max_pct']:.2f}% (ìŠ¤íƒ ìŠ¤ í­ ëŒ€ë¹„)")
    print(f"   RMS ë³€ìœ„: {pre['disp_rms_pct']:.2f}% (ìŠ¤íƒ ìŠ¤ í­ ëŒ€ë¹„)")
    print(f"   íŒì •: {pre['grade']}")

if __name__ == "__main__":
    main()


def run_from_context(ctx: dict):
    """Programmatic runner for head_speed module.

    Accepts a ctx dict with optional keys:
      - dest_dir, job_id, wide2 (overlay DF), wide3 (metrics DF), img_dir, fps, codec, draw

    Returns a JSON-serializable dict with keys:
      - metrics_csv: path or None
      - overlay_mp4: path or None
      - summary: small dict with numeric summaries
    """
    try:
        dest = Path(ctx.get('dest_dir', '.'))
        job_id = str(ctx.get('job_id', ctx.get('job', 'job')))
        fps = int(ctx.get('fps', 30))
        wide3 = ctx.get('wide3')
        wide2 = ctx.get('wide2')
        img_dir = Path(ctx.get('img_dir', dest))
        codec = str(ctx.get('codec', 'mp4v'))
        ensure_dir(dest)

        out = {}

        # Metrics (3D)
        if wide3 is not None:
            try:
                pre = compute_head_movement_preimpact(wide3, head_joint='Nose', skip_ratio=0.2)
            except Exception:
                pre = None

            try:
                pts, head_speed_arr, head_deviations, stability_metrics, head_unit = compute_head_speed_3d(wide3, landmark='Nose', fps=fps)
            except Exception as e:
                return {'error': f'head_speed metrics failure: {e}'}

            try:
                # Build a conservative metrics DataFrame similar to main()
                N = len(wide3)
                nose_x = _get_axis_series(wide3, 'Nose', 'x', prefer_2d=False)
                nose_y = _get_axis_series(wide3, 'Nose', 'y', prefer_2d=False)
                nose_z = _get_axis_series(wide3, 'Nose', 'z', prefer_2d=False)

                lw_x = _get_axis_series(wide3, 'LWrist', 'x', prefer_2d=False)
                lw_y = _get_axis_series(wide3, 'LWrist', 'y', prefer_2d=False)
                lw_z = _get_axis_series(wide3, 'LWrist', 'z', prefer_2d=False)
                rw_x = _get_axis_series(wide3, 'RWrist', 'x', prefer_2d=False)
                rw_y = _get_axis_series(wide3, 'RWrist', 'y', prefer_2d=False)
                rw_z = _get_axis_series(wide3, 'RWrist', 'z', prefer_2d=False)

                metrics_df = pd.DataFrame({
                    'frame': list(range(N)),
                    'nose_x': nose_x,
                    'nose_y': nose_y,
                    'nose_z': nose_z,
                    'lwrist_x': lw_x,
                    'lwrist_y': lw_y,
                    'lwrist_z': lw_z,
                    'rwrist_x': rw_x,
                    'rwrist_y': rw_y,
                    'rwrist_z': rw_z,
                    'head_dx_addr': pre['head_dx'] if pre is not None else np.full(N, np.nan),
                    'head_dy_addr': pre['head_dy'] if pre is not None else np.full(N, np.nan),
                    'head_disp_addr': pre['head_disp'] if pre is not None else np.full(N, np.nan),
                    'head_disp_pct': pre['head_disp_pct'] if pre is not None else np.full(N, np.nan),
                })

                metrics_csv = dest / f"{job_id}_head_speed_metrics.csv"
                ensure_dir(metrics_csv.parent)
                metrics_df.to_csv(metrics_csv, index=False)
                out['metrics_csv'] = str(metrics_csv)
                out['summary'] = {
                    'impact_frame': int(pre['impact_frame']) if pre is not None and 'impact_frame' in pre else None,
                    'disp_max_pct': float(pre['disp_max_pct']) if pre is not None and not np.isnan(pre.get('disp_max_pct', np.nan)) else None,
                    'disp_rms_pct': float(pre['disp_rms_pct']) if pre is not None and not np.isnan(pre.get('disp_rms_pct', np.nan)) else None,
                    'grade': pre.get('grade') if pre is not None else None,
                    'mean_head_speed': float(np.nanmean(head_speed_arr)) if len(head_speed_arr) > 0 else None,
                    'max_head_speed': float(np.nanmax(head_speed_arr)) if len(head_speed_arr) > 0 else None,
                    'unit': head_unit,
                }
            except Exception as e:
                out['metrics_error'] = str(e)
        else:
            out['metrics_csv'] = None

        # Overlay (2D)
        overlay_path = dest / f"{job_id}_head_speed_overlay.mp4"
        try:
            if wide2 is not None:
                # optional smoothing from ctx.draw.smoothing
                draw_cfg = ctx.get('draw', {}) or {}
                smooth_cfg = (draw_cfg.get('smoothing') or {}) if isinstance(draw_cfg.get('smoothing'), dict) else {}
                if smooth_cfg.get('enabled', False):
                    method = smooth_cfg.get('method', 'ema')
                    window = int(smooth_cfg.get('window', 5))
                    alpha = float(smooth_cfg.get('alpha', 0.2))
                    gaussian_sigma = smooth_cfg.get('gaussian_sigma')
                    hampel_sigma = smooth_cfg.get('hampel_sigma', 3.0)
                    oneeuro_min_cutoff = smooth_cfg.get('oneeuro_min_cutoff', 1.0)
                    oneeuro_beta = smooth_cfg.get('oneeuro_beta', 0.007)
                    oneeuro_d_cutoff = smooth_cfg.get('oneeuro_d_cutoff', 1.0)
                    df_overlay_sm = smooth_df_2d(
                        wide2,
                        prefer_2d=True,
                        method=method,
                        window=window,
                        alpha=alpha,
                        fps=fps,
                        gaussian_sigma=gaussian_sigma,
                        hampel_sigma=hampel_sigma,
                        oneeuro_min_cutoff=oneeuro_min_cutoff,
                        oneeuro_beta=oneeuro_beta,
                        oneeuro_d_cutoff=oneeuro_d_cutoff,
                    )
                else:
                    df_overlay_sm = wide2

                # compute head pts if available
                try:
                    head_pts, _, _, _, _ = compute_head_speed_3d(wide3, landmark='Nose', fps=fps) if wide3 is not None else (np.zeros((len(df_overlay_sm), 3)), np.zeros(len(df_overlay_sm)), np.zeros(len(df_overlay_sm)), {}, 'mm/frame')
                except Exception:
                    head_pts = np.zeros((len(df_overlay_sm), 3))

                overlay_head_video(img_dir, df_overlay_sm, head_pts, out.get('summary', {}).get('mean_head_speed', np.zeros(len(df_overlay_sm))),
                                   out.get('summary', {}).get('mean_head_speed', np.zeros(len(df_overlay_sm))),
                                   out.get('summary', {}) or {}, out.get('summary', {}).get('unit', 'mm/frame'), 'Nose', overlay_path, fps, codec)
                out['overlay_mp4'] = str(overlay_path)
        except Exception as e:
            out.setdefault('overlay_error', str(e))

        return out
    except Exception as e:
        return {'error': str(e)}