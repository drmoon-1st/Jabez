# src/com_speed.py
# -*- coding: utf-8 -*-
"""
COM (Center of Mass) Speed ì „ìš© ë¶„ì„ê¸°

ì¸ì²´ì˜ ë¬´ê²Œì¤‘ì‹¬(COM) ì´ë™ ì†ë„ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ ë„êµ¬ì…ë‹ˆë‹¤.

COM(ë¬´ê²Œì¤‘ì‹¬) ë¶„ì„ì˜ ì¤‘ìš”ì„±:
ê³¨í”„ ìŠ¤ìœ™ì—ì„œ COMì˜ ì›€ì§ì„ì€ ì „ì²´ì ì¸ ëª¸ì˜ ê· í˜•ê³¼ íŒŒì›Œ ì „ë‹¬ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
ì ì ˆí•œ COM ì´ë™ì€ íš¨ìœ¨ì ì¸ ì—ë„ˆì§€ ì „ë‹¬ê³¼ ì•ˆì •ì ì¸ ìŠ¤ìœ™ì„ ë§Œë“­ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. COM ìœ„ì¹˜ ê³„ì‚°
   - ëª¨ë“  ê°ì§€ëœ ê´€ì ˆì˜ 3D ì¢Œí‘œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¬´ê²Œì¤‘ì‹¬ ê³„ì‚°
   - ê° ê´€ì ˆì— ë™ì¼í•œ ê°€ì¤‘ì¹˜ ì ìš© (ì‹ ë¢°ë„ ì»¬ëŸ¼ ì—†ìŒ)
   - ì‹¤ì‹œê°„ COM ìœ„ì¹˜ ì¶”ì 

2. COM Speed ë¶„ì„  
   - í”„ë ˆì„ ê°„ COM ì´ë™ ê±°ë¦¬ ê³„ì‚° (mm/s ë˜ëŠ” mm/frame)
   - ìŠ¤ìœ™ ë‹¨ê³„ë³„ COM ì†ë„ ë³€í™” ë¶„ì„
   - ìµœëŒ€/í‰ê·  COM ì†ë„ ì¸¡ì •

3. ì‹œê°í™” ê¸°ëŠ¥
   - COM ìœ„ì¹˜ë¥¼ ë‹¤ì´ì•„ëª¬ë“œë¡œ í‘œì‹œ
   - COM ì´ë™ ê¶¤ì  í‘œì‹œ (ìµœê·¼ 50í”„ë ˆì„)  
   - ì „ì‹  ìŠ¤ì¼ˆë ˆí†¤ê³¼ COMì˜ ê´€ê³„ ì‹œê°í™”
   - ì‹¤ì‹œê°„ ì†ë„ ë° í†µê³„ ì •ë³´ í‘œì‹œ

ë°ì´í„° í˜•ì‹: 
   - CSV ì»¬ëŸ¼: Joint__x, Joint__y, Joint__z (ë”ë¸” ì–¸ë”ìŠ¤ì½”ì–´)
   - ì‹ ë¢°ë„ ì»¬ëŸ¼(_c) ì—†ìŒ - ëª¨ë“  ê´€ì ˆ ë™ì¼ ê°€ì¤‘ì¹˜
"""
import argparse
from pathlib import Path
import pandas as pd
import numpy as np
import cv2
import glob
from typing import Optional, Tuple, Dict, List, Union

try:
    import yaml
except ImportError:
    yaml = None

# ê³µí†µ ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸
import sys
sys.path.append(str(Path(__file__).parent))
from utils_io import natural_key, ensure_dir

# =========================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (__x, __y, __z í˜•ì‹ ì „ìš©)
# =========================================================
def get_xyz_cols(df: pd.DataFrame, name: str):
    """ê´€ì ˆì˜ 3D ì¢Œí‘œ ì»¬ëŸ¼ ì¶”ì¶œ (__x, __y, __z í˜•ì‹)"""
    # ë” ìœ ì—°í•œ ì»¬ëŸ¼ëª… ë§¤ì¹­: '__x', '_X3D', '_X' ë“± ë‹¤ì–‘í•œ í˜•ì‹ì„ ì§€ì›
    cols_map = parse_joint_axis_map_from_columns(df.columns)
    if name in cols_map and all(axis in cols_map[name] for axis in ('x', 'y', 'z')):
        x_col = cols_map[name]['x']
        y_col = cols_map[name]['y']
        z_col = cols_map[name]['z']
        return df[[x_col, y_col, z_col]].to_numpy(float)
    return None


def parse_joint_axis_map_from_columns(columns, prefer_2d: bool = False) -> Dict[str, Dict[str, str]]:
    """ì£¼ì–´ì§„ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ì—ì„œ ê´€ì ˆëª…ê³¼ axis ì»¬ëŸ¼ëª…ì„ ë§¤í•‘í•©ë‹ˆë‹¤.

    ë°˜í™˜ê°’ ì˜ˆì‹œ: {'Nose': {'x':'Nose__x','y':'Nose__y','z':'Nose__z'}, ...}

    ì§€ì›í•˜ëŠ” íŒ¨í„´:
      - Joint__x, Joint__y, Joint__z
      - Joint_X3D, Joint_Y3D, Joint_Z3D
      - Joint_X, Joint_Y, Joint_Z
      - Joint_X_3D ë“± ì¼ë¶€ ë³€í˜•
    """
    cols = list(columns)
    mapping: Dict[str, Dict[str, str]] = {}

    # í›„ë³´ íŒ¨í„´ì„ ë‚˜ì—´ (ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ê²ƒë¶€í„°)
    if prefer_2d:
        # 2D ì¢Œí‘œ ìš°ì„  (ì†Œë¬¸ì _x/_y), ê·¸ ë‹¤ìŒ ì¼ë°˜/3D ë³€í˜•
        axis_patterns = [
            ('_x', '_y', '_z'),
            ('__x', '__y', '__z'),
            ('_X', '_Y', '_Z'),
            ('_X3D', '_Y3D', '_Z3D'),
        ]
    else:
        # 3D ì¢Œí‘œ ìš°ì„  (X3D), ê·¸ ë‹¤ìŒ ì¼ë°˜/2D
        axis_patterns = [
            ('_X3D', '_Y3D', '_Z3D'),
            ('__x', '__y', '__z'),
            ('_X', '_Y', '_Z'),
            ('_x', '_y', '_z'),
        ]

    # ë¹ ë¥¸ íƒìƒ‰ì„ ìœ„í•´ ì»¬ëŸ¼ ì„¸íŠ¸ë¥¼ ì¤€ë¹„
    col_set = set(cols)

    # ì‹œë„: ê° ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ ê´€ì ˆëª…ì„ ì¶”ì •
    for col in cols:
        # skip columns that clearly aren't joints (e.g., frame, time)
        if col.lower() in ('frame', 'time', 'timestamp'):
            continue
        for x_pat, y_pat, z_pat in axis_patterns:
            if col.endswith(x_pat):
                joint = col[:-len(x_pat)]
                x_col = joint + x_pat
                y_col = joint + y_pat
                z_col = joint + z_pat
                if x_col in col_set and y_col in col_set:
                    # z may be missing for 2D datasets
                    mapping.setdefault(joint, {})['x'] = x_col
                    mapping.setdefault(joint, {})['y'] = y_col
                    if z_col in col_set:
                        mapping[joint]['z'] = z_col
                    break

    # ì¶”ê°€ íŒ¨í„´: CamelCase X/Y/Z ì ‘ë¯¸ì‚¬ like Nose_X3D
    # (already handled by '_X3D' pattern)

    return mapping

def get_xyc_row(row: pd.Series, name: str):
    """ê´€ì ˆì˜ 2D ì¢Œí‘œ ì¶”ì¶œ (ì‹œê°í™”ìš©, cëŠ” ì‚¬ìš© ì•ˆí•¨)"""
    # row.indexì— ìˆëŠ” ì»¬ëŸ¼ ì´ë¦„ë“¤ì—ì„œ í•´ë‹¹ ê´€ì ˆì˜ x/y ì»¬ëŸ¼ëª…ì„ ìœ ì—°í•˜ê²Œ ì°¾ì•„ ì½ìŠµë‹ˆë‹¤.
    cols_map = parse_joint_axis_map_from_columns(row.index, prefer_2d=True)
    x = np.nan; y = np.nan
    if name in cols_map:
        if 'x' in cols_map[name]:
            x = row.get(cols_map[name]['x'], np.nan)
        if 'y' in cols_map[name]:
            y = row.get(cols_map[name]['y'], np.nan)
    else:
        # ê°€ìƒ ê´€ì ˆ ìƒì„± (CSVì— Neck/MidHipê°€ ì—†ëŠ” ê²½ìš° L/R í‰ê· ìœ¼ë¡œ ìƒì„±)
        if name == 'Neck' and 'LShoulder' in cols_map and 'RShoulder' in cols_map:
            lx = row.get(cols_map['LShoulder'].get('x', ''), np.nan)
            ly = row.get(cols_map['LShoulder'].get('y', ''), np.nan)
            rx = row.get(cols_map['RShoulder'].get('x', ''), np.nan)
            ry = row.get(cols_map['RShoulder'].get('y', ''), np.nan)
            if not (np.isnan(lx) or np.isnan(ly) or np.isnan(rx) or np.isnan(ry)):
                x = (float(lx) + float(rx)) / 2.0
                y = (float(ly) + float(ry)) / 2.0
        elif name == 'MidHip' and 'LHip' in cols_map and 'RHip' in cols_map:
            lx = row.get(cols_map['LHip'].get('x', ''), np.nan)
            ly = row.get(cols_map['LHip'].get('y', ''), np.nan)
            rx = row.get(cols_map['RHip'].get('x', ''), np.nan)
            ry = row.get(cols_map['RHip'].get('y', ''), np.nan)
            if not (np.isnan(lx) or np.isnan(ly) or np.isnan(rx) or np.isnan(ry)):
                x = (float(lx) + float(rx)) / 2.0
                y = (float(ly) + float(ry)) / 2.0
    c = 1.0  # ì‹ ë¢°ë„ ì»¬ëŸ¼ì´ ì—†ìœ¼ë¯€ë¡œ ê¸°ë³¸ê°’ 1.0
    
    return x, y, c

def speed_3d(points_xyz: np.ndarray, fps):
    """
    3D ê³µê°„ì—ì„œì˜ ì†ë„ ê³„ì‚°
    
    ì—°ì†ëœ 3D ì¢Œí‘œ í¬ì¸íŠ¸ë“¤ ì‚¬ì´ì˜ ìœ í´ë¦¬ë“œ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ì—¬ 
    í”„ë ˆì„ë‹¹ ë˜ëŠ” ì´ˆë‹¹ ì´ë™ ì†ë„ë¥¼ êµ¬í•©ë‹ˆë‹¤.
    
    Args:
        points_xyz (np.ndarray): (N, 3) í˜•íƒœì˜ 3D ì¢Œí‘œ ë°°ì—´ (mm ë‹¨ìœ„)
        fps (float/int/None): í”„ë ˆì„ ë ˆì´íŠ¸. Noneì´ë©´ mm/frame, ê°’ì´ ìˆìœ¼ë©´ mm/s
        
    Returns:
        tuple: (ì†ë„ ë°°ì—´, ë‹¨ìœ„ ë¬¸ìì—´)
    """
    N = len(points_xyz)
    v = np.full(N, np.nan, dtype=float)
    for i in range(1, N):
        a, b = points_xyz[i-1], points_xyz[i]
        if np.any(np.isnan(a)) or np.any(np.isnan(b)):
            continue
        v[i] = float(np.linalg.norm(b - a))
    if fps and fps > 0:
        v = v * float(fps)
        unit = "mm/s"
    else:
        unit = "mm/frame"
    v = pd.Series(v).fillna(method="ffill").fillna(0).to_numpy()
    return v, unit

def load_cfg(p: Path):
    if p.suffix.lower() in (".yml", ".yaml"):
        if yaml is None:
            raise RuntimeError("pip install pyyaml")
        return yaml.safe_load(p.read_text(encoding="utf-8"))
    raise ValueError("Use YAML for analyze config.")

# =========================================================
# 2D ì¢Œí‘œ ìŠ¤ë¬´ë”© ìœ í‹¸ë¦¬í‹° (ì í”„ ì œí•œ ì œê±°, ëŒ€ì²´ í•„í„° ì¶”ê°€)
# =========================================================
def smooth_jump(arr: np.ndarray, k: int = 6, window: int = 5) -> np.ndarray:
    """
    ê°‘ì‘ìŠ¤ëŸ½ê²Œ íŠ€ëŠ” ê°’(outlier jump)ì„ ì™„í™”.
    - delta(ì¦ë¶„)ê°€ ì¤‘ì•™ê°’+KÂ·MAD ì´ìƒì´ë©´ â†’ ì´ì „ ì´ë™ í‰ê· ìœ¼ë¡œ ëŒ€ì²´
    """
    arr = np.asarray(arr, dtype=float)
    out = arr.copy()

    deltas = np.diff(arr, prepend=arr[0])
    abs_deltas = np.abs(deltas)

    med = np.median(abs_deltas)
    mad = np.median(np.abs(abs_deltas - med))
    thresh = med + k * 1.4826 * mad

    for i in range(1, len(arr)):
        if abs_deltas[i] > thresh:  # ì í”„ ê°ì§€
            start = max(0, i - window)
            mean_delta = np.mean(deltas[start:i])
            out[i] = out[i-1] + mean_delta  # ì¦ê°€ë¶„ í‰ê· ìœ¼ë¡œ ëŒ€ì²´
    return out


def _ema(series: pd.Series, alpha: float) -> pd.Series:
    a = alpha if alpha is not None else 0.2
    a = 0.2 if a <= 0 or a >= 1 else a
    return series.ewm(alpha=a, adjust=False).mean()

def _moving(series: pd.Series, window: int) -> pd.Series:
    w = max(int(window or 5), 1)
    return series.rolling(window=w, min_periods=1).mean()

def _median(series: pd.Series, window: int) -> pd.Series:
    w = max(int(window or 5), 1)
    return series.rolling(window=w, min_periods=1).median()

def _gaussian_kernel(window: int, sigma: Optional[float] = None) -> np.ndarray:
    w = int(window or 5)
    if w % 2 == 0:
        w += 1  # í™€ìˆ˜ ê°•ì œ
    if w < 3:
        w = 3
    # í‘œì¤€í¸ì°¨ ê¸°ë³¸ê°’: ì°½ í¬ê¸°ì˜ 1/3
    s = float(sigma) if sigma and sigma > 0 else max(w / 3.0, 1.0)
    r = w // 2
    x = np.arange(-r, r + 1)
    k = np.exp(-0.5 * (x / s) ** 2)
    k /= np.sum(k)
    return k

def _gaussian(series: pd.Series, window: int, sigma: Optional[float]) -> pd.Series:
    vals = series.to_numpy(dtype=float, copy=True)
    mask = np.isnan(vals)
    # ë‚´ë¶€ ê³„ì‚°ì„ ìœ„í•´ ì„ì‹œë¡œ NaN ë³´ê°„ (ì–‘ëì€ ffill/bfill)
    tmp = pd.Series(vals).fillna(method='ffill').fillna(method='bfill').to_numpy()
    k = _gaussian_kernel(window, sigma)
    sm = np.convolve(tmp, k, mode='same')
    sm[mask] = np.nan  # ì›ë˜ NaN ìœ„ì¹˜ëŠ” ìœ ì§€
    return pd.Series(sm, index=series.index)

def _hampel(series: pd.Series, window: int, n_sigma: float = 3.0) -> pd.Series:
    """Hampel í•„í„°: ë¡¤ë§ ì¤‘ì•™ê°’ê³¼ MADë¡œ ì´ìƒì¹˜ë¥¼ ì¤‘ì•™ê°’ìœ¼ë¡œ êµì²´"""
    w = max(int(window or 7), 1)
    if w % 2 == 0:
        w += 1
    x = series.astype(float)
    med = x.rolling(window=w, center=True, min_periods=1).median()
    diff = (x - med).abs()
    mad = diff.rolling(window=w, center=True, min_periods=1).median()
    # 1.4826 * MAD ~= í‘œì¤€í¸ì°¨
    thresh = 1.4826 * mad * float(n_sigma if n_sigma and n_sigma > 0 else 3.0)
    out = x.copy()
    out[diff > thresh] = med[diff > thresh]
    return out

def _one_euro(series: pd.Series, fps: float, min_cutoff: float = 1.0, beta: float = 0.007, d_cutoff: float = 1.0) -> pd.Series:
    """One Euro Filter (Casiez et al.) êµ¬í˜„. NaNì€ ìœ ì§€í•©ë‹ˆë‹¤."""
    vals = series.to_numpy(dtype=float, copy=True)
    mask = np.isnan(vals)
    # ë‚´ë¶€ ê³„ì‚°ìš© ì„ì‹œ ë³´ê°„
    tmp = pd.Series(vals).fillna(method='ffill').fillna(method='bfill').to_numpy()
    dt = 1.0 / float(fps) if fps and fps > 0 else 1.0

    def alpha(cutoff):
        tau = 1.0 / (2.0 * np.pi * float(cutoff)) if cutoff and cutoff > 0 else 1.0
        return 1.0 / (1.0 + tau / dt)

    x_hat = np.zeros_like(tmp)
    dx_hat = 0.0
    a_d = alpha(d_cutoff)
    x_hat[0] = tmp[0]
    prev_x = tmp[0]

    for i in range(1, len(tmp)):
        x = tmp[i]
        # íŒŒìƒê°’ í•„í„°ë§
        dx = (x - prev_x) / dt
        dx_hat = a_d * dx + (1 - a_d) * dx_hat
        cutoff = float(min_cutoff) + float(beta) * abs(dx_hat)
        a = alpha(cutoff)
        x_hat[i] = a * x + (1 - a) * x_hat[i - 1]
        prev_x = x

    x_hat[mask] = np.nan
    return pd.Series(x_hat, index=series.index)

def suppress_jumps(arr, k: float = 5.0):
    """
    ì¢Œí‘œ ì‹œí€€ìŠ¤ì—ì„œ ìˆœê°„ì ì¸ ì í”„(outlier jump)ë¥¼ ì–µì œí•©ë‹ˆë‹¤.
    
    Args:
        arr (array-like): ì…ë ¥ ì¢Œí‘œ ë°°ì—´ (float)
        k (float): ì´ìƒì¹˜ íŒì • ë°°ìˆ˜ (ê¸°ë³¸=5.0)
        
    Returns:
        np.ndarray: ì í”„ ì–µì œëœ ì¢Œí‘œ ë°°ì—´
    """
    arr = np.asarray(arr, dtype=float)
    out = arr.copy()

    # í”„ë ˆì„ ê°„ ë³€í™”ëŸ‰
    deltas = np.diff(arr, prepend=arr[0])
    abs_deltas = np.abs(deltas)

    # MAD ê¸°ë°˜ ì„ê³„ê°’ ê³„ì‚°
    med = np.median(abs_deltas)
    mad = np.median(np.abs(abs_deltas - med))
    thresh = med + k * 1.4826 * mad   # outlier ê¸°ì¤€

    for i in range(1, len(arr)):
        if abs_deltas[i] > thresh:   # ì í”„ ë°œìƒ
            # ì§ì „ ê°’ + ì„ê³„ê°’ìœ¼ë¡œ ì œí•œ
            out[i] = out[i-1] + np.sign(deltas[i]) * thresh
    return out


def smooth_df_2d(
    df: pd.DataFrame,
    prefer_2d: bool = True,
    method: str = 'ema',
    window: int = 5,
    alpha: float = 0.2,
    fps: Optional[float] = None,
    gaussian_sigma: Optional[float] = None,
    hampel_sigma: Optional[float] = 3.0,
    oneeuro_min_cutoff: float = 1.0,
    oneeuro_beta: float = 0.007,
    oneeuro_d_cutoff: float = 1.0,
) -> pd.DataFrame:
    cols_map = parse_joint_axis_map_from_columns(df.columns, prefer_2d=prefer_2d)
    out = df.copy()
    m = (method or 'ema').lower()

    for j, axes in cols_map.items():
        cx, cy = axes.get('x'), axes.get('y')
        if not cx or not cy or cx not in out.columns or cy not in out.columns:
            continue

        # ì›ë³¸ ì‹œë¦¬ì¦ˆ
        sx = out[cx].astype(float)
        sy = out[cy].astype(float)

        # NaN ë³´ê°„
        sx = sx.interpolate(method='linear', limit_direction='both').fillna(method='ffill').fillna(method='bfill')
        sy = sy.interpolate(method='linear', limit_direction='both').fillna(method='ffill').fillna(method='bfill')

        # ğŸš¨ ì í”„ ì–µì œ ì¶”ê°€
        sx_vals = suppress_jumps(sx.to_numpy(), k=5.0)
        sy_vals = suppress_jumps(sy.to_numpy(), k=5.0)
        sx = pd.Series(sx_vals, index=sx.index)
        sy = pd.Series(sy_vals, index=sy.index)

        # ì´í›„ ê¸°ì¡´ smoothing
        if m == 'moving':
            out[cx] = _moving(sx, window)
            out[cy] = _moving(sy, window)
        elif m == 'median':
            out[cx] = _median(sx, window)
            out[cy] = _median(sy, window)
        elif m == 'gaussian':
            out[cx] = _gaussian(sx, window, gaussian_sigma)
            out[cy] = _gaussian(sy, window, gaussian_sigma)
        elif m == 'hampel_ema':
            hx = _hampel(sx, window, hampel_sigma)
            hy = _hampel(sy, window, hampel_sigma)
            out[cx] = _ema(hx, alpha)
            out[cy] = _ema(hy, alpha)
        elif m == 'oneeuro':
            out[cx] = _one_euro(sx, fps=fps, min_cutoff=oneeuro_min_cutoff, beta=oneeuro_beta, d_cutoff=oneeuro_d_cutoff)
            out[cy] = _one_euro(sy, fps=fps, min_cutoff=oneeuro_min_cutoff, beta=oneeuro_beta, d_cutoff=oneeuro_d_cutoff)
        else:  # default ema
            out[cx] = _ema(sx, alpha)
            out[cy] = _ema(sy, alpha)

    print(f"âœ¨ 2D ìŠ¤ë¬´ë”© ì ìš© (method={m}, window={window}, alpha={alpha}, jump_filter=ON)")
    return out

# =========================================================
# COM ì „ìš© ê³„ì‚° í•¨ìˆ˜ (__x, __y, __z í˜•ì‹ì— ìµœì í™”)
# =========================================================
def compute_com_points_3d(df: pd.DataFrame, ignore_joints: Optional[set] = None):
    """
    í”„ë ˆì„ë³„ 3D ë¬´ê²Œì¤‘ì‹¬(COM) ê³„ì‚°
    
    CSVì˜ __x, __y, __z ì»¬ëŸ¼ì„ ì‚¬ìš©í•˜ì—¬ ë¬´ê²Œì¤‘ì‹¬ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    ì‹ ë¢°ë„(_c) ì»¬ëŸ¼ì´ ì—†ìœ¼ë¯€ë¡œ ëª¨ë“  ê´€ì ˆì— ë™ì¼í•œ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•©ë‹ˆë‹¤.
    
    Args:
        df (pd.DataFrame): ê´€ì ˆ ì¢Œí‘œ ë°ì´í„°í”„ë ˆì„
        
    Returns:
        np.ndarray: (N, 3) í˜•íƒœì˜ COM ì¢Œí‘œ ì‹œí€€ìŠ¤ (mm ë‹¨ìœ„)
    """
    # ì»¬ëŸ¼ ë§¤í•‘ì„ í†µí•´ ì‚¬ìš© ê°€ëŠ¥í•œ ê´€ì ˆ ë° x/y/z ì»¬ëŸ¼ëª…ì„ ì°¾ìŒ
    cols_map = parse_joint_axis_map_from_columns(df.columns)
    ignore = set(ignore_joints or [])
    valid_joints = [j for j, axes in cols_map.items() if j not in ignore and all(a in axes for a in ('x', 'y', 'z'))]
    
    print(f"ğŸ¯ COM ê³„ì‚°ìš© ê´€ì ˆ: {valid_joints} (ì´ {len(valid_joints)}ê°œ)")
    
    N = len(df)
    com = np.full((N, 3), np.nan, dtype=float)
    
    for i in range(N):
        valid_coords = []
        
        for joint in valid_joints:
            cols = cols_map[joint]
            x_val = df.loc[i, cols['x']]
            y_val = df.loc[i, cols['y']]
            z_val = df.loc[i, cols['z']]
            
            # NaNì´ ì•„ë‹Œ ìœ íš¨í•œ ì¢Œí‘œë§Œ ì‚¬ìš©
            if not (np.isnan(x_val) or np.isnan(y_val) or np.isnan(z_val)):
                valid_coords.append([x_val, y_val, z_val])
        
        # ìœ íš¨í•œ ì¢Œí‘œê°€ ìˆìœ¼ë©´ í‰ê·  ê³„ì‚° (ë™ì¼ ê°€ì¤‘ì¹˜)
        if valid_coords:
            com[i] = np.mean(valid_coords, axis=0)
    
    return com


def compute_com_points_2d(df: pd.DataFrame, ignore_joints: Optional[set] = None):
    """
    í”„ë ˆì„ë³„ 2D ë¬´ê²Œì¤‘ì‹¬(COM) ê³„ì‚°

    ì„¤ëª…:
    - ì˜¤ë²„ë ˆì´ìš© CSV(2D ì¢Œí‘œ)ê°€ ë³„ë„ë¡œ ì£¼ì–´ì§ˆ ë•Œ, í™”ë©´ì— ê·¸ë¦´ COM ìœ„ì¹˜ëŠ”
      í•´ë‹¹ 2D ì¢Œí‘œë“¤ì˜ í‰ê· ìœ¼ë¡œ ê³„ì‚°í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì§ê´€ì ì…ë‹ˆë‹¤.
    - ì´ í•¨ìˆ˜ëŠ” '__x'/'__y' ì ‘ë¯¸ì‚¬ë¥¼ ê°€ì§„ ê´€ì ˆë“¤ì„ ì°¾ì•„ NaNì´ ì•„ë‹Œ ê°’ì˜ í‰ê· ì„
      ê³„ì‚°í•˜ì—¬ (N,2) ë°°ì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        df (pd.DataFrame): 2D ì¢Œí‘œê°€ ë‹´ê¸´ ë°ì´í„°í”„ë ˆì„

    Returns:
        np.ndarray: (N,2) í˜•íƒœì˜ COM 2D ì¢Œí‘œ ì‹œí€€ìŠ¤ (í”½ì…€ ë˜ëŠ” ì…ë ¥ ì¢Œí‘œ ë‹¨ìœ„)
    """
    cols_map = parse_joint_axis_map_from_columns(df.columns)
    ignore = set(ignore_joints or [])
    joint_names = [k for k in cols_map.keys() if k not in ignore]

    N = len(df)
    com2d = np.full((N, 2), np.nan, dtype=float)

    for i in range(N):
        xs = []
        ys = []
        row = df.iloc[i]
        for j in joint_names:
            axes = cols_map.get(j, {})
            xc = axes.get('x')
            yc = axes.get('y')
            if xc in row.index and yc in row.index:
                xv = row[xc]; yv = row[yc]
                if not (np.isnan(xv) or np.isnan(yv)):
                    xs.append(float(xv)); ys.append(float(yv))
        if xs and ys:
            com2d[i, 0] = float(np.mean(xs))
            com2d[i, 1] = float(np.mean(ys))

    return com2d

def get_com_joints_2d(df: pd.DataFrame, ignore_joints: Optional[set] = None):
    """COM ê³„ì‚°ì— ì‚¬ìš©ë˜ëŠ” ê´€ì ˆë“¤ì˜ 2D ì¢Œí‘œ í™•ì¸"""
    cols_map = parse_joint_axis_map_from_columns(df.columns, prefer_2d=True)
    ignore = set(ignore_joints or [])
    com_joints = [j for j, axes in cols_map.items() if j not in ignore and 'x' in axes and 'y' in axes]

    # ê°€ìƒ ê´€ì ˆë„ ì‹œê°í™”ì— í¬í•¨ (Neck, MidHip)
    if 'LShoulder' in cols_map and 'RShoulder' in cols_map and 'Neck' not in com_joints:
        com_joints.append('Neck')
    if 'LHip' in cols_map and 'RHip' in cols_map and 'MidHip' not in com_joints:
        com_joints.append('MidHip')

    # fallback: common joints
    if not com_joints:
        common = ['Nose', 'Neck', 'MidHip', 'LShoulder', 'RShoulder', 'LHip', 'RHip']
        for c in common:
            if c in cols_map:
                com_joints.append(c)

    print(f"ğŸ”— COM ê´€ì ˆ ì—°ê²°: {com_joints}")
    return com_joints

def build_com_edges(kp_names: List[str]):
    """COM ê´€ë ¨ ê´€ì ˆë“¤ì˜ ì—°ê²°ì„  ìƒì„±"""
    E, have = [], set(kp_names)
    def add(a, b):
        if a in have and b in have: 
            E.append((a, b))
    
    # ì£¼ìš” ê³¨ê²© ì—°ê²° (Body25 ìŠ¤íƒ€ì¼)
    # ìƒì²´
    add("Neck", "RShoulder"); add("RShoulder", "RElbow"); add("RElbow", "RWrist")
    add("Neck", "LShoulder"); add("LShoulder", "LElbow"); add("LElbow", "LWrist")
    add("Neck", "MidHip")
    
    # í•˜ì²´  
    add("MidHip", "RHip"); add("RHip", "RKnee"); add("RKnee", "RAnkle")
    add("MidHip", "LHip"); add("LHip", "LKnee"); add("LKnee", "LAnkle")
    
    # ë¨¸ë¦¬
    add("Neck", "Nose")
    
    # ì–´ê¹¨-ê³¨ë°˜ ì—°ê²°
    add("LShoulder", "RShoulder")
    add("LHip", "RHip")
    
    print(f"ğŸ”— COMìš© ì—°ê²°ì„ : {len(E)}ê°œ")
    return E

def detect_2d_normalized(df: pd.DataFrame, sample_names: List[str]) -> bool:
    """2D ì¢Œí‘œ ì •ê·œí™” ì—¬ë¶€ íƒì§€ (ì „ì²´ ë°ì´í„° ê¸°ì¤€)"""
    # ì „ì²´ ë°ì´í„°ë¡œ ë²”ìœ„ í™•ì¸ (ìƒ˜í”Œë§ ëŒ€ì‹ )
    xmax = ymax = -np.inf
    xmin = ymin = np.inf
    
    for i in range(len(df)):
        row = df.iloc[i]
        for name in sample_names[:10]:  # ì²˜ìŒ 10ê°œ ê´€ì ˆë§Œ í™•ì¸ìœ¼ë¡œ ì†ë„ ìµœì í™”
            x, y, _ = get_xyc_row(row, name)
            if not np.isnan(x): 
                xmax = max(xmax, float(x))
                xmin = min(xmin, float(x))
            if not np.isnan(y): 
                ymax = max(ymax, float(y))
                ymin = min(ymin, float(y))
    
    print(f"ğŸ” ì „ì²´ ë°ì´í„° ì¢Œí‘œ ë²”ìœ„: X({xmin:.3f}~{xmax:.3f}), Y({ymin:.3f}~{ymax:.3f})")
    
    # 3D ì •ê·œí™”ëœ ì¢Œí‘œì¸ì§€ íŒë‹¨ (-1~1 ë²”ìœ„ ë˜ëŠ” ë§¤ìš° ì‘ì€ ê°’)
    is_normalized = (abs(xmax) < 1.0 and abs(xmin) < 1.0 and abs(ymax) < 2.0 and abs(ymin) < 2.0)
    print(f"ğŸ” ì •ê·œí™” ì—¬ë¶€: {is_normalized}")
    return is_normalized

def calculate_data_range(df: pd.DataFrame) -> tuple:
    """ì „ì²´ ë°ì´í„°ì—ì„œ ì‹¤ì œ x,y ì¢Œí‘œ ë²”ìœ„ ê³„ì‚°"""
    x_cols = [col for col in df.columns if col.endswith('__x')]
    y_cols = [col for col in df.columns if col.endswith('__y')]
    
    all_x = []
    all_y = []
    
    for col in x_cols:
        vals = df[col].dropna()
        if len(vals) > 0:
            all_x.extend(vals.tolist())
    
    for col in y_cols:
        vals = df[col].dropna()  
        if len(vals) > 0:
            all_y.extend(vals.tolist())
    
    if all_x and all_y:
        x_min, x_max = min(all_x), max(all_x)
        y_min, y_max = min(all_y), max(all_y)
        print(f"ğŸ“Š ë™ì  ê³„ì‚°ëœ ì „ì²´ ë²”ìœ„: X({x_min:.6f}~{x_max:.6f}), Y({y_min:.6f}~{y_max:.6f})")
        return x_min, x_max, y_min, y_max
    else:
        print("âš ï¸ ì¢Œí‘œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©")
        return -0.867010, 0.628968, -1.532245, 0.854478

# =========================================================
# COM ì‹œê°í™” ì „ìš© ì˜¤ë²„ë ˆì´
# =========================================================
def overlay_com_video(img_dir: Path, df: pd.DataFrame, com_points: np.ndarray, 
                     com_speed: np.ndarray, com_unit: str, 
                     out_mp4: Path, fps: int, codec: str,
                     ignore_joints: Optional[set] = None):
    """COM ê´€ë ¨ ê´€ì ˆë“¤ê³¼ ë¬´ê²Œì¤‘ì‹¬ ì‹œê°í™”"""
    # PNG/JPG ëª¨ë‘ ì§€ì›
    images = sorted(glob.glob(str(img_dir / "*.png")), key=natural_key)
    if not images:
        images = sorted(glob.glob(str(img_dir / "*.jpg")), key=natural_key)
    if not images:
        images = sorted(glob.glob(str(img_dir / "*.jpeg")), key=natural_key)
    if not images:
        raise RuntimeError(f"No images (*.png|*.jpg|*.jpeg) in {img_dir}")

    first = cv2.imread(images[0])
    h, w = first.shape[:2]
    ensure_dir(out_mp4.parent)
    writer = cv2.VideoWriter(str(out_mp4), cv2.VideoWriter_fourcc(*codec), fps, (w, h))
    
    if not writer.isOpened():
        raise RuntimeError(f"VideoWriter open failed: {out_mp4}")

    # COMì— ê¸°ì—¬í•˜ëŠ” ê´€ì ˆë“¤ë§Œ ì‹œê°í™” (2D CSVì˜ ê´€ì ˆë“¤ ì‚¬ìš©)
    kp_names = get_com_joints_2d(df, ignore_joints)
    # ì»¬ëŸ¼ ë§¤í•‘ì€ í•œ ë²ˆë§Œ ê³„ì‚°í•˜ì—¬ ì‚¬ìš© (ì„±ëŠ¥/ì¼ê´€ì„±)
    cols_map_global = parse_joint_axis_map_from_columns(df.columns, prefer_2d=True)
    edges = build_com_edges(kp_names)
    
    # ìë™ ê°ì§€: CSV ê°’ì´ í”½ì…€ ì¢Œí‘œì¸ì§€(ê·¸ëŒ€ë¡œ ì‚¬ìš©) í˜¹ì€
    # ì •ê·œí™”ëœ ì¢Œí‘œê°’ì¸ì§€(ì „ì²´ ë°ì´í„° ë²”ìœ„ë¡œ ë§¤í•‘ í•„ìš”) íŒë‹¨í•©ë‹ˆë‹¤.
    # - í”½ì…€ ì¢Œí‘œ: ê°’ì˜ ì ˆëŒ€ê°’ì´ ì´ë¯¸ì§€ í¬ê¸°ë³´ë‹¤ í¬ê±°ë‚˜ í†µìƒì ì¸ í”½ì…€ ë²”ìœ„(ì˜ˆ: > 2)ì¼ ë•Œ
    # - ì •ê·œí™” ì¢Œí‘œ: ê°’ì˜ ì ˆëŒ€ê°’ì´ ì‘ê³ (ì˜ˆ: <= 2) ì „ ë²”ìœ„ê°€ -1~1 ë“±ìœ¼ë¡œ ì œí•œë  ë•Œ
    # í•„ìš” ì‹œ ì „ì²´ ë°ì´í„° ë²”ìœ„ë¥¼ ê³„ì‚°í•´ ì„ í˜• ë§¤í•‘í•©ë‹ˆë‹¤.
    margin = 0.1

    # ì „ì²´ ë°ì´í„°ì—ì„œ x,y ë²”ìœ„ë¥¼ ê³„ì‚° (com_jointsì— í•œì •, ë§¤í•‘ ì‚¬ìš©)
    xs, ys = [], []
    for name in kp_names:
        axes = cols_map_global.get(name, {})
        cx = axes.get('x'); cy = axes.get('y')
        if cx in df.columns:
            v = df[cx].dropna(); xs.extend(v.tolist())
        if cy in df.columns:
            v = df[cy].dropna(); ys.extend(v.tolist())

    _range = (min(xs), max(xs), min(ys), max(ys)) if xs and ys else None
    is_small_range = False
    x_min = x_max = y_min = y_max = None
    if _range:
        x_min, x_max, y_min, y_max = _range
        # ê°’ë“¤ì´ ì‘ê±°ë‚˜ -1..1 ë²”ìœ„ì— ìˆì„ ê°€ëŠ¥ì„± ì²´í¬
        if abs(x_min) <= 2.0 and abs(x_max) <= 2.0 and abs(y_min) <= 2.0 and abs(y_max) <= 2.0:
            is_small_range = True
        print(f"ğŸ“Š overlay ì¢Œí‘œ ë²”ìœ„: X({x_min:.4f}~{x_max:.4f}) Y({y_min:.4f}~{y_max:.4f}) smallRange={is_small_range}")

    def scale_xy(x, y):
        """ì¢Œí‘œ ë§¤í•‘: í”½ì…€ ì¢Œí‘œëŠ” ê·¸ëŒ€ë¡œ, ì‘ì€ ë²”ìœ„(ì •ê·œí™”)ë¼ë©´ ì „ì²´ ë²”ìœ„ë¡œ ì„ í˜• ë§¤í•‘

        Args:
            x, y: ì…ë ¥ ì¢Œí‘œ (ìˆ«ì ë˜ëŠ” NaN)
        Returns:
            (x_px, y_px) í˜¹ì€ (np.nan, np.nan)
        """
        if np.isnan(x) or np.isnan(y):
            return np.nan, np.nan

        try:
            xf = float(x); yf = float(y)
        except Exception:
            return np.nan, np.nan

        # ì‘ì€ ë²”ìœ„(ì •ê·œí™”ëœ ì¢Œí‘œ)ì¸ ê²½ìš° ì „ì²´ ë°ì´í„° ë²”ìœ„ë¥¼ ì‚¬ìš©í•´ ë§¤í•‘
        if is_small_range and (x_max is not None):
            # ì•ˆì „í•œ ë¶„ëª¨ ì²˜ë¦¬
            dx = x_max - x_min if (x_max - x_min) != 0 else 1.0
            dy = y_max - y_min if (y_max - y_min) != 0 else 1.0
            x_norm = (xf - x_min) / dx
            y_norm = (yf - y_min) / dy
            scaled_x = (margin + x_norm * (1 - 2 * margin)) * w
            scaled_y = (margin + y_norm * (1 - 2 * margin)) * h
            return scaled_x, scaled_y

        # ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ í”½ì…€ ì¢Œí‘œë¡œ ê°„ì£¼
        return xf, yf
    
    # ì²« í”„ë ˆì„ì—ì„œ ì¢Œí‘œ ë³€í™˜ ìƒ˜í”Œ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
    if len(df) > 0 and kp_names:
        sample_row = df.iloc[0]
        sample_joint = kp_names[0]
        # ì „ì—­ ë§¤í•‘ ì‚¬ìš©
        x_tmp = np.nan; y_tmp = np.nan
        if sample_joint in cols_map_global:
            axm = cols_map_global[sample_joint]
            x_tmp = sample_row.get(axm.get('x',''), np.nan)
            y_tmp = sample_row.get(axm.get('y',''), np.nan)
        sample_x, sample_y, _ = (x_tmp, y_tmp, 1.0)
        scaled_x, scaled_y = scale_xy(sample_x, sample_y)
        print(f"ğŸ”§ ì¢Œí‘œ ë³€í™˜ ìƒ˜í”Œ ({sample_joint}): ({sample_x} , {sample_y}) â†’ ({scaled_x} , {scaled_y})")
        print(f"ğŸ”§ í™”ë©´ í¬ê¸°: {w}x{h} (overlay uses 2D CSV)")
    
    # í”„ë ˆì„ ê¸¸ì´ ì •ì±…: ì´ë¯¸ì§€ ê°œìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë Œë”ë§
    n_img = len(images)
    n_df = len(df)
    if n_df != n_img:
        print(f"âš ï¸ í”„ë ˆì„ ê°œìˆ˜ ë¶ˆì¼ì¹˜: images={n_img}, overlay_rows={n_df}. ì´ë¯¸ì§€ ê¸¸ì´ì— ë§ì¶° ë Œë”ë§í•˜ê³ , CSVê°€ ë¶€ì¡±í•œ êµ¬ê°„ì€ ë§ˆì§€ë§‰ ê°’ì„ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.")

    # COM ê¶¤ì  ì €ì¥ (ìµœê·¼ 50í”„ë ˆì„)
    com_trail = []

    for i, p in enumerate(images):
        frame = cv2.imread(p)
        # CSV row ì„ íƒ (ë¶€ì¡±í•˜ë©´ ë§ˆì§€ë§‰ row ì¬ì‚¬ìš©)
        if n_df > 0:
            row_idx = i if i < n_df else (n_df - 1)
            row = df.iloc[row_idx]
        else:
            row = None

    # (HUD/í…ìŠ¤íŠ¸ ì‚­ì œ ë²„ì „) ì§„ë‹¨ìš© ì¹´ìš´í„° ì œê±°

        # --- COM ê´€ì ˆë“¤ ì—°ê²°ì„  ---
        for a, b in edges:
            # ì „ì—­ ë§¤í•‘ ê¸°ë°˜ ì¢Œí‘œ ì½ê¸°
            axm = cols_map_global.get(a, {})
            bxm = cols_map_global.get(b, {})
            ax = row.get(axm.get('x',''), np.nan)
            ay = row.get(axm.get('y',''), np.nan)
            bx = row.get(bxm.get('x',''), np.nan)
            by = row.get(bxm.get('y',''), np.nan)
            
            ax, ay = scale_xy(ax, ay)
            bx, by = scale_xy(bx, by)
            
            if not (np.isnan(ax) or np.isnan(ay) or np.isnan(bx) or np.isnan(by)):
                cv2.line(frame, (int(ax), int(ay)), (int(bx), int(by)), (0, 255, 255), 2)

        # --- COM ê´€ì ˆ ì ë“¤ ---
        for name in kp_names:
            m = cols_map_global.get(name, {})
            x = row.get(m.get('x',''), np.nan)
            y = row.get(m.get('y',''), np.nan)
            x, y = scale_xy(x, y)
            if not (np.isnan(x) or np.isnan(y)):
                cv2.circle(frame, (int(x), int(y)), 4, (255, 0, 0), -1)

        # --- COM ì¤‘ì‹¬ì  í‘œì‹œ ---
        com_idx = i if i < len(com_points) else (len(com_points) - 1 if len(com_points) > 0 else -1)
        if com_idx >= 0 and not np.any(np.isnan(com_points[com_idx])):
            # COMì˜ 2D íˆ¬ì˜
            com_2d_x = com_points[com_idx, 0]
            com_2d_y = com_points[com_idx, 1]
            
            com_x, com_y = scale_xy(com_2d_x, com_2d_y)
            
            if not (np.isnan(com_x) or np.isnan(com_y)):
                # COM ì¤‘ì‹¬ì  (ë¹¨ê°„ ë‹¤ì´ì•„ëª¬ë“œ)
                pts = np.array([
                    [int(com_x), int(com_y-15)],
                    [int(com_x+15), int(com_y)],
                    [int(com_x), int(com_y+15)],
                    [int(com_x-15), int(com_y)]
                ], np.int32)
                cv2.fillPoly(frame, [pts], (0, 0, 255))
                cv2.polylines(frame, [pts], True, (255, 255, 255), 2)
                
                # COM ê¶¤ì  ì¶”ê°€
                com_trail.append((int(com_x), int(com_y)))
                if len(com_trail) > 50:  # ìµœê·¼ 50í”„ë ˆì„ë§Œ ìœ ì§€
                    com_trail.pop(0)
                
                # COM ê¶¤ì  ê·¸ë¦¬ê¸°
                for j in range(1, len(com_trail)):
                    alpha = j / len(com_trail)
                    color_intensity = int(255 * alpha)
                    cv2.line(frame, com_trail[j-1], com_trail[j], (color_intensity, 0, 255), 3)

        # (HUD/í…ìŠ¤íŠ¸ ì œê±°) í”„ë ˆì„ì— ìˆ˜ì¹˜/ë¬¸ì ì •ë³´ëŠ” í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

        writer.write(frame)

    writer.release()

# =========================================================
# ë©”ì¸ í•¨ìˆ˜
# =========================================================
def main():
    ap = argparse.ArgumentParser(description="COM Speed ì „ìš© ë¶„ì„ê¸°")
    ap.add_argument("-c", "--config", default=str(Path(__file__).parent.parent / "config" / "analyze.yaml"))
    ap.add_argument("--use-smoothed", action="store_true", help="ìŠ¤ë¬´ë”©ëœ ì¢Œí‘œ ë°ì´í„° ì‚¬ìš©")
    args = ap.parse_args()
    
    cfg = load_cfg(Path(args.config))
    # CSV ê²½ë¡œ ì„ íƒ: overlayìš© 2D CSVì™€ metricsìš© 3D CSVë¥¼ ë¶„ë¦¬í•˜ì—¬ ì‚¬ìš©
    # analyze.yamlì— `overlay_csv_path`ì™€ `metrics_csv_path`ë¥¼ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.
    # ê¸°ì¡´ì˜ `csv_path`ê°€ ìˆìœ¼ë©´ í˜¸í™˜ì„±ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    overlay_csv = None
    metrics_csv = None

    if "overlay_csv_path" in cfg:
        overlay_csv = Path(cfg["overlay_csv_path"])
        print(f"ğŸ“Š Overlay(2D) CSV ì‚¬ìš©: {overlay_csv}")
    elif "csv_path" in cfg:
        overlay_csv = Path(cfg["csv_path"])  # fallback
        print(f"ğŸ“Š Overlay(2D) CSV (fallback) ì‚¬ìš©: {overlay_csv}")

    if "metrics_csv_path" in cfg:
        metrics_csv = Path(cfg["metrics_csv_path"])
        print(f"ğŸ“Š Metrics(3D) CSV ì‚¬ìš©: {metrics_csv}")
    elif "csv_path" in cfg:
        metrics_csv = Path(cfg["csv_path"])  # fallback
        print(f"ğŸ“Š Metrics(3D) CSV (fallback) ì‚¬ìš©: {metrics_csv}")
    
    img_dir = Path(cfg["img_dir"])
    fps = int(cfg.get("fps", 30))
    codec = str(cfg.get("codec", "mp4v"))
    
    # ì¶œë ¥ ê²½ë¡œ (COM ì „ìš©)
    out_csv = Path(cfg["metrics_csv"]).parent / "com_speed_metrics.csv"
    out_mp4 = Path(cfg["overlay_mp4"]).parent / "com_speed_analysis.mp4"

    # 1) CSV ë¡œë“œ
    # - metrics_csv (3D) -> ë©”íŠ¸ë¦­ ê³„ì‚°
    # - overlay_csv (2D) -> ì˜¤ë²„ë ˆì´ ì‹œê°í™”
    if metrics_csv is None or not metrics_csv.exists():
        raise RuntimeError("metrics_csv_path ê°€ configì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•Šê±°ë‚˜ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    if overlay_csv is None or not overlay_csv.exists():
        raise RuntimeError("overlay_csv_path ê°€ configì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•Šê±°ë‚˜ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    df_metrics = pd.read_csv(metrics_csv)
    df_overlay = pd.read_csv(overlay_csv)
    print(f"ğŸ“‹ Metrics CSV ë¡œë“œ: {metrics_csv} ({len(df_metrics)} frames)")
    print(f"ğŸ“‹ Overlay CSV ë¡œë“œ: {overlay_csv} ({len(df_overlay)} frames)")

    # ë¬´ì‹œí•  ê´€ì ˆ (ì˜ˆ: ì–¼êµ´ 5ê°œ ì‚­ì œ)
    default_ignore = {"Nose", "LEye", "REye", "LEar", "REar"}
    ignore_cfg = set(cfg.get('ignore_joints', [])) if isinstance(cfg.get('ignore_joints', []), list) else set()
    ignore_set = default_ignore.union(ignore_cfg)

    # 2) COM ê³„ì‚° (3D metrics ë°ì´í„° ì‚¬ìš©)
    com_pts = compute_com_points_3d(df_metrics, ignore_joints=ignore_set)
    com_v, com_unit = speed_3d(com_pts, fps)

    # 3) ê²°ê³¼ ì €ì¥
    metrics = pd.DataFrame({
        'frame': range(len(df_metrics)),
        'com_speed': com_v,
        'com_x': com_pts[:, 0],
        'com_y': com_pts[:, 1],
        'com_z': com_pts[:, 2]
    })
    
    ensure_dir(out_csv.parent)
    metrics.to_csv(out_csv, index=False)
    print(f"âœ… COM ë©”íŠ¸ë¦­ ì €ì¥: {out_csv}")

    # 4) ë¹„ë””ì˜¤ ì˜¤ë²„ë ˆì´
    #    ì˜¤ë²„ë ˆì´ ì „ì— ì„ íƒì ìœ¼ë¡œ 2D ìŠ¤ë¬´ë”© ì ìš©
    draw_cfg = cfg.get('draw', {}) or {}
    smooth_cfg = (draw_cfg.get('smoothing') or {}) if isinstance(draw_cfg.get('smoothing'), dict) else {}
    if smooth_cfg.get('enabled', False):
        method = smooth_cfg.get('method', 'ema')
        window = int(smooth_cfg.get('window', 5))
        alpha = float(smooth_cfg.get('alpha', 0.2))
        # ì¶”ê°€ íŒŒë¼ë¯¸í„° (ìˆìœ¼ë©´ ì‚¬ìš©)
        gaussian_sigma = smooth_cfg.get('gaussian_sigma')
        hampel_sigma = smooth_cfg.get('hampel_sigma', 3.0)
        oneeuro_min_cutoff = smooth_cfg.get('oneeuro_min_cutoff', 1.0)
        oneeuro_beta = smooth_cfg.get('oneeuro_beta', 0.007)
        oneeuro_d_cutoff = smooth_cfg.get('oneeuro_d_cutoff', 1.0)

        df_overlay_sm = smooth_df_2d(
            df_overlay,
            prefer_2d=True,
            method=method,
            window=window,
            alpha=alpha,
            fps=fps,
            gaussian_sigma=gaussian_sigma,
            hampel_sigma=hampel_sigma,
            oneeuro_min_cutoff=oneeuro_min_cutoff,
            oneeuro_beta=oneeuro_beta,
            oneeuro_d_cutoff=oneeuro_d_cutoff,
        )
    else:
        df_overlay_sm = df_overlay

    com2d = compute_com_points_2d(df_overlay_sm, ignore_joints=ignore_set)
    overlay_com_video(img_dir, df_overlay_sm, com2d, com_v, com_unit, out_mp4, fps, codec, ignore_joints=ignore_set)
    print(f"âœ… COM ë¶„ì„ ë¹„ë””ì˜¤ ì €ì¥: {out_mp4}")
    
    # 5) í†µê³„ ì¶œë ¥
    print(f"\nğŸ“Š COM Speed ë¶„ì„ ê²°ê³¼:")
    print(f"   í‰ê·  COM Speed: {np.nanmean(com_v):.2f} {com_unit}")
    print(f"   ìµœëŒ€ COM Speed: {np.nanmax(com_v):.2f} {com_unit}")
    
    # COM ë¶„ì„ì— ì‚¬ìš©ëœ ê´€ì ˆ ì •ë³´
    cols_map_3d = parse_joint_axis_map_from_columns(df_metrics.columns, prefer_2d=False)
    valid_joints = [j for j, axes in cols_map_3d.items() if all(a in axes for a in ('x','y','z'))]
    
    print(f"   ì‚¬ìš©ëœ ê´€ì ˆ ìˆ˜: {len(valid_joints)}ê°œ")
    print(f"   ê´€ì ˆ ëª©ë¡: {valid_joints}")

if __name__ == "__main__":
    main()


def run_from_context(ctx: dict):
    """Standardized runner for com_speed.

    Returns JSON-serializable dict with keys:
      - metrics_csv: path
      - overlay_mp4: path (if produced)
      - summary: dict of simple numeric summaries
    """
    try:
        dest = Path(ctx.get('dest_dir', '.'))
        job_id = ctx.get('job_id', 'job')
        fps = int(ctx.get('fps', 30))
        wide3 = ctx.get('wide3')
        wide2 = ctx.get('wide2')
        ensure_dir(dest)

        out = {}

        # Metrics (3D)
        if wide3 is not None:
            try:
                com_pts = compute_com_points_3d(wide3)
                v, unit = speed_3d(com_pts, fps)
                metrics_df = pd.DataFrame({
                    'frame': list(range(len(wide3))),
                    'com_speed': list(map(float, v.tolist())),
                    'com_x': list(map(lambda x: float(x) if not np.isnan(x) else None, com_pts[:, 0].tolist())),
                    'com_y': list(map(lambda x: float(x) if not np.isnan(x) else None, com_pts[:, 1].tolist())),
                    'com_z': list(map(lambda x: float(x) if not np.isnan(x) else None, com_pts[:, 2].tolist())),
                })
                metrics_csv = dest / f"{job_id}_com_speed_metrics.csv"
                ensure_dir(metrics_csv.parent)
                metrics_df.to_csv(metrics_csv, index=False)
                out['metrics_csv'] = str(metrics_csv)
                out['summary'] = {
                    'mean_com_speed': float(np.nanmean(v)) if len(v) > 0 else None,
                    'max_com_speed': float(np.nanmax(v)) if len(v) > 0 else None,
                    'unit': unit,
                }
            except Exception as e:
                return {'error': f'com_speed metrics failure: {e}'}
        else:
            out['metrics_csv'] = None

        # Overlay (2D)
        overlay_path = dest / f"{job_id}_com_speed_overlay.mp4"
        try:
            if wide2 is not None:
                com2d = compute_com_points_2d(wide2)
                # ensure img_dir is present in ctx, default to dest
                img_dir = Path(ctx.get('img_dir', dest))
                overlay_com_video(img_dir, wide2, com2d, v if 'v' in locals() else np.zeros(len(com2d)), unit if 'unit' in locals() else 'mm/frame', overlay_path, fps, 'mp4v')
                out['overlay_mp4'] = str(overlay_path)
        except Exception as e:
            # non-fatal; record error
            out.setdefault('overlay_error', str(e))

        return out
    except Exception as e:
        return {'error': str(e)}