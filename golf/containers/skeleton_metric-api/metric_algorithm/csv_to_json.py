#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CSV â†’ JSON ë³€í™˜ ìœ í‹¸ë¦¬í‹°

ê°œë…
- í”„ë¡ íŠ¸ì—”ë“œëŠ” ë³´í†µ JSONì„ ë” ì‰½ê²Œ ì†Œë¹„í•©ë‹ˆë‹¤. ë¶„ì„ ë‹¨ê³„ì—ì„œ ìƒì„±ëœ CSVë“¤ì„
  ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ê¸°ë³´ë‹¤, ê° í–‰ì„ ê°ì²´(record)ë¡œ ê°–ëŠ” JSON ë°°ì—´ë¡œ ë³€í™˜í•´ ì£¼ë©´
  í´ë¼ì´ì–¸íŠ¸(ì›¹/ì•±)ì—ì„œ íŒŒì‹± ì—†ì´ ë°”ë¡œ ì‚¬ìš©í•˜ê¸° í¸í•©ë‹ˆë‹¤.
- ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” í´ë” ë‹¨ìœ„ë¡œ CSV íŒŒì¼ë“¤ì„ ì°¾ì•„ ê°™ì€ ì´ë¦„ì˜ .json íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.
- NaN/NaT ë“± ê²°ì¸¡ì¹˜ëŠ” JSONì˜ null ë¡œ ì§ë ¬í™”í•˜ì—¬ í”„ë¡ íŠ¸ì—ì„œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬ë˜ë„ë¡ í•©ë‹ˆë‹¤.

ì‚¬ìš© ì˜ˆ
  # í´ë” ë‚´ ëª¨ë“  CSVë¥¼ JSONìœ¼ë¡œ ë³€í™˜ (ë™ì¼ í´ë”ì— .json ìƒì„±)
  python src/csv_to_json.py -i /path/to/summary

  # ë‹¨ì¼ íŒŒì¼ ë³€í™˜ ë° ì¶œë ¥ í´ë” ì§€ì •
  python src/csv_to_json.py -i /path/to/metrics.csv -o /path/to/out_json

ì˜µì…˜
- --orient: JSON êµ¬ì¡°ë¥¼ ì„ íƒ(records|split|index|columns|values|table). ê¸°ë³¸ records
- --pattern: ë””ë ‰í„°ë¦¬ ì…ë ¥ ì‹œ ë§¤ì¹­ íŒ¨í„´ (ê¸°ë³¸ *.csv)

analyze.yaml ì—°ë™
- -c/--config ë¡œ analyze.yamlì„ ë„˜ê¸°ë©´, ë‹¤ìŒ í‚¤ë“¤ì„ í†µí•´ ê²½ë¡œë¥¼ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    json_export:
        input: "/path/to/csv_or_dir"
        output_dir: "/path/to/save_json"
        pattern: "*_metrics.csv"   # í´ë” ì…ë ¥ ì‹œ í•„í„°
        orient: "records"          # records|split|index|columns|values|table
        indent: 2                   # records ëª¨ë“œ ë“¤ì—¬ì“°ê¸°
        ensure_ascii: false         # trueë©´ ASCIIë¡œ ì´ìŠ¤ì¼€ì´í”„

        # ì—¬ëŸ¬ CSV â†’ í•˜ë‚˜ì˜ JSON ë³‘í•© ì¶œë ¥(ì˜µì…˜)
        merge_output: "/path/to/merged.json"   # ì§€ì • ì‹œ ë³‘í•© JSONë„ ìƒì„±
        merge_mode: "by-file"                   # by-file | concat
        # by-file: {"<csv_stem>": [records...], ...}
        # concat:  [ {source: "<csv_stem>", ...record}, ... ]
"""

from __future__ import annotations
import argparse
import json
import os
from pathlib import Path
from typing import Iterable

import pandas as pd
try:
    import yaml
except Exception:
    yaml = None

try:
    # í”„ë¡œì íŠ¸ ê³µìš© ìœ í‹¸ (í´ë” ìƒì„± ë“±)
    from utils_io import ensure_dir
except Exception:
    def ensure_dir(p: Path):
        p.mkdir(parents=True, exist_ok=True)


ALLOWED_ORIENTS = {"records", "split", "index", "columns", "values", "table"}


def convert_one(csv_path: Path, out_dir: Path | None = None, orient: str = "records", indent: int = 2, ensure_ascii: bool = False) -> Path:
    if orient not in ALLOWED_ORIENTS:
        raise ValueError(f"unsupported orient: {orient}")

    df = pd.read_csv(csv_path)
    # NaN/NaT â†’ None (JSON null)
    df = df.where(pd.notna(df), None)

    if out_dir is None:
        out_dir = csv_path.parent
    ensure_dir(out_dir)
    out_path = out_dir / (csv_path.stem + ".json")

    # orient ë³„ ì§ë ¬í™”
    if orient == "records":
        payload = df.to_dict(orient="records")
        with out_path.open("w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=ensure_ascii, indent=indent)
    else:
        # DataFrame.to_jsonì€ NaNì„ nullë¡œ ì§ë ¬í™”í•¨
        txt = df.to_json(orient=orient, force_ascii=ensure_ascii)
        with out_path.open("w", encoding="utf-8") as f:
            f.write(txt)

    return out_path


def iter_csvs_in_dir(d: Path, pattern: str = "*.csv") -> Iterable[Path]:
    yield from sorted(d.glob(pattern))


def read_as_records(csv_path: Path) -> list[dict]:
    """CSVë¥¼ records(list[dict])ë¡œ ë¡œë“œ(NaNâ†’None). ë³‘í•©ìš©.
    """
    df = pd.read_csv(csv_path)
    df = df.where(pd.notna(df), None)
    return df.to_dict(orient="records")


def main():
    ap = argparse.ArgumentParser(description="CSV â†’ JSON ë³€í™˜ê¸° (í´ë”/ë‹¨ì¼ íŒŒì¼ ì§€ì›)")
    ap.add_argument("-c", "--config", default=str(Path(__file__).parent.parent / "config" / "analyze.yaml"), help="analyze.yaml ê²½ë¡œ")
    ap.add_argument("-i", "--input", default=None, help="CSV íŒŒì¼ ê²½ë¡œ ë˜ëŠ” CSVë“¤ì´ ìˆëŠ” í´ë” ê²½ë¡œ (ë¯¸ì§€ì • ì‹œ analyze.yamlì˜ json_export.input ì‚¬ìš©)")
    ap.add_argument("-o", "--output-dir", default=None, help="ì¶œë ¥ JSONì„ ì €ì¥í•  í´ë” (ë¯¸ì§€ì • ì‹œ ì…ë ¥ê³¼ ë™ì¼ í´ë” ë˜ëŠ” analyze.yamlì˜ json_export.output_dir)")
    ap.add_argument("--orient", default=None, choices=sorted(ALLOWED_ORIENTS), help="JSON êµ¬ì¡° ìœ í˜• (ê¸°ë³¸ records ë˜ëŠ” analyze.yamlì˜ json_export.orient)")
    ap.add_argument("--pattern", default=None, help="ë””ë ‰í„°ë¦¬ ì…ë ¥ ì‹œ CSV ë§¤ì¹­ íŒ¨í„´ (ê¸°ë³¸ *.csv ë˜ëŠ” analyze.yamlì˜ json_export.pattern)")
    ap.add_argument("--indent", type=int, default=None, help="JSON ë“¤ì—¬ì“°ê¸° (records ëª¨ë“œì— ì ìš©). ê¸°ë³¸ 2 ë˜ëŠ” analyze.yamlì˜ json_export.indent")
    ap.add_argument("--ensure-ascii", action="store_true", help="ASCIIë§Œ ì‚¬ìš©í•˜ì—¬ ì´ìŠ¤ì¼€ì´í”„(ê¸°ë³¸: í•œê¸€ ìœ ì§€). analyze.yamlì—ì„œ true ì„¤ì • ê°€ëŠ¥")
    # ë³‘í•© ì¶œë ¥ ì˜µì…˜
    ap.add_argument("-m", "--merge-output", default=None, help="ì—¬ëŸ¬ CSVë¥¼ í•˜ë‚˜ì˜ JSONìœ¼ë¡œ ë³‘í•©í•´ ì €ì¥í•  ê²½ë¡œ")
    ap.add_argument("--merge-mode", default=None, choices=["by-file","concat"], help="ë³‘í•© ë°©ì‹: by-file|concat (ê¸°ë³¸ by-file)")
    args = ap.parse_args()

    # analyze.yaml ë¡œë“œ (ìˆì„ ë•Œë§Œ)
    cfg = None
    cfg_path = Path(args.config) if args.config else None
    if cfg_path and cfg_path.exists() and cfg_path.suffix.lower() in (".yml", ".yaml") and yaml is not None:
        try:
            cfg = yaml.safe_load(cfg_path.read_text(encoding="utf-8"))
        except Exception:
            cfg = None
    jexp = (cfg.get("json_export") if isinstance(cfg, dict) else None) or {}

    # ìš°ì„ ìˆœìœ„: CLI > analyze.yaml > ê¸°ë³¸ê°’
    in_val = args.input or jexp.get("input")
    out_val = args.output_dir or jexp.get("output_dir")
    orient = args.orient or jexp.get("orient") or "records"
    pattern = args.pattern or jexp.get("pattern") or "*.csv"
    indent = (args.indent if args.indent is not None else jexp.get("indent", 2))
    ensure_ascii = bool(args.ensure_ascii or jexp.get("ensure_ascii", False))
    merge_output = args.merge_output or jexp.get("merge_output")
    merge_mode = args.merge_mode or jexp.get("merge_mode", "by-file")

    if not in_val:
        raise FileNotFoundError("ì…ë ¥ ê²½ë¡œê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. -i ë˜ëŠ” analyze.yamlì˜ json_export.inputì„ ì„¤ì •í•˜ì„¸ìš”.")

    in_path = Path(in_val)
    out_dir = Path(out_val) if out_val else None

    print(f"ğŸ“¥ ì…ë ¥: {in_path}")
    if out_dir:
        print(f"ğŸ“¤ ì¶œë ¥ í´ë”: {out_dir}")
    print(f"âš™ï¸ ì˜µì…˜: orient={orient}, pattern={pattern}, indent={indent}, ensure_ascii={ensure_ascii}")
    if merge_output:
        print(f"ğŸ”— ë³‘í•© ì¶œë ¥: {merge_output} (mode={merge_mode})")

    generated = []
    if in_path.is_file():
        p = convert_one(in_path, out_dir, orient=orient, indent=indent, ensure_ascii=ensure_ascii)
        generated.append(p)
    elif in_path.is_dir():
        for csvf in iter_csvs_in_dir(in_path, pattern=pattern):
            p = convert_one(csvf, out_dir or in_path, orient=orient, indent=indent, ensure_ascii=ensure_ascii)
            generated.append(p)
    else:
        raise FileNotFoundError(f"ì…ë ¥ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {in_path}")

    # ë³‘í•© JSON ìƒì„±(ì˜µì…˜): í´ë” ì…ë ¥ì¼ ë•Œ ì£¼ë¡œ ì‚¬ìš©, íŒŒì¼ ì…ë ¥ë„ ë‹¨ì¼ ë³‘í•©ìœ¼ë¡œ ì €ì¥ ê°€ëŠ¥
    if merge_output:
        merge_out_path = Path(merge_output)
        merge_out_path.parent.mkdir(parents=True, exist_ok=True)
        # ëŒ€ìƒ CSV ëª©ë¡
        targets: list[Path]
        if in_path.is_file():
            targets = [in_path]
        else:
            targets = list(iter_csvs_in_dir(in_path, pattern=pattern))

        if merge_mode == "concat":
            merged: list[dict] = []
            for csvp in targets:
                recs = read_as_records(csvp)
                stem = csvp.stem
                for r in recs:
                    if isinstance(r, dict) and "source" not in r:
                        r["source"] = stem
                merged.extend(recs)
            with merge_out_path.open("w", encoding="utf-8") as f:
                json.dump(merged, f, ensure_ascii=ensure_ascii, indent=indent)
        else:  # by-file
            merged: dict[str, list[dict]] = {}
            for csvp in targets:
                recs = read_as_records(csvp)
                merged[csvp.stem] = recs
            with merge_out_path.open("w", encoding="utf-8") as f:
                json.dump(merged, f, ensure_ascii=ensure_ascii, indent=indent)
        print(f"[SAVE] ë³‘í•© JSON: {merge_out_path}")

    if generated:
        print("\n[SAVE] JSON ìƒì„± ì™„ë£Œ:")
        for p in generated:
            print(f"  - {p}")
    else:
        print("ë³€í™˜í•  CSVê°€ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()
