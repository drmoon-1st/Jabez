{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ab6047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "import subprocess\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------------- Configuration ----------------\n",
    "# Input root where AIHub data (male/, female/ folders) are stored\n",
    "INPUT_ROOT = Path(r\"D:/golfDataset/스포츠 사람 동작 영상(골프)\")\n",
    "# Output root under dataset/train\n",
    "DATASET_ROOT = Path(r\"D:/golfDataset/dataset/train\")\n",
    "# OpenPose binary path\n",
    "OPENPOSE_BIN = r\"C:/openpose/openpose/bin/OpenPoseDemo.exe\"\n",
    "# Temporary JSON directory for intermediate OpenPose outputs\n",
    "TMP_JSON_DIR = DATASET_ROOT / \"_tmp_json\"\n",
    "# FPS for video encoding\n",
    "FPS = 30\n",
    "# Evaluation labels\n",
    "TRUE_EVALS = {\"best\", \"good\", \"normal\"}\n",
    "FALSE_EVALS = {\"bad\", \"worst\"}\n",
    "# Margin for cropping box (e.g., 10% larger)\n",
    "MARGIN = 0.1\n",
    "\n",
    "# ---------------- Step 1: Classification ----------------\n",
    "def classify_actions(input_root: Path, output_root: Path):\n",
    "    for gender_folder in input_root.iterdir():\n",
    "        if not gender_folder.is_dir():\n",
    "            continue\n",
    "        for js in gender_folder.rglob('*.json'):\n",
    "            try:\n",
    "                data = json.loads(js.read_text(encoding='utf-8'))\n",
    "            except Exception:\n",
    "                continue\n",
    "            eval_label = data.get('evaluation', '').lower()\n",
    "            if eval_label in TRUE_EVALS:\n",
    "                label = 'true'\n",
    "            elif eval_label in FALSE_EVALS:\n",
    "                label = 'false'\n",
    "            else:\n",
    "                continue  # skip unrecognized\n",
    "            # ensure dirs\n",
    "            for ext in ['json', 'jpg']:\n",
    "                (output_root / label / ext).mkdir(parents=True, exist_ok=True)\n",
    "            # copy json\n",
    "            shutil.copy2(js, output_root / label / 'json' / js.name)\n",
    "            # copy jpg\n",
    "            jpg = js.with_suffix('.jpg')\n",
    "            if jpg.exists():\n",
    "                shutil.copy2(jpg, output_root / label / 'jpg' / jpg.name)\n",
    "    print(\"[Step 1] Classification complete.\")\n",
    "\n",
    "# ---------------- Step 2: JPG → MP4 ----------------\n",
    "def images_to_video(img_dir: Path, video_dir: Path, fps: int = FPS):\n",
    "    video_dir.mkdir(parents=True, exist_ok=True)\n",
    "    # group by prefix before _####.jpg\n",
    "    groups = {}\n",
    "    for jp in img_dir.glob('*.jpg'):\n",
    "        prefix = jp.stem.rsplit('_', 1)[0]\n",
    "        groups.setdefault(prefix, []).append(jp)\n",
    "    for prefix, files in groups.items():\n",
    "        out_mp4 = video_dir / f\"{prefix}.mp4\"\n",
    "        pattern = str(img_dir / f\"{prefix}_%04d.jpg\")\n",
    "        cmd = ['ffmpeg', '-y', '-r', str(fps), '-i', pattern, '-c:v', 'libx264', str(out_mp4)]\n",
    "        subprocess.run(cmd, check=True)\n",
    "    # delete jpg\n",
    "    for jp in img_dir.glob('*.jpg'):\n",
    "        jp.unlink()\n",
    "\n",
    "def convert_all_jpgs(output_root: Path):\n",
    "    for label in ['true', 'false']:\n",
    "        img_dir = output_root / label / 'jpg'\n",
    "        video_dir = output_root / label / 'video'\n",
    "        if img_dir.exists():\n",
    "            print(f\"[Step 2] Converting {label}/jpg to MP4...\")\n",
    "            images_to_video(img_dir, video_dir)\n",
    "    print(\"[Step 2] JPG→MP4 conversion complete.\")\n",
    "\n",
    "# ---------------- Step 3: Balanced True Extraction ----------------\n",
    "def extract_balanced_true(output_root: Path):\n",
    "    false_vids = list((output_root / 'false' / 'video').glob('*.mp4'))\n",
    "    num_false = len(false_vids)\n",
    "    true_vids = list((output_root / 'true' / 'video').glob('*.mp4'))\n",
    "    if num_false == 0:\n",
    "        print(\"No false videos found; skipping balanced extraction.\")\n",
    "        return\n",
    "    random.shuffle(true_vids)\n",
    "    selected = true_vids[:num_false]\n",
    "    bt_root = output_root / 'balanced_true'\n",
    "    for sub in ['video', 'crop_video', 'crop_keypoint', 'crop_pkl']:\n",
    "        (bt_root / sub).mkdir(parents=True, exist_ok=True)\n",
    "    for vid in selected:\n",
    "        shutil.copy2(vid, bt_root / 'video' / vid.name)\n",
    "    print(f\"[Step 3] Extracted {len(selected)} balanced_true videos.\")\n",
    "\n",
    "# ---------------- Step 4: OpenPose Crop & CSV ----------------\n",
    "def run_openpose(video_path: Path, json_out: Path):\n",
    "    json_out.mkdir(parents=True, exist_ok=True)\n",
    "    cmd = [OPENPOSE_BIN, '--video', str(video_path), '--write_json', str(json_out), '--display', '0', '--render_pose', '0', '--tracking', '1', '--number_people_max', '2']\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "\n",
    "def get_torso_bbox(json_dir: Path):\n",
    "    coords = []\n",
    "    for js in sorted(json_dir.glob('*.json')):\n",
    "        data = json.loads(js.read_text(encoding='utf-8'))\n",
    "        people = data.get('people', [])\n",
    "        if not people:\n",
    "            continue\n",
    "        pts = np.array(people[0]['pose_keypoints_2d']).reshape(-1, 3)\n",
    "        torso_idxs = [1, 8, 2, 5, 9, 12]\n",
    "        torso = pts[torso_idxs, :2]\n",
    "        coords.append(torso)\n",
    "    if not coords:\n",
    "        return None\n",
    "    all_pts = np.vstack(coords)\n",
    "    cx, cy = np.median(all_pts, axis=0)\n",
    "    w, h = np.percentile(all_pts, 90, axis=0)\n",
    "    w *= (1 + MARGIN)\n",
    "    h *= (1 + MARGIN)\n",
    "    x1 = max(0, int(cx - w / 2))\n",
    "    y1 = max(0, int(cy - h / 2))\n",
    "    return x1, y1, int(w), int(h)\n",
    "\n",
    "\n",
    "def crop_video(input_vid: Path, output_vid: Path, bbox: tuple):\n",
    "    x, y, w, h = bbox\n",
    "    output_vid.parent.mkdir(parents=True, exist_ok=True)\n",
    "    cmd = ['ffmpeg', '-y', '-i', str(input_vid), '-filter:v', f\"crop={w}:{h}:{x}:{y}\", str(output_vid)]\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "\n",
    "def json_dir_to_csv(json_dir: Path, csv_path: Path):\n",
    "    rows = []\n",
    "    for js in sorted(json_dir.glob('*.json')):\n",
    "        data = json.loads(js.read_text(encoding='utf-8'))\n",
    "        people = data.get('people', [])\n",
    "        if people:\n",
    "            kps = people[0]['pose_keypoints_2d']\n",
    "        else:\n",
    "            kps = [0] * 75\n",
    "        rows.append(kps)\n",
    "    df = pd.DataFrame(rows)\n",
    "    csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(csv_path, index=False, header=False)\n",
    "\n",
    "\n",
    "def preprocess_videos(output_root: Path):\n",
    "    for label in ['true', 'false', 'balanced_true']:\n",
    "        in_vid_dir = output_root / label / 'video'\n",
    "        out_crop_vid = output_root / label / 'crop_video'\n",
    "        out_kp = output_root / label / 'crop_keypoint'\n",
    "        if not in_vid_dir.exists():\n",
    "            continue\n",
    "        for vid in tqdm(list(in_vid_dir.glob('*.mp4')), desc=f\"[Step 4] {label}\"):\n",
    "            name = vid.stem\n",
    "            raw_json = TMP_JSON_DIR / f\"raw_{name}\"\n",
    "            run_openpose(vid, raw_json)\n",
    "            bbox = get_torso_bbox(raw_json)\n",
    "            if bbox is None:\n",
    "                print(f\"Skipping {name}: no keypoints\")\n",
    "                continue\n",
    "            crop_mp4 = out_crop_vid / f\"{name}.mp4\"\n",
    "            crop_video(vid, crop_mp4, bbox)\n",
    "            crop_json = TMP_JSON_DIR / f\"crop_{name}\"\n",
    "            run_openpose(crop_mp4, crop_json)\n",
    "            csv_file = out_kp / f\"{name}.csv\"\n",
    "            json_dir_to_csv(crop_json, csv_file)\n",
    "            shutil.rmtree(raw_json)\n",
    "            shutil.rmtree(crop_json)\n",
    "    print(\"[Step 4] Video crop & CSV extraction complete.\")\n",
    "\n",
    "# ---------------- Step 5: CSV → PKL ----------------\n",
    "def convert_csv_to_pkl(output_root: Path):\n",
    "    for label in ['true', 'false', 'balanced_true']:\n",
    "        csv_dir = output_root / label / 'crop_keypoint'\n",
    "        pkl_dir = output_root / label / 'crop_pkl'\n",
    "        if not csv_dir.exists():\n",
    "            continue\n",
    "        pkl_dir.mkdir(parents=True, exist_ok=True)\n",
    "        for csv_f in csv_dir.glob('*.csv'):\n",
    "            seq = pd.read_csv(csv_f, header=None).values.tolist()\n",
    "            record = {'keypoints': seq}\n",
    "            out_pkl = pkl_dir / f\"{csv_f.stem}.pkl\"\n",
    "            with open(out_pkl, 'wb') as f:\n",
    "                pickle.dump(record, f)\n",
    "    print(\"[Step 5] CSV to PKL conversion complete.\")\n",
    "\n",
    "# ---------------- Main Pipeline ----------------\n",
    "def main():\n",
    "    # ensure base train dirs\n",
    "    (DATASET_ROOT / 'true').mkdir(parents=True, exist_ok=True)\n",
    "    (DATASET_ROOT / 'false').mkdir(parents=True, exist_ok=True)\n",
    "    classify_actions(INPUT_ROOT, DATASET_ROOT)\n",
    "    convert_all_jpgs(DATASET_ROOT)\n",
    "    extract_balanced_true(DATASET_ROOT)\n",
    "    preprocess_videos(DATASET_ROOT)\n",
    "    convert_csv_to_pkl(DATASET_ROOT)\n",
    "    print(\"All preprocessing steps completed.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0c5348",
   "metadata": {},
   "source": [
    "## test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca377bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------- Configuration ----------------\n",
    "# Root of the preprocessed training dataset\n",
    "TRAIN_ROOT = Path(r\"D:/golfDataset/dataset/train\")\n",
    "# Destination for test split\n",
    "TEST_ROOT = Path(r\"D:/golfDataset/dataset/test\")\n",
    "# Backup directory for moved files\n",
    "TMP_ROOT = Path(r\"D:/golfDataset/dataset/tmp\")\n",
    "# Fraction of train data to move to test\n",
    "SPLIT_RATIO = 0.2\n",
    "# Random seed for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "def split_train_test(train_root: Path, test_root: Path, tmp_root: Path,\n",
    "                     split_ratio: float = SPLIT_RATIO, seed: int = SEED):\n",
    "    random.seed(seed)\n",
    "    test_root.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for label_dir in train_root.iterdir():\n",
    "        if not label_dir.is_dir():\n",
    "            continue\n",
    "        # gather all video stems\n",
    "        videos = list((label_dir / 'video').glob('*.mp4'))\n",
    "        stems = [v.stem for v in videos]\n",
    "        if not stems:\n",
    "            continue\n",
    "        random.shuffle(stems)\n",
    "        k = int(len(stems) * split_ratio)\n",
    "        selected = set(stems[:k])\n",
    "\n",
    "        # move related files for each selected stem\n",
    "        for stem in selected:\n",
    "            for subfolder in ['json', 'video', 'crop_video', 'crop_keypoint', 'crop_pkl']:\n",
    "                src_dir = label_dir / subfolder\n",
    "                if not src_dir.exists():\n",
    "                    continue\n",
    "                for file in src_dir.glob(f\"{stem}.*\"):\n",
    "                    rel_path = Path(label_dir.name) / subfolder / file.name\n",
    "                    dest_tmp = tmp_root / rel_path\n",
    "                    dest_test = test_root / rel_path\n",
    "                    dest_tmp.parent.mkdir(parents=True, exist_ok=True)\n",
    "                    dest_test.parent.mkdir(parents=True, exist_ok=True)\n",
    "                    # backup original\n",
    "                    shutil.copy2(file, dest_tmp)\n",
    "                    # move to test\n",
    "                    shutil.move(str(file), str(dest_test))\n",
    "\n",
    "    print(f\"Splitting complete: {split_ratio*100}% of training data moved to test.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    split_train_test(TRAIN_ROOT, TEST_ROOT, TMP_ROOT)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
