{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c21abb8",
   "metadata": {},
   "source": [
    "Openpose crop이 이미 적용된 csv, pkl에 대해 정규화를 적용하는 코드,\n",
    "video_crop_and_csv_merged에 적용되어 있어 이후엔 굳이 실행 안해도 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1db532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ─────────────────────────────\n",
    "# 1. 설정\n",
    "ROOT = Path(r\"D:\\golfDataset\\dataset\")  # dataset 루트\n",
    "SPLITS = [\"train\", \"test\"]             # 정규화 대상 split\n",
    "KP = [\"Nose\",\"Neck\",\"RShoulder\",\"RElbow\",\"RWrist\",\"LShoulder\",\"LElbow\",\"LWrist\",\n",
    "      \"MidHip\",\"RHip\",\"RKnee\",\"RAnkle\",\"LHip\",\"LKnee\",\"LAnkle\",\"REye\",\"LEye\",\n",
    "      \"REar\",\"LEar\",\"LBigToe\",\"LSmallToe\",\"LHeel\",\"RBigToe\",\"RSmallToe\",\"RHeel\"]\n",
    "COLS = [f\"{k}_{c}\" for k in KP for c in (\"x\", \"y\", \"c\")]\n",
    "\n",
    "# ─────────────────────────────\n",
    "# 2. CSV 정규화 함수\n",
    "\n",
    "def normalize_pose(row):\n",
    "    arr = row.values.reshape(-1, 3).copy()  # (25, 3)\n",
    "    if np.isnan(arr).all():\n",
    "        return row\n",
    "    midhip = arr[8, :2]\n",
    "    arr[:, :2] -= midhip\n",
    "    std = np.std(arr[:, :2])\n",
    "    if std > 1e-5:\n",
    "        arr[:, :2] /= std\n",
    "    return pd.Series(arr.flatten(), index=row.index)\n",
    "\n",
    "# ─────────────────────────────\n",
    "# 3. PKL 정규화 함수\n",
    "\n",
    "def normalize_pose_array(arr):\n",
    "    for i in range(arr.shape[0]):\n",
    "        frame = arr[i]\n",
    "        if np.isnan(frame).all():\n",
    "            continue\n",
    "        center = frame[8, :2]\n",
    "        frame[:, :2] -= center\n",
    "        std = np.std(frame[:, :2])\n",
    "        if std > 1e-5:\n",
    "            frame[:, :2] /= std\n",
    "    return arr\n",
    "\n",
    "def normalize_pkl(pkl_path):\n",
    "    with open(pkl_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    for sample in data['annotations']:\n",
    "        for person in sample['keypoint']:\n",
    "            person[:] = normalize_pose_array(person)\n",
    "    with open(pkl_path, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "# ─────────────────────────────\n",
    "# 4. 실행 루프\n",
    "\n",
    "for split in SPLITS:\n",
    "    print(f\"\\n📁 Split: {split.upper()}\")\n",
    "\n",
    "    # --- CSV 정규화 ---\n",
    "    kp_root = ROOT / split\n",
    "    for folder in [\"balanced_true\", \"false\"]:\n",
    "        kp_dir = kp_root / folder / \"crop_keypoint\"\n",
    "        if not kp_dir.exists(): continue\n",
    "        for csv_path in tqdm(sorted(kp_dir.glob(\"*_crop.csv\")), desc=f\"[{split}] {folder} CSV\"):\n",
    "            df = pd.read_csv(csv_path)\n",
    "            df = df[COLS]  # 열 방어\n",
    "            df_norm = df.apply(normalize_pose, axis=1)\n",
    "            df_norm.to_csv(csv_path, index=False)\n",
    "\n",
    "    # --- PKL 정규화 ---\n",
    "    pkl_dir = kp_root / \"crop_pkl\"\n",
    "    for pkl_path in sorted(pkl_dir.glob(\"skeleton_dataset_*.pkl\")):\n",
    "        print(f\"→ PKL 정규화: {pkl_path.name}\")\n",
    "        normalize_pkl(pkl_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classifier_fusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
