{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ebcad6c",
   "metadata": {},
   "source": [
    "# CLS 토큰 only, fintuned 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca35136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 2072개 mp4 처리\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|███████████████████████████| 2072/2072 [40:35<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from decord import VideoReader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "# === 파라미터 직접 지정 ===\n",
    "ROOT = Path(r'D:/golfDataset/dataset')\n",
    "FUSION_DIR = Path(r'D:/Jabez/golf/fusion')\n",
    "PER_VIDEO_DIR = FUSION_DIR / 'embedding_data' / 'timesformer' / 'per_video'\n",
    "PER_VIDEO_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_PATH = Path(r'D:/Jabez/golf/Timesformer_finetune/timesformer_finetuned.pth')\n",
    "PRETRAINED = Path(r'D:/timesformer/pretrained/TimeSformer_divST_96x4_224_K600.pyth')\n",
    "NUM_FRAMES = 96    # 비디오에서 추출할 프레임 수, pretrained 모델이 96이므로, 이에 맞춤\n",
    "# 일반적으로 스윙은 2초 이상(jpg 결합이 30fps 기준, 120프레임은 필요)\n",
    "CLIPS_PER_VID = 2\n",
    "IMG_SIZE = 224\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "sys.path.append(r'D:/timesformer')\n",
    "from timesformer.models.vit import TimeSformer\n",
    "\n",
    "# ImageNet mean/std 사용 (공식 권장)\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std  = [0.229, 0.224, 0.225]\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),  # [0,1], (C,H,W)\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "def uniform_sample(length, num):\n",
    "    if length >= num:\n",
    "        return np.linspace(0, length-1, num, dtype=int)\n",
    "    return np.pad(np.arange(length), (0,num-length), mode='edge')\n",
    "\n",
    "def load_clip(path: Path):\n",
    "    vr = VideoReader(str(path))\n",
    "    L  = len(vr)\n",
    "    segs = np.linspace(0, L, CLIPS_PER_VID+1, dtype=int)\n",
    "    clips = []\n",
    "    for s,e in zip(segs[:-1], segs[1:]):\n",
    "        idx = uniform_sample(e-s, NUM_FRAMES) + s\n",
    "        arr = vr.get_batch(idx).asnumpy()  # (T,H,W,3)\n",
    "        proc = []\n",
    "        for frame in arr:\n",
    "            img = transforms.ToPILImage()(frame)\n",
    "            img_t = eval_transform(img)\n",
    "            proc.append(img_t)\n",
    "        clip = torch.stack(proc, dim=1)  # (C,T,H,W)\n",
    "        clips.append(clip)\n",
    "    return clips\n",
    "\n",
    "# train, test 폴더 내 balanced_true/false/crop_video/*.mp4 모두 처리\n",
    "mapping = {'balanced_true': 1, 'false': 0}\n",
    "all_mp4s = []\n",
    "\n",
    "for split in ['train', 'test']:\n",
    "    split_root = ROOT / split\n",
    "    for cat, lbl in mapping.items():\n",
    "        vd = split_root / cat / 'crop_video'\n",
    "        if not vd.exists(): continue\n",
    "        for mp4 in vd.glob('*.mp4'):\n",
    "            all_mp4s.append((mp4, lbl, cat, split))\n",
    "\n",
    "print(f'총 {len(all_mp4s)}개 mp4 처리')\n",
    "\n",
    "# === 파인튜닝된 모델로 임베딩 추출 (timesformer_finetuned.pth) ===\n",
    "\n",
    "class TimeSformerEmbed(nn.Module):\n",
    "    def __init__(self, model_path, img_size, num_frames, num_classes, pretrained_path):\n",
    "        super().__init__()\n",
    "        self.base = TimeSformer(\n",
    "            img_size=img_size,\n",
    "            num_frames=num_frames,\n",
    "            num_classes=num_classes,\n",
    "            attention_type='divided_space_time',\n",
    "            pretrained_model=str(pretrained_path)\n",
    "        )\n",
    "        ckpt = torch.load(model_path, map_location=\"cpu\")\n",
    "        self.base.load_state_dict(ckpt[\"model\"])\n",
    "        # 분류 헤드 제거\n",
    "        self.base.head = nn.Identity()\n",
    "        self.base.cls_head = nn.Identity()\n",
    "\n",
    "    def forward(self, x):  # x: (B, 3, T, H, W)\n",
    "        return self.base(x)  # (B, embed_dim)\n",
    "\n",
    "# 기존 모델 대신 파인튜닝된 모델로 교체\n",
    "embed_model = TimeSformerEmbed(\n",
    "    model_path=MODEL_PATH,\n",
    "    img_size=IMG_SIZE,\n",
    "    num_frames=NUM_FRAMES,\n",
    "    num_classes=2,\n",
    "    pretrained_path=PRETRAINED\n",
    ").to(DEVICE)\n",
    "embed_model.eval()\n",
    "\n",
    "# 임베딩 추출 및 저장\n",
    "for mp4, lbl, cat, split in tqdm(all_mp4s, desc='Extracting', ncols=80):\n",
    "    vid = mp4.stem\n",
    "    out_path = PER_VIDEO_DIR / f'{vid}.npy'\n",
    "    meta_path = PER_VIDEO_DIR / f'{vid}.json'\n",
    "    # --- 기존 임베딩이 있어도 무조건 새로 생성 ---\n",
    "    # if out_path.exists():\n",
    "    #     continue\n",
    "    clips = load_clip(mp4)\n",
    "    feats = []\n",
    "    for clip in clips:\n",
    "        c = clip.unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            out = embed_model.base.model.forward_features(c)\n",
    "        cls = out[:,0,:] if out.ndim==3 else out\n",
    "        feats.append(cls.squeeze(0).cpu().numpy())\n",
    "    emb = np.stack(feats,0).mean(0)\n",
    "    np.save(out_path, emb)\n",
    "    meta = {\n",
    "        'video_id': vid, 'label': lbl, 'category': cat, 'split': split,\n",
    "        'mp4_path': str(mp4)\n",
    "    }\n",
    "    with open(meta_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(meta, f, ensure_ascii=False, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timesformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
