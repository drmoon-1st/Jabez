{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca35136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 275개 mp4 처리\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|█████████████████████████████| 275/275 [08:08<00:00,  1.78s/it]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from decord import VideoReader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "# === 파라미터 직접 지정 ===\n",
    "ROOT = Path(r'D:/golfDataset/dataset')\n",
    "FUSION_DIR = Path(r'D:/Jabez/golf/fusion')\n",
    "PER_VIDEO_DIR = FUSION_DIR / 'embbeding_data' / 'timesformer' / 'per_video'\n",
    "PER_VIDEO_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PRETRAINED = Path(r'D:/timesformer/pretrained/TimeSformer_divST_96x4_224_K600.pyth')\n",
    "NUM_FRAMES = 32\n",
    "CLIPS_PER_VID = 5\n",
    "IMG_SIZE = 224\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "sys.path.append(r'D:/timesformer')\n",
    "from timesformer.models.vit import TimeSformer\n",
    "\n",
    "# transform\n",
    "mean = [0.45,0.45,0.45]; std=[0.225,0.225,0.225]\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "def uniform_sample(length, num):\n",
    "    if length >= num:\n",
    "        return np.linspace(0, length-1, num, dtype=int)\n",
    "    return np.pad(np.arange(length), (0,num-length), mode='edge')\n",
    "\n",
    "def load_clip(path: Path):\n",
    "    vr = VideoReader(str(path))\n",
    "    L  = len(vr)\n",
    "    segs = np.linspace(0, L, CLIPS_PER_VID+1, dtype=int)\n",
    "    clips = []\n",
    "    for s,e in zip(segs[:-1], segs[1:]):\n",
    "        idx = uniform_sample(e-s, NUM_FRAMES) + s\n",
    "        arr = vr.get_batch(idx).asnumpy()  # (T,H,W,3)\n",
    "        proc = []\n",
    "        for frame in arr:\n",
    "            img = transforms.ToPILImage()(frame)\n",
    "            img_t = eval_transform(img)\n",
    "            proc.append(img_t)\n",
    "        clip = torch.stack(proc, dim=1)  # (C,T,H,W)\n",
    "        clips.append(clip)\n",
    "    return clips\n",
    "\n",
    "# 모델 로드\n",
    "model = TimeSformer(\n",
    "    img_size=IMG_SIZE,\n",
    "    num_frames=NUM_FRAMES,\n",
    "    num_classes=2,\n",
    "    attention_type='divided_space_time',\n",
    "    pretrained_model=str(PRETRAINED)\n",
    ").to(DEVICE)\n",
    "for attr in ('head','cls_head'):\n",
    "    if hasattr(model, attr): setattr(model, attr, nn.Identity())\n",
    "    if hasattr(model, 'model') and hasattr(model.model, attr):\n",
    "        setattr(model.model, attr, nn.Identity())\n",
    "model.eval()\n",
    "\n",
    "# train, test 폴더 내 balanced_true/false/crop_video/*.mp4 모두 처리\n",
    "mapping = {'balanced_true': 1, 'false': 0}\n",
    "all_mp4s = []\n",
    "\n",
    "for split in ['train', 'test']:\n",
    "    split_root = ROOT / split\n",
    "    for cat, lbl in mapping.items():\n",
    "        vd = split_root / cat / 'crop_video'\n",
    "        if not vd.exists(): continue\n",
    "        for mp4 in vd.glob('*.mp4'):\n",
    "            all_mp4s.append((mp4, lbl, cat, split))\n",
    "\n",
    "print(f'총 {len(all_mp4s)}개 mp4 처리')\n",
    "\n",
    "for mp4, lbl, cat, split in tqdm(all_mp4s, desc='Extracting', ncols=80):\n",
    "    vid = mp4.stem\n",
    "    out_path = PER_VIDEO_DIR / f'{vid}.npy'\n",
    "    meta_path = PER_VIDEO_DIR / f'{vid}.json'\n",
    "    if out_path.exists():\n",
    "        continue\n",
    "    clips = load_clip(mp4)\n",
    "    feats = []\n",
    "    for clip in clips:\n",
    "        c = clip.unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            out = model.model.forward_features(c)\n",
    "        cls = out[:,0,:] if out.ndim==3 else out\n",
    "        feats.append(cls.squeeze(0).cpu().numpy())\n",
    "    emb = np.stack(feats,0).mean(0)\n",
    "    np.save(out_path, emb)\n",
    "    meta = {\n",
    "        'video_id': vid, 'label': lbl, 'category': cat, 'split': split,\n",
    "        'mp4_path': str(mp4)\n",
    "    }\n",
    "    with open(meta_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(meta, f, ensure_ascii=False, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timesformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
