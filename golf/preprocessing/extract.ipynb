{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체 폴더 처리 코드(순회)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def find_json_files(root_folder):\n",
    "    json_files = [os.path.join(root, file) for root, _, files in os.walk(root_folder) for file in files if file.endswith(\".json\")]\n",
    "    print(f\"[DEBUG] Found {len(json_files)} JSON files in {root_folder}\")\n",
    "    return json_files\n",
    "\n",
    "def extract_skeleton_points(json_data):\n",
    "    for annotation in json_data.get(\"annotations\", []):\n",
    "        if annotation.get(\"class\") == \"person\" and \"points\" in annotation:\n",
    "            points = annotation[\"points\"]\n",
    "            if isinstance(points, list) and len(points) % 3 == 0:\n",
    "                return [(points[i], points[i+1]) for i in range(0, len(points), 3)]\n",
    "            if all(isinstance(pt, (list, tuple)) and len(pt) == 2 for pt in points):\n",
    "                return points\n",
    "    return None\n",
    "\n",
    "def is_impact_front_view(points):\n",
    "    try:\n",
    "        left_shoulder_x, right_shoulder_x = points[5][0], points[2][0]\n",
    "        left_wrist_x, right_wrist_x = points[9][0], points[6][0]\n",
    "        return right_shoulder_x <= right_wrist_x <= left_shoulder_x and right_shoulder_x <= left_wrist_x <= left_shoulder_x\n",
    "    except (TypeError, IndexError):\n",
    "        print(f\"[DEBUG] Invalid points format: {points}\")\n",
    "        return False\n",
    "\n",
    "def is_impact_side_view(points, address_right_wrist, address_left_wrist):\n",
    "    try:\n",
    "        right_wrist, left_wrist = points[6], points[9]\n",
    "        if not (address_right_wrist and address_left_wrist):\n",
    "            return False\n",
    "        return (abs(right_wrist[0] - address_right_wrist[0]) + abs(right_wrist[1] - address_right_wrist[1]) +\n",
    "                abs(left_wrist[0] - address_left_wrist[0]) + abs(left_wrist[1] - address_left_wrist[1])) < 150  # Threshold increased\n",
    "    except (TypeError, IndexError):\n",
    "        print(f\"[DEBUG] Invalid points format for side view: {points}\")\n",
    "        return False\n",
    "\n",
    "def extract_frame_number(filename):\n",
    "    try:\n",
    "        frame_str = os.path.splitext(os.path.basename(filename))[0].split('_')[-1]\n",
    "        return int(frame_str)\n",
    "    except ValueError:\n",
    "        print(f\"[DEBUG] Cannot extract frame number from {filename}\")\n",
    "        return None\n",
    "\n",
    "def get_title_prefix(filename):\n",
    "    parts = os.path.splitext(os.path.basename(filename))[0].split('_')\n",
    "    return '_'.join(parts[:-1]) if len(parts) > 1 else parts[0]\n",
    "\n",
    "def process_json_files(root_folder, output_csv, cluster_gap_threshold=5, margin=5):  # Margin increased\n",
    "    json_files = find_json_files(root_folder)\n",
    "    groups = {}\n",
    "    \n",
    "    for file in json_files:\n",
    "        title, frame_number = get_title_prefix(file), extract_frame_number(file)\n",
    "        if frame_number is not None:\n",
    "            groups.setdefault(title, []).append((frame_number, file))\n",
    "    \n",
    "    print(f\"[DEBUG] Grouped files into {len(groups)} unique titles\")\n",
    "    \n",
    "    impact_filenames = []\n",
    "    for title, files_info in groups.items():\n",
    "        files_info.sort()\n",
    "        \n",
    "        clusters, current_cluster = [], [files_info[0]]\n",
    "        for info in files_info[1:]:\n",
    "            if info[0] - current_cluster[-1][0] <= cluster_gap_threshold:\n",
    "                current_cluster.append(info)\n",
    "            else:\n",
    "                clusters.append(current_cluster)\n",
    "                current_cluster = [info]\n",
    "        clusters.append(current_cluster)\n",
    "        \n",
    "        if not clusters:\n",
    "            continue\n",
    "        \n",
    "        with open(clusters[0][0][1], \"r\", encoding=\"utf-8\") as f:\n",
    "            address_points = extract_skeleton_points(json.load(f))\n",
    "        if not address_points or len(address_points) < 10:\n",
    "            print(f\"[DEBUG] Address points missing or invalid in {clusters[0][0][1]}\")\n",
    "            continue\n",
    "        \n",
    "        address_right_wrist = address_points[6]\n",
    "        address_left_wrist = address_points[9]\n",
    "        \n",
    "        detected_impacts = []\n",
    "        for cluster in clusters[1:]:\n",
    "            impact_count = 0\n",
    "            total = len(cluster)\n",
    "            for _, file in cluster:\n",
    "                with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                    points = extract_skeleton_points(json.load(f))\n",
    "                if not points:\n",
    "                    continue\n",
    "                if is_impact_front_view(points) or is_impact_side_view(points, address_right_wrist, address_left_wrist):\n",
    "                    impact_count += 1\n",
    "                    detected_impacts.append(file)\n",
    "            print(f\"[DEBUG] Cluster {title}: {impact_count}/{total} impact frames detected\")\n",
    "        \n",
    "        if detected_impacts:\n",
    "            impact_filenames.extend(detected_impacts[-int(len(detected_impacts) / 2):])  # Keep only second half\n",
    "    \n",
    "    pd.DataFrame(impact_filenames, columns=[\"filename\"]).to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"[DEBUG] Impact 조건을 만족하는 {len(impact_filenames)}개의 JSON 파일 목록이 {output_csv}에 저장되었습니다.\")\n",
    "\n",
    "# 실행 예시\n",
    "root_folder = r\"D:\\\\golfDataset\\\\스포츠 사람 동작 영상(골프)\\\\Training\"\n",
    "output_csv = \"impact_filenames.csv\"\n",
    "process_json_files(root_folder, output_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 특정 폴더 처리 코드(시간절약, 테스트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impact 조건을 만족하는 JSON 파일 목록이 impact_filenames.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def find_json_files(root_folder):\n",
    "    \"\"\" 주어진 폴더 내의 JSON 파일만 반환한다. \"\"\"\n",
    "    return [\n",
    "        os.path.join(root_folder, file)\n",
    "        for file in os.listdir(root_folder)\n",
    "        if os.path.isfile(os.path.join(root_folder, file)) and file.lower().endswith(\".json\")\n",
    "    ]\n",
    "\n",
    "def extract_skeleton_points(json_data):\n",
    "    \"\"\" JSON에서 class가 person인 객체의 points 값을 가져오고, (x, y, visibility) 형식이면 (x, y)만 추출한다. \"\"\"\n",
    "    for annotation in json_data.get(\"annotations\", []):\n",
    "        if annotation.get(\"class\") == \"person\" and \"points\" in annotation:\n",
    "            points = annotation[\"points\"]\n",
    "            \n",
    "            # Mediapipe 스타일의 (x, y, visibility) 리스트일 경우 (x, y)만 추출\n",
    "            if isinstance(points, list) and all(isinstance(pt, (int, float)) for pt in points):\n",
    "                if len(points) % 3 == 0:  # (x, y, visibility) 구조인지 확인\n",
    "                    return [(points[i], points[i+1]) for i in range(0, len(points), 3)]\n",
    "            \n",
    "            # (x, y) 형태인지 확인\n",
    "            if all(isinstance(pt, (list, tuple)) and len(pt) == 2 for pt in points):\n",
    "                return points\n",
    "            \n",
    "            print(f\"Invalid points format: {points}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def is_impact_front_view(points):\n",
    "    \"\"\" 정면 및 유사 방향에서의 impact 판단: 양쪽 손목이 양쪽 어깨의 x좌표 내에 존재하는지 확인 \"\"\"\n",
    "    if not points or len(points) < 16:\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        left_shoulder_x, right_shoulder_x = points[4][0], points[3][0]\n",
    "        left_wrist_x, right_wrist_x = points[8][0], points[7][0]\n",
    "    except (TypeError, IndexError) as e:\n",
    "        print(f\"Error accessing points: {points} - {e}\")\n",
    "        return False\n",
    "    \n",
    "    return right_shoulder_x <= right_wrist_x <= left_shoulder_x and right_shoulder_x <= left_wrist_x <= left_shoulder_x\n",
    "\n",
    "def is_impact_side_view(points, address_right_wrist, address_left_wrist):\n",
    "    \"\"\" 측면 방향에서의 impact 판단: 현재 프레임의 손목 위치와 어드레스 시점의 손목 위치 차이가 작으면 impact로 간주 \"\"\"\n",
    "    if not points or len(points) < 16:\n",
    "        return False\n",
    "    \n",
    "    right_wrist, left_wrist = points[7], points[8]\n",
    "    if not (address_right_wrist and address_left_wrist):\n",
    "        return False\n",
    "    \n",
    "    right_diff = abs(right_wrist[0] - address_right_wrist[0]) + abs(right_wrist[1] - address_right_wrist[1])\n",
    "    left_diff = abs(left_wrist[0] - address_left_wrist[0]) + abs(left_wrist[1] - address_left_wrist[1])\n",
    "    \n",
    "    return (right_diff + left_diff) < 50  # 임계값 미만이면 impact\n",
    "\n",
    "def extract_frame_number(filename):\n",
    "    \"\"\"\n",
    "    파일 이름에서 마지막 4자리 숫자를 추출한다.\n",
    "    예: 20201124_General_035_DOS_A_M40_BT_001_0001.json -> 1 반환\n",
    "    \"\"\"\n",
    "    basename = os.path.basename(filename)\n",
    "    name_without_ext = os.path.splitext(basename)[0]\n",
    "    parts = name_without_ext.split('_')\n",
    "    if parts:\n",
    "        frame_str = parts[-1]\n",
    "        try:\n",
    "            return int(frame_str)\n",
    "        except ValueError:\n",
    "            print(f\"Cannot convert {frame_str} to int in filename {filename}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def get_title_prefix(filename):\n",
    "    \"\"\"\n",
    "    파일 이름에서 마지막 4자리 숫자(프레임 번호)를 제외한 제목(prefix)을 반환한다.\n",
    "    예: 20201124_General_035_DOS_A_M40_BT_001_0001.json -> 20201124_General_035_DOS_A_M40_BT_001\n",
    "    \"\"\"\n",
    "    basename = os.path.basename(filename)\n",
    "    name_without_ext = os.path.splitext(basename)[0]\n",
    "    parts = name_without_ext.split('_')\n",
    "    if len(parts) > 1:\n",
    "        return '_'.join(parts[:-1])\n",
    "    return name_without_ext\n",
    "\n",
    "def process_json_files(root_folder, output_csv, cluster_gap_threshold=5, margin=2):\n",
    "    \"\"\"\n",
    "    - json 파일을 파일명(prefix)별로 그룹화하여,\n",
    "      한 동작에서 어드레스와 임팩트를 구분한다.\n",
    "    - 각 그룹 내에서 프레임 번호가 연속(갭이 cluster_gap_threshold 이하인 경우)하는 것을 하나의 클러스터로 판단.\n",
    "    - 첫번째 클러스터는 어드레스(주소)로 간주하여 CSV에 저장하지 않고,\n",
    "      이후 클러스터 중 과반수 프레임이 impact 조건(정면 혹은 측면)을 만족하면 impact 클러스터로 판단.\n",
    "    - impact 클러스터에 대해서는 양쪽 끝에서 margin 만큼 추가 프레임도 포함시킨다.\n",
    "    \"\"\"\n",
    "    json_files = find_json_files(root_folder)\n",
    "    # 그룹화: title_prefix -> list of (frame_number, full_path, basename)\n",
    "    groups = {}\n",
    "    for file in json_files:\n",
    "        title = get_title_prefix(file)\n",
    "        frame_number = extract_frame_number(file)\n",
    "        if frame_number is None:\n",
    "            continue\n",
    "        groups.setdefault(title, []).append((frame_number, file, os.path.basename(file)))\n",
    "    \n",
    "    impact_filenames = []\n",
    "    \n",
    "    # 각 그룹별 처리\n",
    "    for title, files_info in groups.items():\n",
    "        # 프레임 번호 기준 정렬\n",
    "        files_info.sort(key=lambda x: x[0])\n",
    "        \n",
    "        # 클러스터 생성 (연속성 기준: 인접 프레임 번호 차이가 cluster_gap_threshold 이하)\n",
    "        clusters = []\n",
    "        current_cluster = [files_info[0]]\n",
    "        for info in files_info[1:]:\n",
    "            if info[0] - current_cluster[-1][0] <= cluster_gap_threshold:\n",
    "                current_cluster.append(info)\n",
    "            else:\n",
    "                clusters.append(current_cluster)\n",
    "                current_cluster = [info]\n",
    "        clusters.append(current_cluster)\n",
    "        \n",
    "        if not clusters:\n",
    "            continue\n",
    "        \n",
    "        # 첫번째 클러스터는 어드레스(주소)로 간주\n",
    "        address_cluster = clusters[0]\n",
    "        # 어드레스 시점의 손목 좌표는 해당 클러스터의 첫번째 파일에서 추출\n",
    "        with open(address_cluster[0][1], \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        address_points = extract_skeleton_points(data)\n",
    "        if address_points and len(address_points) >= 9:\n",
    "            address_right_wrist, address_left_wrist = address_points[7], address_points[8]\n",
    "        else:\n",
    "            address_right_wrist, address_left_wrist = None, None\n",
    "        \n",
    "        # 두번째 클러스터부터 impact 여부 판단\n",
    "        for cluster in clusters[1:]:\n",
    "            impact_count = 0\n",
    "            total = len(cluster)\n",
    "            for _, file_path, _ in cluster:\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    data = json.load(f)\n",
    "                points = extract_skeleton_points(data)\n",
    "                if not points:\n",
    "                    continue\n",
    "                if is_impact_front_view(points) or is_impact_side_view(points, address_right_wrist, address_left_wrist):\n",
    "                    impact_count += 1\n",
    "            # 과반수 이상이 impact 조건을 만족하면 해당 클러스터를 impact 클러스터로 판단\n",
    "            if impact_count >= total / 2:\n",
    "                # 클러스터의 최소, 최대 프레임 번호로 확장(여유 margin 추가)\n",
    "                start_frame = cluster[0][0]\n",
    "                end_frame = cluster[-1][0]\n",
    "                extended_cluster = []\n",
    "                # 같은 그룹 내에서 margin 범위 내의 모든 프레임을 포함 (이미 포함된 클러스터와 중복되지 않도록)\n",
    "                for info in files_info:\n",
    "                    if start_frame - margin <= info[0] <= end_frame + margin:\n",
    "                        extended_cluster.append(info)\n",
    "                for _, _, fname in extended_cluster:\n",
    "                    if fname not in impact_filenames:\n",
    "                        impact_filenames.append(fname)\n",
    "            # 만약 후반에 나타난 클러스터가 address로 예측된다면, 따로 impact로 추가하지 않음.\n",
    "    \n",
    "    df = pd.DataFrame(impact_filenames, columns=[\"filename\"])\n",
    "    df.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"Impact 조건을 만족하는 JSON 파일 목록이 {output_csv}에 저장되었습니다.\")\n",
    "\n",
    "# 실행 예시\n",
    "root_folder = r\"D:\\golfDataset\\스포츠 사람 동작 영상(골프)\\Training\\Amateur\\male\\[라벨]swing_03\\20201123_General_002_DIS_S_M20_SS\"\n",
    "output_csv = \"impact_filenames.csv\"\n",
    "process_json_files(root_folder, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] CSV에서 13개의 파일명을 로드했습니다.\n",
      "[DEBUG] JSON 변환 후 파일 목록 예시: ['20201124_General_035_DOS_A_M40_BT_062_0113.jpg', '20201124_General_035_DOS_A_M40_BT_062_0114.jpg', '20201124_General_035_DOS_A_M40_BT_062_0110.jpg', '20201124_General_035_DOS_A_M40_BT_062_0107.jpg', '20201124_General_035_DOS_A_M40_BT_062_0111.jpg']\n",
      "[INFO] 총 13/13개의 파일이 복사되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "def copy_matching_images(csv_file, source_folder, target_folder):\n",
    "    \"\"\" impact_filenames.csv에 기록된 파일과 동일한 이름의 jpg 파일을 images 폴더로 복사 (하위 폴더 포함) \"\"\"\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.makedirs(target_folder)\n",
    "\n",
    "    # CSV 파일에서 파일 이름 읽기\n",
    "    df = pd.read_csv(csv_file, encoding=\"utf-8-sig\")\n",
    "    \n",
    "    if \"filename\" not in df.columns:\n",
    "        raise KeyError(\"CSV 파일에 'filename' 열이 없습니다.\")\n",
    "\n",
    "    df[\"filename\"] = df[\"filename\"].astype(str).str.strip()\n",
    "    \n",
    "    # 파일명을 추출하여 JSON → JPG 변환\n",
    "    json_filenames = set(os.path.basename(x).replace(\".json\", \".jpg\") for x in df[\"filename\"])\n",
    "\n",
    "    print(f\"[DEBUG] CSV에서 {len(json_filenames)}개의 파일명을 로드했습니다.\")\n",
    "    print(f\"[DEBUG] JSON 변환 후 파일 목록 예시: {list(json_filenames)[:5]}\")\n",
    "\n",
    "    copied_files = 0\n",
    "    missing_files = []\n",
    "\n",
    "    # 재귀적으로 모든 하위 폴더 탐색\n",
    "    for root, _, files in os.walk(source_folder):\n",
    "        for file in files:\n",
    "            if os.path.basename(file) in json_filenames:  # 파일명만 비교\n",
    "                source_path = os.path.join(root, file)\n",
    "                target_path = os.path.join(target_folder, file)\n",
    "                \n",
    "                shutil.copy(source_path, target_path)\n",
    "                copied_files += 1\n",
    "            else:\n",
    "                missing_files.append(file)\n",
    "\n",
    "    print(f\"[INFO] 총 {copied_files}/{len(json_filenames)}개의 파일이 복사되었습니다.\")\n",
    "\n",
    "# 실행 예시\n",
    "source_folder = r\"D:\\\\golfDataset\\\\스포츠 사람 동작 영상(골프)\\\\Training\"\n",
    "target_folder = r\"D:\\\\golfDataset\\\\preprocessing\\\\impact_images\"\n",
    "csv_file = \"impact_filenames.csv\"\n",
    "\n",
    "copy_matching_images(csv_file, source_folder, target_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
