{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28cde1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Saved D:\\golfDataset\\스포츠 사람 동작 영상(골프)\\Training\\Public\\male\\train\\crop_pkl\\skeleton_dataset_90_10.pkl with 436 samples: 392 train, 44 val\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "OpenPose CSV → MMAction2 Skeleton PKL 변환 스크립트\n",
    "하나의 PKL 파일에 전체 데이터와 90/10 split 정보(xsub_train/xsub_val)를 저장합니다.\n",
    "balanced_true 폴더의 CSV는 label=1, false 폴더의 CSV는 label=0으로 설정합니다.\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# BODY_25 → COCO17 매핑\n",
    "MAPPING_BODY25_TO_COCO17 = [\n",
    "    0, 16, 15, 18, 17,\n",
    "    5, 2, 6, 3, 7,\n",
    "    4, 12, 9, 13, 10,\n",
    "    14, 11\n",
    "]\n",
    "\n",
    "\n",
    "def load_and_process(csv_path: Path,\n",
    "                     img_shape=(1080, 1920),\n",
    "                     confidence_threshold=0.1,\n",
    "                     interpolate=True,  # 기본 보간 활성화,\n",
    "                     normalize_method='0to1') -> dict:\n",
    "    \"\"\"\n",
    "    단일 CSV 파일을 읽어 annotation dict 반환\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    T = len(df)\n",
    "    V25 = 25\n",
    "\n",
    "    kp25 = np.zeros((1, T, V25, 2), dtype=np.float32)\n",
    "    score25 = np.zeros((1, T, V25), dtype=np.float32)\n",
    "    for t, row in df.iterrows():\n",
    "        vals = row.values.reshape(-1, 3)\n",
    "        # NaN/Inf 처리: 이상치 0으로 대체\n",
    "        vals = np.nan_to_num(vals, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        kp25[0, t] = vals[:, :2]\n",
    "        score25[0, t] = vals[:, 2]\n",
    "\n",
    "    # confidence filter\n",
    "    low = score25 < confidence_threshold\n",
    "    kp25[low] = 0\n",
    "    score25[low] = 0\n",
    "\n",
    "    # interpolation\n",
    "    h, w = img_shape\n",
    "    if normalize_method == '0to1':\n",
    "        kp25[..., 0] /= w\n",
    "        kp25[..., 1] /= h\n",
    "    elif normalize_method == 'center':\n",
    "        kp25[..., 0] = (kp25[..., 0] - w/2) / (w/2)\n",
    "        kp25[..., 1] = (kp25[..., 1] - h/2) / (h/2)\n",
    "    elif normalize_method == 'skeleton_center':\n",
    "        for t in range(T):\n",
    "            pts = kp25[0, t]\n",
    "            valid = np.all(pts != 0, axis=1)\n",
    "            if valid.any():\n",
    "                cxy = pts[valid].mean(axis=0)\n",
    "                bbox = pts[valid]\n",
    "                scale = max(bbox[:,0].ptp(), bbox[:,1].ptp())\n",
    "                if scale > 0:\n",
    "                    kp25[0, t] = (pts - cxy) / scale\n",
    "\n",
    "    # COCO17 변환\n",
    "    kp17 = kp25[:, :, MAPPING_BODY25_TO_COCO17, :]\n",
    "    score17 = score25[:, :, MAPPING_BODY25_TO_COCO17]\n",
    "\n",
    "    sample = {\n",
    "        'total_frames': T,\n",
    "        'img_shape': img_shape,\n",
    "        'original_shape': img_shape,\n",
    "        'keypoint': kp17,\n",
    "        'keypoint_score': score17\n",
    "    }\n",
    "    return sample\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 기본 경로 설정\n",
    "    BASE = Path(r'D:/golfDataset/스포츠 사람 동작 영상(골프)/Training/Public/male/train')\n",
    "    cats = ['balanced_true', 'false']\n",
    "\n",
    "    # 전체 CSV 파일 목록 수집\n",
    "    all_csvs = []\n",
    "    for cat in cats:\n",
    "        all_csvs.extend((BASE / cat / 'crop_keypoint').glob('*.csv'))\n",
    "    all_csvs = sorted(all_csvs)\n",
    "\n",
    "    # 90/10 split\n",
    "    random.seed()   # 현재 시간 기반 시드 설정\n",
    "    ids = [p.stem for p in all_csvs]\n",
    "    random.shuffle(ids)\n",
    "    split_idx = int(len(ids) * 0.9)\n",
    "    train_set = set(ids[:split_idx])\n",
    "    val_set = set(ids[split_idx:])\n",
    "\n",
    "    # annotations 및 split 사전 초기화\n",
    "    annotations = []\n",
    "    split_dict = {'xsub_train': [], 'xsub_val': []}\n",
    "\n",
    "    for csv_path in all_csvs:\n",
    "        fid = csv_path.stem\n",
    "        # annotation 생성\n",
    "        info = load_and_process(csv_path, interpolate=True)\n",
    "        # 폴더 이름으로 레이블 설정\n",
    "        category = csv_path.parent.parent.name\n",
    "        label = 1 if category == 'balanced_true' else 0\n",
    "        info.update({'frame_dir': fid, 'label': label})\n",
    "        annotations.append(info)\n",
    "\n",
    "        # split 기록\n",
    "        if fid in train_set:\n",
    "            split_dict['xsub_train'].append(fid)\n",
    "        else:\n",
    "            split_dict['xsub_val'].append(fid)\n",
    "\n",
    "    # 전체 데이터 패키징\n",
    "    data = {'split': split_dict, 'annotations': annotations}\n",
    "\n",
    "    # PKL 저장\n",
    "    out_pkl = BASE / 'crop_pkl' / 'skeleton_dataset_90_10.pkl'\n",
    "    out_pkl.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_pkl, 'wb') as f:\n",
    "        pickle.dump(data, f, protocol=4)\n",
    "    print(f\"[DONE] Saved {out_pkl} with {len(annotations)} samples: \"\n",
    "          f\"{len(split_dict['xsub_train'])} train, {len(split_dict['xsub_val'])} val\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmaction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
