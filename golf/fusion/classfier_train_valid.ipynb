{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83923be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Î°úÎìú ÏôÑÎ£å: train=392  valid=44\n",
      "Fused dims ‚Üí train:(392, 1024), valid:(44, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qqppq\\AppData\\Local\\Temp\\ipykernel_22352\\4148548505.py:40: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(arr, axis=1)         # (N, 256)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Î™®Îç∏ ÌååÎùºÎØ∏ÌÑ∞ Ïàò: 590,722\n",
      "[01/40]  loss=nan  train_acc=47.96%  valid_acc=45.45%\n",
      "[02/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[03/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[04/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[05/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[06/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[07/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[08/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[09/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[10/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[11/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[12/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[13/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[14/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[15/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[16/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[17/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[18/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[19/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[20/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[21/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[22/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[23/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[24/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[25/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[26/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[27/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[28/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[29/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[30/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[31/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[32/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[33/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[34/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[35/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[36/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[37/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[38/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[39/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "[40/40]  loss=nan  train_acc=50.51%  valid_acc=45.45%\n",
      "\n",
      "‚úÖ Í∞ÄÏ§ëÏπò Ï†ÄÏû• ‚Üí D:\\golf\\fusion_ckpt\\fusion_mlp_best.pth\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4545    1.0000    0.6250        20\n",
      "           1     0.0000    0.0000    0.0000        24\n",
      "\n",
      "    accuracy                         0.4545        44\n",
      "   macro avg     0.2273    0.5000    0.3125        44\n",
      "weighted avg     0.2066    0.4545    0.2841        44\n",
      "\n",
      "üèÖ Best VALID ACC = 45.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qqppq\\anaconda3\\envs\\fusion\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\qqppq\\anaconda3\\envs\\fusion\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\qqppq\\anaconda3\\envs\\fusion\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "#               ÏÑ§Ï†ï(ÌïÑÏöî ÏãúÎßå ÏàòÏ†ï)\n",
    "# =========================================================\n",
    "from pathlib import Path\n",
    "DATA_ROOT = Path(r\"embbeding_data\")   # embbeding_data Ìè¥Îçî\n",
    "AGG_METHOD = \"mean\"           # \"mean\" | \"max\" | \"flatten\"\n",
    "BATCH      = 128\n",
    "EPOCHS     = 40\n",
    "LR         = 0.005\n",
    "DEVICE     = \"cuda:0\" if __import__(\"torch\").cuda.is_available() else \"cpu\"\n",
    "SAVE_DIR   = Path(r\"D:\\golf\\fusion_ckpt\")     # None ‚Üí Ï†ÄÏû• ÏÉùÎûµ\n",
    "# =========================================================\n",
    "\n",
    "import json, time, numpy as np, torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# ---------- Îç∞Ïù¥ÌÑ∞ Î°úÎìú --------------------------------------------------\n",
    "def load_split(split: str, model: str):\n",
    "    \"\"\"split=train|valid, model=stgcnpp|timesformer\"\"\"\n",
    "    base = DATA_ROOT / model / split\n",
    "    emb  = np.load(base / \"embeddings.npy\")\n",
    "    lbl  = np.load(base / \"labels.npy\").ravel()\n",
    "    return emb, lbl\n",
    "\n",
    "ts_tr, y_tr = load_split(\"train\", \"timesformer\")   # (N_tr, 768)\n",
    "ts_va, y_va = load_split(\"valid\", \"timesformer\")\n",
    "st_tr, _    = load_split(\"train\", \"stgcnpp\")       # (N_tr, 10, 256)\n",
    "st_va, _    = load_split(\"valid\", \"stgcnpp\")\n",
    "\n",
    "assert (y_tr == np.load(DATA_ROOT/\"stgcnpp/train/labels.npy\").ravel()).all()\n",
    "assert (y_va == np.load(DATA_ROOT/\"stgcnpp/valid/labels.npy\").ravel()).all()\n",
    "print(f\"‚úÖ Î°úÎìú ÏôÑÎ£å: train={ts_tr.shape[0]}  valid={ts_va.shape[0]}\")\n",
    "\n",
    "\n",
    "# ---------- ST-GCN ÏûÑÎ≤†Îî© (N,10,256) ‚Üí (N,256 ÎòêÎäî 2560) ---------------\n",
    "def reduce_stgcn(arr):\n",
    "    if AGG_METHOD == \"mean\":\n",
    "        return np.nanmean(arr, axis=1)         # (N, 256)\n",
    "    if AGG_METHOD == \"max\":\n",
    "        return np.nanmax(arr, axis=1)\n",
    "    if AGG_METHOD == \"flatten\":\n",
    "        return arr.reshape(arr.shape[0], -1)   # (N, 2560)\n",
    "    raise ValueError(f\"AGG_METHOD={AGG_METHOD}\")\n",
    "\n",
    "st_tr_flat = reduce_stgcn(st_tr)\n",
    "st_va_flat = reduce_stgcn(st_va)\n",
    "\n",
    "# ---------- ÌäπÏßï Í≤∞Ìï© ----------------------------------------------------\n",
    "X_tr = np.concatenate([ts_tr, st_tr_flat], axis=1).astype(np.float32)\n",
    "X_va = np.concatenate([ts_va, st_va_flat], axis=1).astype(np.float32)\n",
    "y_tr = y_tr.astype(np.int64)\n",
    "y_va = y_va.astype(np.int64)\n",
    "\n",
    "print(f\"Fused dims ‚Üí train:{X_tr.shape}, valid:{X_va.shape}\")\n",
    "\n",
    "\n",
    "# ---------- PyTorch Dataset / DataLoader --------------------------------\n",
    "ds_tr = TensorDataset(torch.from_numpy(X_tr), torch.from_numpy(y_tr))\n",
    "ds_va = TensorDataset(torch.from_numpy(X_va), torch.from_numpy(y_va))\n",
    "dl_tr = DataLoader(ds_tr, batch_size=BATCH, shuffle=True,  drop_last=False)\n",
    "dl_va = DataLoader(ds_va, batch_size=BATCH, shuffle=False, drop_last=False)\n",
    "\n",
    "\n",
    "# ---------- Î™®Îç∏ ---------------------------------------------------------\n",
    "class FusionMLP(nn.Module):\n",
    "    def __init__(self, in_dim, n_cls, hidden=(512, 128), p_drop=0.3):\n",
    "        super().__init__()\n",
    "        layers, dims = [], [in_dim, *hidden]\n",
    "        for d_in, d_out in zip(dims[:-1], dims[1:]):\n",
    "            layers += [nn.Linear(d_in, d_out), nn.ReLU(), nn.Dropout(p_drop)]\n",
    "        layers += [nn.Linear(dims[-1], n_cls)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):            # (B, in_dim)\n",
    "        return self.net(x)\n",
    "\n",
    "n_cls = int(max(y_tr.max(), y_va.max())) + 1\n",
    "model = FusionMLP(in_dim=X_tr.shape[1], n_cls=n_cls).to(DEVICE)\n",
    "opt    = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "crit   = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"üîß Î™®Îç∏ ÌååÎùºÎØ∏ÌÑ∞ Ïàò: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "\n",
    "# ---------- ÌïôÏäµ / ÌèâÍ∞Ä Î£®ÌîÑ -------------------------------------------\n",
    "best_acc, best_state = 0.0, None\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    # --- train ---\n",
    "    model.train()\n",
    "    loss_sum, n_correct, n_total = 0.0, 0, 0\n",
    "    for x, y in dl_tr:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        opt.zero_grad()\n",
    "        out  = model(x)\n",
    "        loss = crit(out, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        loss_sum  += loss.item() * y.size(0)\n",
    "        n_correct += (out.argmax(1) == y).sum().item()\n",
    "        n_total   += y.size(0)\n",
    "\n",
    "    tr_loss = loss_sum / n_total\n",
    "    tr_acc  = n_correct / n_total\n",
    "\n",
    "    # --- valid ---\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dl_va:\n",
    "            x = x.to(DEVICE)\n",
    "            out = model(x)\n",
    "            y_true.append(y)\n",
    "            y_pred.append(out.argmax(1).cpu())\n",
    "    y_true = torch.cat(y_true).numpy()\n",
    "    y_pred = torch.cat(y_pred).numpy()\n",
    "    va_acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"[{epoch:02d}/{EPOCHS}]  \"\n",
    "          f\"loss={tr_loss:.4f}  train_acc={tr_acc*100:.2f}%  \"\n",
    "          f\"valid_acc={va_acc*100:.2f}%\")\n",
    "\n",
    "    if va_acc > best_acc:\n",
    "        best_acc, best_state = va_acc, model.state_dict()\n",
    "\n",
    "# ---------- ÏµúÏ†Å Î™®Îç∏ Ï†ÄÏû• ----------------------------------------------\n",
    "if SAVE_DIR:\n",
    "    SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(best_state, SAVE_DIR / \"fusion_mlp_best.pth\")\n",
    "    with open(SAVE_DIR / \"meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\n",
    "            \"input_dim\": X_tr.shape[1],\n",
    "            \"n_classes\": n_cls,\n",
    "            \"valid_acc\": best_acc,\n",
    "            \"agg_method\": AGG_METHOD,\n",
    "            \"hidden\": [512, 128],\n",
    "            \"epochs\": EPOCHS\n",
    "        }, f, indent=2)\n",
    "    print(f\"\\n‚úÖ Í∞ÄÏ§ëÏπò Ï†ÄÏû• ‚Üí {SAVE_DIR/'fusion_mlp_best.pth'}\")\n",
    "\n",
    "# ---------- ÏµúÏ¢Ö Î¶¨Ìè¨Ìä∏ --------------------------------------------------\n",
    "print(\"\\n\" + classification_report(y_true, y_pred, digits=4))\n",
    "print(f\"üèÖ Best VALID ACC = {best_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1542dfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  ÏÑúÎ°ú Îã§Î•∏ ÏúÑÏπò: [] ... Ï¥ù 0Í∞ú\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>ts_label</th>\n",
       "      <th>st_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [idx, ts_label, st_label]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "root = Path(r\"embbeding_data\")\n",
    "y_ts = np.load(root/'timesformer/train/labels.npy').ravel().astype(int)\n",
    "y_st = np.load(root/'stgcnpp/train/labels.npy').ravel().astype(int)\n",
    "\n",
    "mismatch_idx = np.where(y_ts != y_st)[0]\n",
    "print(f\"‚ö†Ô∏è  ÏÑúÎ°ú Îã§Î•∏ ÏúÑÏπò: {mismatch_idx[:10]} ... Ï¥ù {len(mismatch_idx)}Í∞ú\")\n",
    "pd.DataFrame({'idx': mismatch_idx,\n",
    "              'ts_label': y_ts[mismatch_idx],\n",
    "              'st_label': y_st[mismatch_idx]})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
