{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83923be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 로드 완료: train=392  valid=44\n",
      "Fused dims → train:(392, 1024), valid:(44, 1024)\n",
      "🔧 모델 파라미터 수: 1,312,514\n",
      "[01/60]  loss=0.6911  train_acc=51.28%  valid_acc=54.55%\n",
      "[02/60]  loss=0.6646  train_acc=63.27%  valid_acc=70.45%\n",
      "[03/60]  loss=0.6546  train_acc=67.09%  valid_acc=72.73%\n",
      "[04/60]  loss=0.6388  train_acc=67.09%  valid_acc=72.73%\n",
      "[05/60]  loss=0.6121  train_acc=69.90%  valid_acc=72.73%\n",
      "[06/60]  loss=0.5918  train_acc=70.92%  valid_acc=75.00%\n",
      "[07/60]  loss=0.5626  train_acc=78.57%  valid_acc=75.00%\n",
      "[08/60]  loss=0.5374  train_acc=79.59%  valid_acc=79.55%\n",
      "[09/60]  loss=0.5110  train_acc=79.08%  valid_acc=81.82%\n",
      "[10/60]  loss=0.4838  train_acc=82.40%  valid_acc=77.27%\n",
      "[11/60]  loss=0.4802  train_acc=79.59%  valid_acc=84.09%\n",
      "[12/60]  loss=0.4192  train_acc=84.69%  valid_acc=86.36%\n",
      "[13/60]  loss=0.4125  train_acc=84.44%  valid_acc=86.36%\n",
      "[14/60]  loss=0.3973  train_acc=84.95%  valid_acc=86.36%\n",
      "[15/60]  loss=0.3741  train_acc=86.99%  valid_acc=86.36%\n",
      "[16/60]  loss=0.3506  train_acc=85.97%  valid_acc=84.09%\n",
      "[17/60]  loss=0.3378  train_acc=88.52%  valid_acc=77.27%\n",
      "[18/60]  loss=0.3213  train_acc=87.50%  valid_acc=84.09%\n",
      "[19/60]  loss=0.2910  train_acc=89.80%  valid_acc=79.55%\n",
      "[20/60]  loss=0.2863  train_acc=90.56%  valid_acc=86.36%\n",
      "[21/60]  loss=0.2566  train_acc=91.84%  valid_acc=86.36%\n",
      "[22/60]  loss=0.2787  train_acc=90.31%  valid_acc=86.36%\n",
      "[23/60]  loss=0.2391  train_acc=91.58%  valid_acc=84.09%\n",
      "[24/60]  loss=0.2567  train_acc=91.07%  valid_acc=86.36%\n",
      "[25/60]  loss=0.2413  train_acc=91.58%  valid_acc=84.09%\n",
      "[26/60]  loss=0.2233  train_acc=92.60%  valid_acc=84.09%\n",
      "[27/60]  loss=0.2234  train_acc=92.60%  valid_acc=81.82%\n",
      "[28/60]  loss=0.2110  train_acc=94.90%  valid_acc=79.55%\n",
      "[29/60]  loss=0.2160  train_acc=93.88%  valid_acc=86.36%\n",
      "[30/60]  loss=0.2021  train_acc=93.11%  valid_acc=86.36%\n",
      "[31/60]  loss=0.1762  train_acc=94.90%  valid_acc=81.82%\n",
      "[32/60]  loss=0.1928  train_acc=94.90%  valid_acc=84.09%\n",
      "[33/60]  loss=0.1943  train_acc=93.11%  valid_acc=86.36%\n",
      "[34/60]  loss=0.1749  train_acc=94.90%  valid_acc=86.36%\n",
      "[35/60]  loss=0.1530  train_acc=95.15%  valid_acc=84.09%\n",
      "[36/60]  loss=0.1757  train_acc=93.88%  valid_acc=84.09%\n",
      "[37/60]  loss=0.1605  train_acc=96.17%  valid_acc=81.82%\n",
      "[38/60]  loss=0.1429  train_acc=96.17%  valid_acc=81.82%\n",
      "[39/60]  loss=0.1444  train_acc=96.43%  valid_acc=81.82%\n",
      "[40/60]  loss=0.1488  train_acc=95.66%  valid_acc=86.36%\n",
      "[41/60]  loss=0.1424  train_acc=96.68%  valid_acc=86.36%\n",
      "[42/60]  loss=0.1251  train_acc=97.19%  valid_acc=81.82%\n",
      "[43/60]  loss=0.1342  train_acc=96.68%  valid_acc=81.82%\n",
      "[44/60]  loss=0.1288  train_acc=96.94%  valid_acc=81.82%\n",
      "[45/60]  loss=0.1369  train_acc=96.68%  valid_acc=84.09%\n",
      "[46/60]  loss=0.1236  train_acc=96.94%  valid_acc=84.09%\n",
      "[47/60]  loss=0.1267  train_acc=97.96%  valid_acc=81.82%\n",
      "[48/60]  loss=0.1214  train_acc=97.70%  valid_acc=86.36%\n",
      "[49/60]  loss=0.1162  train_acc=97.70%  valid_acc=86.36%\n",
      "[50/60]  loss=0.1276  train_acc=96.94%  valid_acc=84.09%\n",
      "[51/60]  loss=0.1144  train_acc=97.19%  valid_acc=84.09%\n",
      "[52/60]  loss=0.1117  train_acc=96.43%  valid_acc=79.55%\n",
      "[53/60]  loss=0.1215  train_acc=97.19%  valid_acc=84.09%\n",
      "[54/60]  loss=0.1216  train_acc=96.94%  valid_acc=84.09%\n",
      "[55/60]  loss=0.1204  train_acc=97.70%  valid_acc=84.09%\n",
      "[56/60]  loss=0.1093  train_acc=97.70%  valid_acc=86.36%\n",
      "[57/60]  loss=0.0988  train_acc=97.96%  valid_acc=84.09%\n",
      "[58/60]  loss=0.1017  train_acc=98.21%  valid_acc=84.09%\n",
      "[59/60]  loss=0.0995  train_acc=97.70%  valid_acc=81.82%\n",
      "[60/60]  loss=0.0968  train_acc=97.96%  valid_acc=84.09%\n",
      "\n",
      "✅ 가중치 저장 → D:\\Jabez\\golf\\fusion\\fusion_ckpt\\fusion_mlp_best.pth\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8421    0.8000    0.8205        20\n",
      "           1     0.8400    0.8750    0.8571        24\n",
      "\n",
      "    accuracy                         0.8409        44\n",
      "   macro avg     0.8411    0.8375    0.8388        44\n",
      "weighted avg     0.8410    0.8409    0.8405        44\n",
      "\n",
      "🏅 Best VALID ACC = 86.36%\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "#               설정(필요 시만 수정)\n",
    "# =========================================================\n",
    "from pathlib import Path\n",
    "import json, time, numpy as np, torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------- 하이퍼파라미터 ----------------------\n",
    "DATA_ROOT = Path(r\"embbeding_data\")   # 임베딩 데이터 폴더\n",
    "AGG_METHOD = \"mean\"                   # \"mean\" | \"max\" | \"flatten\"\n",
    "BATCH      = 64                        # 배치 크기\n",
    "EPOCHS     = 60                        # 에폭 수\n",
    "LR         = 1e-4                      # 학습률\n",
    "WEIGHT_DECAY = 1e-4                    # AdamW 가중치 감쇠\n",
    "HIDDEN_DIMS = (1024, 256)              # 은닉층 크기\n",
    "DROPOUT_P  = 0.5                       # 드롭아웃 비율\n",
    "DEVICE     = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "SAVE_DIR   = Path(r\"D:\\golf\\fusion_ckpt\")  # 저장 디렉토리\n",
    "\n",
    "# ---------- 데이터 로드 --------------------------------------------------\n",
    "def load_split(split: str, model: str):\n",
    "    base = DATA_ROOT / model / split\n",
    "    emb  = np.load(base / \"embeddings.npy\")\n",
    "    lbl  = np.load(base / \"labels.npy\").ravel()\n",
    "    return emb, lbl\n",
    "\n",
    "# Timesformer & ST-GCN 임베딩 로드\n",
    "ts_tr, y_tr = load_split(\"train\", \"timesformer\")\n",
    "ts_va, y_va = load_split(\"valid\", \"timesformer\")\n",
    "st_tr, _    = load_split(\"train\", \"stgcnpp\")\n",
    "st_va, _    = load_split(\"valid\", \"stgcnpp\")\n",
    "\n",
    "# 레이블 확인\n",
    "assert (y_tr == np.load(DATA_ROOT/\"stgcnpp/train/labels.npy\").ravel()).all()\n",
    "assert (y_va == np.load(DATA_ROOT/\"stgcnpp/valid/labels.npy\").ravel()).all()\n",
    "print(f\"✅ 로드 완료: train={ts_tr.shape[0]}  valid={ts_va.shape[0]}\")\n",
    "\n",
    "# ---------- ST-GCN 임베딩 축소 -------------------------------------------\n",
    "def reduce_stgcn(arr):\n",
    "    if AGG_METHOD == \"mean\":\n",
    "        return np.nanmean(arr, axis=1)\n",
    "    if AGG_METHOD == \"max\":\n",
    "        return np.nanmax(arr, axis=1)\n",
    "    if AGG_METHOD == \"flatten\":\n",
    "        return arr.reshape(arr.shape[0], -1)\n",
    "    raise ValueError(f\"AGG_METHOD={AGG_METHOD}\")\n",
    "\n",
    "st_tr_flat = reduce_stgcn(st_tr)\n",
    "st_va_flat = reduce_stgcn(st_va)\n",
    "\n",
    "# ---------- 특징 결합 ----------------------------------------------------\n",
    "X_tr = np.concatenate([ts_tr, st_tr_flat], axis=1).astype(np.float32)\n",
    "X_va = np.concatenate([ts_va, st_va_flat], axis=1).astype(np.float32)\n",
    "y_tr = y_tr.astype(np.int64)\n",
    "y_va = y_va.astype(np.int64)\n",
    "\n",
    "print(f\"Fused dims → train:{X_tr.shape}, valid:{X_va.shape}\")\n",
    "\n",
    "# ---------- DataLoader --------------------------------------------------\n",
    "ds_tr = TensorDataset(torch.from_numpy(X_tr), torch.from_numpy(y_tr))\n",
    "ds_va = TensorDataset(torch.from_numpy(X_va), torch.from_numpy(y_va))\n",
    "dl_tr = DataLoader(ds_tr, batch_size=BATCH, shuffle=True)\n",
    "dl_va = DataLoader(ds_va, batch_size=BATCH, shuffle=False)\n",
    "\n",
    "# ---------- 모델 정의 ----------------------------------------------------\n",
    "class FusionMLP(nn.Module):\n",
    "    def __init__(self, in_dim, n_cls, hidden, p_drop):\n",
    "        super().__init__()\n",
    "        layers, dims = [], [in_dim, *hidden]\n",
    "        for d_in, d_out in zip(dims[:-1], dims[1:]):\n",
    "            layers += [nn.Linear(d_in, d_out), nn.ReLU(), nn.Dropout(p_drop)]\n",
    "        layers += [nn.Linear(dims[-1], n_cls)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# 클래스 수\n",
    "n_cls = int(max(y_tr.max(), y_va.max())) + 1\n",
    "model = FusionMLP(in_dim=X_tr.shape[1], n_cls=n_cls,\n",
    "                  hidden=HIDDEN_DIMS, p_drop=DROPOUT_P).to(DEVICE)\n",
    "opt   = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=20, gamma=0.5)\n",
    "crit  = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"🔧 모델 파라미터 수: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# ---------- 학습 및 평가 ----------------------------------------------\n",
    "train_losses, train_accs, val_accs = [], [], []\n",
    "val_probs = []\n",
    "\n",
    "best_acc, best_state = 0.0, None\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    # --- train ---\n",
    "    model.train()\n",
    "    loss_sum, n_correct, n_total = 0.0, 0, 0\n",
    "    for x, y in dl_tr:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        opt.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = crit(out, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        loss_sum  += loss.item() * y.size(0)\n",
    "        n_correct += (out.argmax(1) == y).sum().item()\n",
    "        n_total   += y.size(0)\n",
    "    scheduler.step()\n",
    "    tr_loss = loss_sum / n_total\n",
    "    tr_acc  = n_correct / n_total\n",
    "    train_losses.append(tr_loss)\n",
    "    train_accs.append(tr_acc)\n",
    "\n",
    "    # --- valid ---\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    probs_epoch = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dl_va:\n",
    "            x = x.to(DEVICE)\n",
    "            out = model(x)\n",
    "            prob = torch.softmax(out, dim=1)[:,1].cpu().numpy()\n",
    "            probs_epoch.extend(prob)\n",
    "            y_true.append(y)\n",
    "            y_pred.append(out.argmax(1).cpu())\n",
    "    y_true = torch.cat(y_true).numpy()\n",
    "    y_pred = torch.cat(y_pred).numpy()\n",
    "    val_acc = accuracy_score(y_true, y_pred)\n",
    "    val_accs.append(val_acc)\n",
    "    val_probs.append(probs_epoch)\n",
    "\n",
    "    print(f\"[{epoch:02d}/{EPOCHS}]  loss={tr_loss:.4f}  train_acc={tr_acc*100:.2f}%  valid_acc={val_acc*100:.2f}%\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc, best_state = val_acc, model.state_dict()\n",
    "        best_true, best_pred = y_true, y_pred\n",
    "        best_probs = probs_epoch.copy()\n",
    "\n",
    "# ---------- 저장 및 리포트 ----------------------------------------------\n",
    "if SAVE_DIR:\n",
    "    SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(best_state, SAVE_DIR / \"fusion_mlp_best.pth\")\n",
    "    with open(SAVE_DIR / \"meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\n",
    "            \"input_dim\": X_tr.shape[1],\n",
    "            \"n_classes\": n_cls,\n",
    "            \"valid_acc\": best_acc,\n",
    "            \"agg_method\": AGG_METHOD,\n",
    "            \"hidden\": list(HIDDEN_DIMS),\n",
    "            \"epochs\": EPOCHS,\n",
    "            \"lr\": LR,\n",
    "            \"batch\": BATCH\n",
    "        }, f, indent=2)\n",
    "    print(f\"\\n✅ 가중치 저장 → {SAVE_DIR/'fusion_mlp_best.pth'}\")\n",
    "\n",
    "# ---------- 최종 리포트 --------------------------------------------------\n",
    "print(\"\\n\" + classification_report(best_true, best_pred, digits=4))\n",
    "print(f\"🏅 Best VALID ACC = {best_acc*100:.2f}%\")\n",
    "\n",
    "# ---------- 학습 곡선 시각화 ----------------------------------------------\n",
    "epochs = list(range(1, EPOCHS+1))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_losses, label='Train Loss')\n",
    "plt.xlabel('Epoch'), plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve'), plt.legend()\n",
    "plt.savefig(SAVE_DIR / 'loss_curve.png')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_accs, label='Train Acc')\n",
    "plt.plot(epochs, val_accs, label='Val Acc')\n",
    "plt.xlabel('Epoch'), plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Curve'), plt.legend()\n",
    "plt.savefig(SAVE_DIR / 'accuracy_curve.png')\n",
    "\n",
    "# ---------- ROC 곡선 시각화 ----------------------------------------------\n",
    "y_true_all = np.array(best_true)\n",
    "y_scores_all = np.array(best_probs)\n",
    "fpr, tpr, _ = roc_curve(y_true_all, y_scores_all)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0,1], [0,1], '--')\n",
    "plt.xlabel('FPR'), plt.ylabel('TPR')\n",
    "plt.title('ROC Curve'), plt.legend()\n",
    "plt.savefig(SAVE_DIR / 'roc_curve.png')\n",
    "\n",
    "# ---------- 혼동 행렬 시각화 ----------------------------------------------\n",
    "cm = confusion_matrix(best_true, best_pred)\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.matshow(cm, cmap='Blues')\n",
    "for (i, j), z in np.ndenumerate(cm):\n",
    "    ax.text(j, i, str(z), ha='center', va='center')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xlabel('Predicted'), ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "fig.savefig(SAVE_DIR / 'confusion_matrix.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1542dfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\qqppq\\anaconda3\\envs\\fusion\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "  File \"C:\\Users\\qqppq\\AppData\\Local\\Temp\\ipykernel_1972\\1198015937.py\", line 1, in <module>\n",
      "    import numpy as np, pandas as pd\n",
      "ModuleNotFoundError: No module named 'numpy'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\qqppq\\anaconda3\\envs\\fusion\\lib\\site-packages\\pygments\\styles\\__init__.py\", line 45, in get_style_by_name\n",
      "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\qqppq\\anaconda3\\envs\\fusion\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2170, in showtraceback\n",
      "  File \"c:\\Users\\qqppq\\anaconda3\\envs\\fusion\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1457, in structured_traceback\n",
      "  File \"c:\\Users\\qqppq\\anaconda3\\envs\\fusion\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1348, in structured_traceback\n",
      "  File \"c:\\Users\\qqppq\\anaconda3\\envs\\fusion\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1195, in structured_traceback\n",
      "  File \"c:\\Users\\qqppq\\anaconda3\\envs\\fusion\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1085, in format_exception_as_a_whole\n",
      "  File \"c:\\Users\\qqppq\\anaconda3\\envs\\fusion\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1136, in get_records\n",
      "  File \"c:\\Users\\qqppq\\anaconda3\\envs\\fusion\\lib\\site-packages\\pygments\\styles\\__init__.py\", line 47, in get_style_by_name\n",
      "pygments.util.ClassNotFound: Could not find style module 'pygments.styles.default', though it should be builtin.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "root = Path(r\"embbeding_data\")\n",
    "y_ts = np.load(root/'timesformer/train/labels.npy').ravel().astype(int)\n",
    "y_st = np.load(root/'stgcnpp/train/labels.npy').ravel().astype(int)\n",
    "\n",
    "mismatch_idx = np.where(y_ts != y_st)[0]\n",
    "print(f\"⚠️  서로 다른 위치: {mismatch_idx[:10]} ... 총 {len(mismatch_idx)}개\")\n",
    "pd.DataFrame({'idx': mismatch_idx,\n",
    "              'ts_label': y_ts[mismatch_idx],\n",
    "              'st_label': y_st[mismatch_idx]})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classifier_fusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
