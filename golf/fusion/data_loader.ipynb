{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1fc0aae",
   "metadata": {},
   "source": [
    "### train, test 섞은 후, train, valid, test 분할코드  \n",
    "test 데이터에 대한 일반화 성능 검증은 힘듦, 대신 성능은 잘나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76d2828",
   "metadata": {},
   "source": [
    "model은  \n",
    "'D:\\\\mmaction2\\\\checkpoints\\\\stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d_20221228-86e1e77a.pth'  \n",
    "\"D:\\mmaction2\\work_dirs\\my_stgcnpp\\best_acc_top1_epoch_5.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cb6d03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RUN] conda run -n timesformer python -u D:\\Jabez\\golf\\fusion\\assemble_timesformer_embeddings.py --per-video-dir D:\\Jabez\\golf\\fusion\\embedding_data\\timesformer\\per_video --id-list D:\\Jabez\\golf\\fusion\\ids_txt\\train_ids.txt --out-dir D:\\Jabez\\golf\\fusion\\embedding_data\\timesformer\\train\n",
      "Saved: (1026, 768), (1026,), (1026,)\n",
      "\n",
      "\n",
      "[RUN] conda run -n timesformer python -u D:\\Jabez\\golf\\fusion\\assemble_timesformer_embeddings.py --per-video-dir D:\\Jabez\\golf\\fusion\\embedding_data\\timesformer\\per_video --id-list D:\\Jabez\\golf\\fusion\\ids_txt\\valid_ids.txt --out-dir D:\\Jabez\\golf\\fusion\\embedding_data\\timesformer\\valid\n",
      "Saved: (127, 768), (127,), (127,)\n",
      "\n",
      "\n",
      "[RUN] conda run -n timesformer python -u D:\\Jabez\\golf\\fusion\\assemble_timesformer_embeddings.py --per-video-dir D:\\Jabez\\golf\\fusion\\embedding_data\\timesformer\\per_video --id-list D:\\Jabez\\golf\\fusion\\ids_txt\\test_ids.txt --out-dir D:\\Jabez\\golf\\fusion\\embedding_data\\timesformer\\test\n",
      "Saved: (130, 768), (130,), (130,)\n",
      "\n",
      "\n",
      "[RUN] conda run -n mmaction python -u D:\\Jabez\\golf\\fusion\\extract_embedding_stgcn.py --cfg D:\\mmaction2\\configs\\skeleton\\stgcnpp\\my_stgcnpp.py --ckpt D:\\mmaction2\\checkpoints\\stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d_20221228-86e1e77a.pth --device cuda:0 --out-dir D:\\Jabez\\golf\\fusion\\embedding_data\\stgcnpp --train-pkl D:\\golfDataset\\dataset\\crop_pkl\\skeleton_dataset_train.pkl --valid-pkl D:\\golfDataset\\dataset\\crop_pkl\\skeleton_dataset_valid.pkl --test-pkl D:\\golfDataset\\dataset\\crop_pkl\\skeleton_dataset_test.pkl --num-workers 0\n",
      "07/28 15:32:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: win32\n",
      "    Python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 348161647\n",
      "    GPU 0: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "    CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.6\n",
      "    NVCC: Cuda compilation tools, release 12.6, V12.6.20\n",
      "    MSVC: Microsoft (R) C/C++ 최적화 컴파일러 버전 19.41.34120(x64)\n",
      "    GCC: n/a\n",
      "    PyTorch: 2.1.2+cu121\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 199711\n",
      "  - MSVC 192930151\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.8.1  (built against CUDA 12.0)\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.8.1, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /utf-8 /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.2+cu121\n",
      "    OpenCV: 4.12.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 348161647\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "07/28 15:32:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "ann_file = 'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl'\n",
      "auto_scale_lr = dict(base_batch_size=128, enable=False)\n",
      "custom_hooks = [\n",
      "    dict(\n",
      "        min_delta=0.001,\n",
      "        monitor='val/top1_acc',\n",
      "        patience=5,\n",
      "        type='EarlyStoppingHook'),\n",
      "]\n",
      "dataset_type = 'PoseDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='VisualizationHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "fp16 = dict(loss_scale='dynamic', type='Fp16OptimizerHook')\n",
      "launcher = 'none'\n",
      "load_from = 'checkpoints\\\\stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d_20221228-86e1e77a.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        gcn_adaptive='init',\n",
      "        gcn_with_res=True,\n",
      "        graph_cfg=dict(layout='coco', mode='spatial'),\n",
      "        tcn_type='mstcn',\n",
      "        type='STGCN'),\n",
      "    cls_head=dict(dropout=0.7, in_channels=256, num_classes=2, type='GCNHead'),\n",
      "    type='RecognizerGCN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(\n",
      "        lr=0.005, momentum=0.9, nesterov=True, type='SGD',\n",
      "        weight_decay=0.0001))\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=10,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            3,\n",
      "            6,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'D:\\\\golfDataset\\\\dataset\\\\crop_pkl\\\\skeleton_dataset_test.pkl',\n",
      "        pipeline=[\n",
      "            dict(type='PreNormalize2D'),\n",
      "            dict(dataset='coco', feats=[\n",
      "                'j',\n",
      "            ], type='GenSkeFeat'),\n",
      "            dict(\n",
      "                clip_len=100,\n",
      "                num_clips=10,\n",
      "                test_mode=True,\n",
      "                type='UniformSampleFrames'),\n",
      "            dict(type='PoseDecode'),\n",
      "            dict(num_person=2, type='FormatGCNInput'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        split='xsub_val',\n",
      "        test_mode=True,\n",
      "        type='PoseDataset'),\n",
      "    num_workers=0,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = [\n",
      "    dict(type='AccMetric'),\n",
      "    dict(out_file_path='result/result.pkl', type='DumpResults'),\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='PreNormalize2D'),\n",
      "    dict(dataset='coco', feats=[\n",
      "        'j',\n",
      "    ], type='GenSkeFeat'),\n",
      "    dict(\n",
      "        clip_len=100, num_clips=10, test_mode=True,\n",
      "        type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(num_person=2, type='FormatGCNInput'),\n",
      "    dict(type='PackActionInputs'),\n",
      "    dict(type='AddFrameDirToMeta'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=8, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        dataset=dict(\n",
      "            ann_file=\n",
      "            'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl',\n",
      "            pipeline=[\n",
      "                dict(type='PreNormalize2D'),\n",
      "                dict(dataset='coco', feats=[\n",
      "                    'j',\n",
      "                ], type='GenSkeFeat'),\n",
      "                dict(clip_len=100, type='UniformSampleFrames'),\n",
      "                dict(type='PoseDecode'),\n",
      "                dict(num_person=2, type='FormatGCNInput'),\n",
      "                dict(type='PackActionInputs'),\n",
      "            ],\n",
      "            split='xsub_train',\n",
      "            type='PoseDataset'),\n",
      "        times=1,\n",
      "        type='RepeatDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='PreNormalize2D'),\n",
      "    dict(dataset='coco', feats=[\n",
      "        'j',\n",
      "    ], type='GenSkeFeat'),\n",
      "    dict(clip_len=100, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(num_person=2, type='FormatGCNInput'),\n",
      "    dict(type='PackActionInputs'),\n",
      "    dict(type='AddFrameDirToMeta'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl',\n",
      "        pipeline=[\n",
      "            dict(type='PreNormalize2D'),\n",
      "            dict(dataset='coco', feats=[\n",
      "                'j',\n",
      "            ], type='GenSkeFeat'),\n",
      "            dict(\n",
      "                clip_len=100,\n",
      "                num_clips=1,\n",
      "                test_mode=True,\n",
      "                type='UniformSampleFrames'),\n",
      "            dict(type='PoseDecode'),\n",
      "            dict(num_person=2, type='FormatGCNInput'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        split='xsub_val',\n",
      "        test_mode=True,\n",
      "        type='PoseDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = [\n",
      "    dict(type='AccMetric'),\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(type='PreNormalize2D'),\n",
      "    dict(dataset='coco', feats=[\n",
      "        'j',\n",
      "    ], type='GenSkeFeat'),\n",
      "    dict(\n",
      "        clip_len=100, num_clips=1, test_mode=True, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(num_person=2, type='FormatGCNInput'),\n",
      "    dict(type='PackActionInputs'),\n",
      "    dict(type='AddFrameDirToMeta'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs\\\\my_stgcnpp'\n",
      "\n",
      "07/28 15:32:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "07/28 15:32:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOWEST      ) EarlyStoppingHook                  \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      "(LOWEST      ) EarlyStoppingHook                  \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "Loads checkpoint by local backend from path: D:\\mmaction2\\checkpoints\\stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d_20221228-86e1e77a.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for cls_head.fc.weight: copying a param with shape torch.Size([60, 256]) from checkpoint, the shape in current model is torch.Size([2, 256]).\n",
      "size mismatch for cls_head.fc.bias: copying a param with shape torch.Size([60]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "07/28 15:32:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 130 videos remain after valid thresholding\n",
      "07/28 15:32:34 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class DumpResults.\n",
      "✅ test done: embeddings=(130, 10, 256), labels=(130, 1), ids=(130,)\n",
      "07/28 15:32:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: win32\n",
      "    Python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1497251029\n",
      "    GPU 0: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "    CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.6\n",
      "    NVCC: Cuda compilation tools, release 12.6, V12.6.20\n",
      "    MSVC: Microsoft (R) C/C++ 최적화 컴파일러 버전 19.41.34120(x64)\n",
      "    GCC: n/a\n",
      "    PyTorch: 2.1.2+cu121\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 199711\n",
      "  - MSVC 192930151\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.8.1  (built against CUDA 12.0)\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.8.1, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /utf-8 /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.2+cu121\n",
      "    OpenCV: 4.12.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 1497251029\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "07/28 15:32:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "ann_file = 'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl'\n",
      "auto_scale_lr = dict(base_batch_size=128, enable=False)\n",
      "custom_hooks = [\n",
      "    dict(\n",
      "        min_delta=0.001,\n",
      "        monitor='val/top1_acc',\n",
      "        patience=5,\n",
      "        type='EarlyStoppingHook'),\n",
      "]\n",
      "dataset_type = 'PoseDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='VisualizationHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "fp16 = dict(loss_scale='dynamic', type='Fp16OptimizerHook')\n",
      "launcher = 'none'\n",
      "load_from = 'checkpoints\\\\stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d_20221228-86e1e77a.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        gcn_adaptive='init',\n",
      "        gcn_with_res=True,\n",
      "        graph_cfg=dict(layout='coco', mode='spatial'),\n",
      "        tcn_type='mstcn',\n",
      "        type='STGCN'),\n",
      "    cls_head=dict(dropout=0.7, in_channels=256, num_classes=2, type='GCNHead'),\n",
      "    type='RecognizerGCN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(\n",
      "        lr=0.005, momentum=0.9, nesterov=True, type='SGD',\n",
      "        weight_decay=0.0001))\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=10,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            3,\n",
      "            6,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'D:\\\\golfDataset\\\\dataset\\\\crop_pkl\\\\skeleton_dataset_train.pkl',\n",
      "        pipeline=[\n",
      "            dict(type='PreNormalize2D'),\n",
      "            dict(dataset='coco', feats=[\n",
      "                'j',\n",
      "            ], type='GenSkeFeat'),\n",
      "            dict(\n",
      "                clip_len=100,\n",
      "                num_clips=10,\n",
      "                test_mode=True,\n",
      "                type='UniformSampleFrames'),\n",
      "            dict(type='PoseDecode'),\n",
      "            dict(num_person=2, type='FormatGCNInput'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        split='xsub_val',\n",
      "        test_mode=True,\n",
      "        type='PoseDataset'),\n",
      "    num_workers=0,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = [\n",
      "    dict(type='AccMetric'),\n",
      "    dict(out_file_path='result/result.pkl', type='DumpResults'),\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='PreNormalize2D'),\n",
      "    dict(dataset='coco', feats=[\n",
      "        'j',\n",
      "    ], type='GenSkeFeat'),\n",
      "    dict(\n",
      "        clip_len=100, num_clips=10, test_mode=True,\n",
      "        type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(num_person=2, type='FormatGCNInput'),\n",
      "    dict(type='PackActionInputs'),\n",
      "    dict(type='AddFrameDirToMeta'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=8, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        dataset=dict(\n",
      "            ann_file=\n",
      "            'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl',\n",
      "            pipeline=[\n",
      "                dict(type='PreNormalize2D'),\n",
      "                dict(dataset='coco', feats=[\n",
      "                    'j',\n",
      "                ], type='GenSkeFeat'),\n",
      "                dict(clip_len=100, type='UniformSampleFrames'),\n",
      "                dict(type='PoseDecode'),\n",
      "                dict(num_person=2, type='FormatGCNInput'),\n",
      "                dict(type='PackActionInputs'),\n",
      "            ],\n",
      "            split='xsub_train',\n",
      "            type='PoseDataset'),\n",
      "        times=1,\n",
      "        type='RepeatDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='PreNormalize2D'),\n",
      "    dict(dataset='coco', feats=[\n",
      "        'j',\n",
      "    ], type='GenSkeFeat'),\n",
      "    dict(clip_len=100, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(num_person=2, type='FormatGCNInput'),\n",
      "    dict(type='PackActionInputs'),\n",
      "    dict(type='AddFrameDirToMeta'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl',\n",
      "        pipeline=[\n",
      "            dict(type='PreNormalize2D'),\n",
      "            dict(dataset='coco', feats=[\n",
      "                'j',\n",
      "            ], type='GenSkeFeat'),\n",
      "            dict(\n",
      "                clip_len=100,\n",
      "                num_clips=1,\n",
      "                test_mode=True,\n",
      "                type='UniformSampleFrames'),\n",
      "            dict(type='PoseDecode'),\n",
      "            dict(num_person=2, type='FormatGCNInput'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        split='xsub_val',\n",
      "        test_mode=True,\n",
      "        type='PoseDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = [\n",
      "    dict(type='AccMetric'),\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(type='PreNormalize2D'),\n",
      "    dict(dataset='coco', feats=[\n",
      "        'j',\n",
      "    ], type='GenSkeFeat'),\n",
      "    dict(\n",
      "        clip_len=100, num_clips=1, test_mode=True, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(num_person=2, type='FormatGCNInput'),\n",
      "    dict(type='PackActionInputs'),\n",
      "    dict(type='AddFrameDirToMeta'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs\\\\my_stgcnpp'\n",
      "\n",
      "07/28 15:32:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "07/28 15:32:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOWEST      ) EarlyStoppingHook                  \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      "(LOWEST      ) EarlyStoppingHook                  \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "Loads checkpoint by local backend from path: D:\\mmaction2\\checkpoints\\stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d_20221228-86e1e77a.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for cls_head.fc.weight: copying a param with shape torch.Size([60, 256]) from checkpoint, the shape in current model is torch.Size([2, 256]).\n",
      "size mismatch for cls_head.fc.bias: copying a param with shape torch.Size([60]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "07/28 15:32:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 1026 videos remain after valid thresholding\n",
      "07/28 15:32:41 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class DumpResults.\n",
      "✅ train done: embeddings=(1026, 10, 256), labels=(1026, 1), ids=(1026,)\n",
      "07/28 15:33:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: win32\n",
      "    Python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 742003589\n",
      "    GPU 0: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "    CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.6\n",
      "    NVCC: Cuda compilation tools, release 12.6, V12.6.20\n",
      "    MSVC: Microsoft (R) C/C++ 최적화 컴파일러 버전 19.41.34120(x64)\n",
      "    GCC: n/a\n",
      "    PyTorch: 2.1.2+cu121\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 199711\n",
      "  - MSVC 192930151\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.8.1  (built against CUDA 12.0)\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.8.1, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /utf-8 /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.2+cu121\n",
      "    OpenCV: 4.12.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 742003589\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "07/28 15:33:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "ann_file = 'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl'\n",
      "auto_scale_lr = dict(base_batch_size=128, enable=False)\n",
      "custom_hooks = [\n",
      "    dict(\n",
      "        min_delta=0.001,\n",
      "        monitor='val/top1_acc',\n",
      "        patience=5,\n",
      "        type='EarlyStoppingHook'),\n",
      "]\n",
      "dataset_type = 'PoseDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='VisualizationHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "fp16 = dict(loss_scale='dynamic', type='Fp16OptimizerHook')\n",
      "launcher = 'none'\n",
      "load_from = 'checkpoints\\\\stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d_20221228-86e1e77a.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        gcn_adaptive='init',\n",
      "        gcn_with_res=True,\n",
      "        graph_cfg=dict(layout='coco', mode='spatial'),\n",
      "        tcn_type='mstcn',\n",
      "        type='STGCN'),\n",
      "    cls_head=dict(dropout=0.7, in_channels=256, num_classes=2, type='GCNHead'),\n",
      "    type='RecognizerGCN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(\n",
      "        lr=0.005, momentum=0.9, nesterov=True, type='SGD',\n",
      "        weight_decay=0.0001))\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=10,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            3,\n",
      "            6,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'D:\\\\golfDataset\\\\dataset\\\\crop_pkl\\\\skeleton_dataset_valid.pkl',\n",
      "        pipeline=[\n",
      "            dict(type='PreNormalize2D'),\n",
      "            dict(dataset='coco', feats=[\n",
      "                'j',\n",
      "            ], type='GenSkeFeat'),\n",
      "            dict(\n",
      "                clip_len=100,\n",
      "                num_clips=10,\n",
      "                test_mode=True,\n",
      "                type='UniformSampleFrames'),\n",
      "            dict(type='PoseDecode'),\n",
      "            dict(num_person=2, type='FormatGCNInput'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        split='xsub_val',\n",
      "        test_mode=True,\n",
      "        type='PoseDataset'),\n",
      "    num_workers=0,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = [\n",
      "    dict(type='AccMetric'),\n",
      "    dict(out_file_path='result/result.pkl', type='DumpResults'),\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='PreNormalize2D'),\n",
      "    dict(dataset='coco', feats=[\n",
      "        'j',\n",
      "    ], type='GenSkeFeat'),\n",
      "    dict(\n",
      "        clip_len=100, num_clips=10, test_mode=True,\n",
      "        type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(num_person=2, type='FormatGCNInput'),\n",
      "    dict(type='PackActionInputs'),\n",
      "    dict(type='AddFrameDirToMeta'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=8, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        dataset=dict(\n",
      "            ann_file=\n",
      "            'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl',\n",
      "            pipeline=[\n",
      "                dict(type='PreNormalize2D'),\n",
      "                dict(dataset='coco', feats=[\n",
      "                    'j',\n",
      "                ], type='GenSkeFeat'),\n",
      "                dict(clip_len=100, type='UniformSampleFrames'),\n",
      "                dict(type='PoseDecode'),\n",
      "                dict(num_person=2, type='FormatGCNInput'),\n",
      "                dict(type='PackActionInputs'),\n",
      "            ],\n",
      "            split='xsub_train',\n",
      "            type='PoseDataset'),\n",
      "        times=1,\n",
      "        type='RepeatDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='PreNormalize2D'),\n",
      "    dict(dataset='coco', feats=[\n",
      "        'j',\n",
      "    ], type='GenSkeFeat'),\n",
      "    dict(clip_len=100, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(num_person=2, type='FormatGCNInput'),\n",
      "    dict(type='PackActionInputs'),\n",
      "    dict(type='AddFrameDirToMeta'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl',\n",
      "        pipeline=[\n",
      "            dict(type='PreNormalize2D'),\n",
      "            dict(dataset='coco', feats=[\n",
      "                'j',\n",
      "            ], type='GenSkeFeat'),\n",
      "            dict(\n",
      "                clip_len=100,\n",
      "                num_clips=1,\n",
      "                test_mode=True,\n",
      "                type='UniformSampleFrames'),\n",
      "            dict(type='PoseDecode'),\n",
      "            dict(num_person=2, type='FormatGCNInput'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        split='xsub_val',\n",
      "        test_mode=True,\n",
      "        type='PoseDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = [\n",
      "    dict(type='AccMetric'),\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(type='PreNormalize2D'),\n",
      "    dict(dataset='coco', feats=[\n",
      "        'j',\n",
      "    ], type='GenSkeFeat'),\n",
      "    dict(\n",
      "        clip_len=100, num_clips=1, test_mode=True, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(num_person=2, type='FormatGCNInput'),\n",
      "    dict(type='PackActionInputs'),\n",
      "    dict(type='AddFrameDirToMeta'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs\\\\my_stgcnpp'\n",
      "\n",
      "07/28 15:33:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "07/28 15:33:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOWEST      ) EarlyStoppingHook                  \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      "(LOWEST      ) EarlyStoppingHook                  \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "Loads checkpoint by local backend from path: D:\\mmaction2\\checkpoints\\stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d_20221228-86e1e77a.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for cls_head.fc.weight: copying a param with shape torch.Size([60, 256]) from checkpoint, the shape in current model is torch.Size([2, 256]).\n",
      "size mismatch for cls_head.fc.bias: copying a param with shape torch.Size([60]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "07/28 15:33:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 127 videos remain after valid thresholding\n",
      "07/28 15:33:27 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class DumpResults.\n",
      "✅ valid done: embeddings=(127, 10, 256), labels=(127, 1), ids=(127,)\n",
      "\n",
      "\n",
      "\n",
      "✅ 모든 작업 완료!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "unified_split_and_run.py\n",
    "\n",
    "1) D:\\golfDataset\\dataset\\train\\<class>\\crop_keypoint 에서 모든 CSV ID 수집\n",
    "2) 계층적 비율로 train/valid/test 분할 (TimeSformer 가능한 ID 기준)\n",
    "3) 각각 ID txt 저장 및 PKL 생성\n",
    "4) TimeSformer와 ST-GCN embedding 추출 (정렬 포함)\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "import subprocess\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# 설정\n",
    "TRUE_ROOT   = Path(r\"D:\\golfDataset\\dataset\")\n",
    "TRAIN_ROOT  = TRUE_ROOT / 'train'\n",
    "TEST_ROOT   = TRUE_ROOT / 'test'\n",
    "CUR_DIR     = Path(os.getcwd()).resolve()\n",
    "IDS_DIR     = CUR_DIR / 'ids_txt'\n",
    "TS_ENV      = 'timesformer'\n",
    "STGCN_ENV   = 'mmaction'\n",
    "MODEL       = 'D:\\\\mmaction2\\\\checkpoints\\\\stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d_20221228-86e1e77a.pth'\n",
    "SPLIT_RATIO = (0.8, 0.1, 0.1)  # train/valid/test\n",
    "SEED        = 125125214\n",
    "\n",
    "\n",
    "MAPPING_BODY25_TO_COCO17 = [\n",
    "    0,16,15,18,17,\n",
    "    5,2,6,3,7,\n",
    "    4,12,9,13,10,\n",
    "    14,11\n",
    "]\n",
    "\n",
    "def run(cmd, env):\n",
    "    full = ['conda', 'run', '-n', env] + cmd\n",
    "    print(\"[RUN]\", \" \".join(full))\n",
    "    proc = subprocess.run(full, capture_output=True, text=True)\n",
    "    if proc.stdout:\n",
    "        print(proc.stdout)\n",
    "    if proc.stderr:\n",
    "        print(proc.stderr, file=sys.stderr)\n",
    "    if proc.returncode != 0:\n",
    "        raise subprocess.CalledProcessError(proc.returncode, proc.args, output=proc.stdout, stderr=proc.stderr)\n",
    "\n",
    "def load_and_process(csv_path: Path, img_shape=(1080,1920), threshold=0.1, norm='0to1'):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    T, _ = df.shape\n",
    "    V25 = 25\n",
    "    kp25 = np.zeros((1, T, V25, 2), dtype=np.float32)\n",
    "    score25 = np.zeros((1, T, V25), dtype=np.float32)\n",
    "    for t, row in enumerate(df.values):\n",
    "        vals = row.reshape(V25, 3)\n",
    "        kp25[0, t] = vals[:, :2]\n",
    "        score25[0, t] = vals[:, 2]\n",
    "    mask = score25 < threshold\n",
    "    kp25[mask] = 0\n",
    "    score25[mask] = 0\n",
    "    h, w = img_shape\n",
    "    if norm == '0to1':\n",
    "        kp25[..., 0] /= w\n",
    "        kp25[..., 1] /= h\n",
    "    kp17 = kp25[:, :, MAPPING_BODY25_TO_COCO17, :]\n",
    "    score17 = score25[:, :, MAPPING_BODY25_TO_COCO17]\n",
    "    return {\n",
    "        'total_frames': T,\n",
    "        'img_shape': img_shape,\n",
    "        'original_shape': img_shape,\n",
    "        'keypoint': kp17,\n",
    "        'keypoint_score': score17\n",
    "    }\n",
    "\n",
    "def make_pkl(id_list, out_path: Path):\n",
    "    annotations = []\n",
    "    sorted_ids = []\n",
    "    for vid in id_list:\n",
    "        for base in [TRAIN_ROOT, TEST_ROOT]:\n",
    "            p_true  = base / 'balanced_true' / 'crop_keypoint' / f\"{vid}.csv\"\n",
    "            p_false = base / 'false' / 'crop_keypoint' / f\"{vid}.csv\"\n",
    "            if p_true.exists():\n",
    "                p = p_true\n",
    "                label = 1\n",
    "                break\n",
    "            elif p_false.exists():\n",
    "                p = p_false\n",
    "                label = 0\n",
    "                break\n",
    "        else:\n",
    "            print(f\"[⚠️] {vid}.csv not found in both folders.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            info = load_and_process(p)\n",
    "            info.update({\n",
    "                'frame_dir': vid,\n",
    "                'label': label,\n",
    "                'img_shape': info['img_shape'],\n",
    "                'original_shape': info['original_shape'],\n",
    "                'metainfo': {'frame_dir': vid, 'img_shape': info['img_shape']}\n",
    "            })\n",
    "            annotations.append(info)\n",
    "            sorted_ids.append(vid)\n",
    "        except Exception as e:\n",
    "            print(f\"[❌] Failed to load {vid}: {e}\")\n",
    "\n",
    "    data = {'annotations': annotations, 'split': {'xsub_val': sorted_ids}}\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_path, 'wb') as f:\n",
    "        pickle.dump(data, f, protocol=4)\n",
    "    np.save(out_path.with_name(out_path.stem + '_ids.npy'), np.array(sorted_ids))\n",
    "    return len(annotations)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    random.seed(SEED)\n",
    "\n",
    "    ts_ids = set()\n",
    "    per_video_dir = CUR_DIR / 'embedding_data' / 'timesformer' / 'per_video'\n",
    "    for json_file in per_video_dir.glob(\"*.json\"):\n",
    "        ts_ids.add(json_file.stem)\n",
    "\n",
    "    ids_by_label = defaultdict(list)\n",
    "\n",
    "    for ROOT in [TRAIN_ROOT, TEST_ROOT]:\n",
    "        for cat in ['balanced_true', 'false']:\n",
    "            kp_dir = ROOT / cat / 'crop_keypoint'\n",
    "            video_dirs = [ROOT / cat / 'crop_video', ROOT / cat / 'video']\n",
    "            label = 1 if cat == 'balanced_true' else 0\n",
    "            if not kp_dir.exists(): continue\n",
    "            for csv in kp_dir.glob(\"*.csv\"):\n",
    "                vid = csv.stem\n",
    "                if vid not in ts_ids:\n",
    "                    continue\n",
    "                if any((vd / f\"{vid}.mp4\").exists() for vd in video_dirs):\n",
    "                    ids_by_label[label].append(vid)\n",
    "\n",
    "    # 분할\n",
    "    train_ids, valid_ids, test_ids = [], [], []\n",
    "    for label, ids in ids_by_label.items():\n",
    "        random.shuffle(ids)\n",
    "        n = len(ids)\n",
    "        n_train = int(n * SPLIT_RATIO[0])\n",
    "        n_valid = int(n * SPLIT_RATIO[1])\n",
    "        train_ids += ids[:n_train]\n",
    "        valid_ids += ids[n_train:n_train + n_valid]\n",
    "        test_ids  += ids[n_train + n_valid:]\n",
    "\n",
    "    random.shuffle(train_ids)\n",
    "    random.shuffle(valid_ids)\n",
    "    random.shuffle(test_ids)\n",
    "\n",
    "\n",
    "    IDS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    (IDS_DIR / 'train_ids.txt').write_text('\\n'.join(train_ids))\n",
    "    (IDS_DIR / 'valid_ids.txt').write_text('\\n'.join(valid_ids))\n",
    "    (IDS_DIR / 'test_ids.txt').write_text('\\n'.join(test_ids))\n",
    "\n",
    "    base_pkl = TRUE_ROOT / 'crop_pkl'\n",
    "    make_pkl(train_ids, base_pkl / 'skeleton_dataset_train.pkl')\n",
    "    make_pkl(valid_ids, base_pkl / 'skeleton_dataset_valid.pkl')\n",
    "    make_pkl(test_ids,  base_pkl / 'skeleton_dataset_test.pkl')\n",
    "\n",
    "    run(['python', '-u', str(CUR_DIR/'assemble_timesformer_embeddings.py'),\n",
    "         '--per-video-dir', str(per_video_dir),\n",
    "         '--id-list', str(IDS_DIR/'train_ids.txt'),\n",
    "         '--out-dir', str(CUR_DIR/'embedding_data/timesformer/train')], TS_ENV)\n",
    "\n",
    "    run(['python', '-u', str(CUR_DIR/'assemble_timesformer_embeddings.py'),\n",
    "         '--per-video-dir', str(per_video_dir),\n",
    "         '--id-list', str(IDS_DIR/'valid_ids.txt'),\n",
    "         '--out-dir', str(CUR_DIR/'embedding_data/timesformer/valid')], TS_ENV)\n",
    "\n",
    "    run(['python', '-u', str(CUR_DIR/'assemble_timesformer_embeddings.py'),\n",
    "         '--per-video-dir', str(per_video_dir),\n",
    "         '--id-list', str(IDS_DIR/'test_ids.txt'),\n",
    "         '--out-dir', str(CUR_DIR/'embedding_data/timesformer/test')], TS_ENV)\n",
    "\n",
    "    run(['python', '-u', 'D:\\\\Jabez\\\\golf\\\\fusion\\\\extract_embedding_stgcn.py',\n",
    "         '--cfg',      'D:\\\\mmaction2\\\\configs\\\\skeleton\\\\stgcnpp\\\\my_stgcnpp.py',\n",
    "         '--ckpt',     MODEL,\n",
    "         '--device',   'cuda:0',\n",
    "         '--out-dir',  str(CUR_DIR/'embedding_data/stgcnpp'),\n",
    "         '--train-pkl', str(base_pkl / 'skeleton_dataset_train.pkl'),\n",
    "         '--valid-pkl', str(base_pkl / 'skeleton_dataset_valid.pkl'),\n",
    "         '--test-pkl',  str(base_pkl / 'skeleton_dataset_test.pkl'),\n",
    "         '--num-workers', '0'], STGCN_ENV)\n",
    "\n",
    "    print(\"\\n✅ 모든 작업 완료!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1809018d",
   "metadata": {},
   "source": [
    "# train, test 폴더 원천 분리 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f02e304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] #Train=247 #Valid=28 #Test=0\n",
      "[⚠️] NaN/Inf in keypoint: 20201116_General_002_DOS_A_F40_MM_053_crop → 보간/보강 처리\n",
      "[⚠️] NaN/Inf in keypoint: 20201116_General_003_DOS_A_F30_MM_060_crop → 보간/보강 처리\n",
      "[RUN] conda run -n timesformer python -u D:\\Jabez\\golf\\fusion\\assemble_timesformer_embeddings.py --per-video-dir D:\\Jabez\\golf\\fusion\\embedding_data\\timesformer\\per_video --id-list D:\\Jabez\\golf\\fusion\\ids_txt\\train_ids.txt --out-dir D:\\Jabez\\golf\\fusion\\embedding_data\\timesformer\\train\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 217\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✅ 모든 작업 완료!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 190\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# 이후 Timesformer/TS, ST-GCN 추출 코드에서 이 id 리스트를 사용\u001b[39;00m\n\u001b[0;32m    189\u001b[0m per_video_dir \u001b[38;5;241m=\u001b[39m CUR_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_data\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimesformer\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mper_video\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 190\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpython\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-u\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCUR_DIR\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43massemble_timesformer_embeddings.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m     \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--per-video-dir\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mper_video_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m     \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--id-list\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mIDS_DIR\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_ids.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m     \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--out-dir\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCUR_DIR\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43membedding_data/timesformer/train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTS_ENV\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m run([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-u\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(CUR_DIR\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124massemble_timesformer_embeddings.py\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m    195\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--per-video-dir\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(per_video_dir),\n\u001b[0;32m    196\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--id-list\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(IDS_DIR\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_ids.txt\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m    197\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--out-dir\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(CUR_DIR\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_data/timesformer/valid\u001b[39m\u001b[38;5;124m'\u001b[39m)], TS_ENV)\n\u001b[0;32m    198\u001b[0m run([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-u\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(CUR_DIR\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124massemble_timesformer_embeddings.py\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m    199\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--per-video-dir\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(per_video_dir),\n\u001b[0;32m    200\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--id-list\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(IDS_DIR\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_ids.txt\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m    201\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--out-dir\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(CUR_DIR\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_data/timesformer/test\u001b[39m\u001b[38;5;124m'\u001b[39m)], TS_ENV)\n",
      "Cell \u001b[1;32mIn[4], line 35\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(cmd, env)\u001b[0m\n\u001b[0;32m     33\u001b[0m full \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconda\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-n\u001b[39m\u001b[38;5;124m'\u001b[39m, env] \u001b[38;5;241m+\u001b[39m cmd\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[RUN]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(full))\n\u001b[1;32m---> 35\u001b[0m proc \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstdout:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(proc\u001b[38;5;241m.\u001b[39mstdout)\n",
      "File \u001b[1;32mc:\\Users\\qqppq\\anaconda3\\envs\\classifier_fusion\\lib\\subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[1;32mc:\\Users\\qqppq\\anaconda3\\envs\\classifier_fusion\\lib\\subprocess.py:1154\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1151\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1154\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\qqppq\\anaconda3\\envs\\classifier_fusion\\lib\\subprocess.py:1544\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1540\u001b[0m \u001b[38;5;66;03m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;66;03m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;66;03m# calls communicate again.\u001b[39;00m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1544\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remaining_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1545\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m   1546\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, orig_timeout)\n",
      "File \u001b[1;32mc:\\Users\\qqppq\\anaconda3\\envs\\classifier_fusion\\lib\\threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\qqppq\\anaconda3\\envs\\classifier_fusion\\lib\\threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 📦 완전 분리 train/valid/test dataset 생성 & 추출 스크립트\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 사용자 환경 설정\n",
    "ROOT         = Path(r\"D:\\golfDataset\\dataset\")\n",
    "CUR_DIR      = Path(os.getcwd()).resolve()\n",
    "IDS_DIR      = CUR_DIR / 'ids_txt'\n",
    "TS_ENV       = 'timesformer'\n",
    "STGCN_ENV    = 'mmaction'\n",
    "MODEL        = 'D:\\\\mmaction2\\\\checkpoints\\\\stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d_20221228-86e1e77a.pth'\n",
    "SPLIT_RATIO  = (0.9, 0.1)    # train/valid (train 폴더 내에서만 분리)\n",
    "SEED         = 124124\n",
    "TRAIN_ROOT   = ROOT / \"train\"\n",
    "TEST_ROOT    = ROOT / \"test\"\n",
    "\n",
    "MAPPING_BODY25_TO_COCO17 = [\n",
    "    0,16,15,18,17,\n",
    "    5,2,6,3,7,\n",
    "    4,12,9,13,10,\n",
    "    14,11\n",
    "]\n",
    "\n",
    "def run(cmd, env):\n",
    "    full = ['conda', 'run', '-n', env] + cmd\n",
    "    print(\"[RUN]\", \" \".join(full))\n",
    "    proc = subprocess.run(full, capture_output=True, text=True)\n",
    "    if proc.stdout:\n",
    "        print(proc.stdout)\n",
    "    if proc.stderr:\n",
    "        print(proc.stderr, file=sys.stderr)\n",
    "    if proc.returncode != 0:\n",
    "        raise subprocess.CalledProcessError(proc.returncode, proc.args, output=proc.stdout, stderr=proc.stderr)\n",
    "\n",
    "def load_and_process(csv_path: Path, img_shape=(1080,1920), threshold=0.1, norm='0to1'):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    T, _ = df.shape\n",
    "    V25 = 25\n",
    "    kp25 = np.zeros((1, T, V25, 2), dtype=np.float32)\n",
    "    score25 = np.zeros((1, T, V25), dtype=np.float32)\n",
    "    for t, row in enumerate(df.values):\n",
    "        vals = row.reshape(V25, 3)\n",
    "        kp25[0, t] = vals[:, :2]\n",
    "        score25[0, t] = vals[:, 2]\n",
    "    mask = score25 < threshold\n",
    "    kp25[mask] = 0\n",
    "    score25[mask] = 0\n",
    "    h, w = img_shape\n",
    "    if norm == '0to1':\n",
    "        kp25[..., 0] /= w\n",
    "        kp25[..., 1] /= h\n",
    "    kp17 = kp25[:, :, MAPPING_BODY25_TO_COCO17, :]\n",
    "    score17 = score25[:, :, MAPPING_BODY25_TO_COCO17]\n",
    "    return {\n",
    "        'total_frames': T,\n",
    "        'img_shape': img_shape,\n",
    "        'original_shape': img_shape,\n",
    "        'keypoint': kp17,\n",
    "        'keypoint_score': score17\n",
    "    }\n",
    "\n",
    "def fix_nan_inf(kp):\n",
    "    # kp: (1, T, V, 2)\n",
    "    # 1. NaN/Inf → np.nan으로 통일\n",
    "    kp = np.where(np.isfinite(kp), kp, np.nan)\n",
    "    # 2. 각 joint별로 선형보간 (프레임축)\n",
    "    for v in range(kp.shape[2]):\n",
    "        for c in range(2):\n",
    "            arr = kp[0, :, v, c]\n",
    "            nans = np.isnan(arr)\n",
    "            if nans.any():\n",
    "                idx = np.arange(arr.shape[0])\n",
    "                arr[nans] = np.interp(idx[nans], idx[~nans], arr[~nans]) if (~nans).any() else 0\n",
    "                kp[0, :, v, c] = arr\n",
    "    # 3. 남은 NaN은 0으로\n",
    "    kp = np.nan_to_num(kp)\n",
    "    return kp\n",
    "\n",
    "# make_pkl 내부에서 사용 예시\n",
    "def make_pkl(id_list, out_path: Path, label_map, removed_ids=None):\n",
    "    annotations = []\n",
    "    sorted_ids = []\n",
    "    for vid in id_list:\n",
    "        label = label_map[vid]\n",
    "        p = label['csv']\n",
    "        try:\n",
    "            info = load_and_process(p)\n",
    "            kp = info['keypoint']\n",
    "            # NaN/Inf 보강\n",
    "            if np.isnan(kp).any() or np.isinf(kp).any():\n",
    "                print(f\"[⚠️] NaN/Inf in keypoint: {vid} → 보간/보강 처리\")\n",
    "                kp = fix_nan_inf(kp)\n",
    "                info['keypoint'] = kp\n",
    "            # keypoint가 전부 0이면 제외\n",
    "            if (kp == 0).all():\n",
    "                print(f\"[❌] All-zero keypoint: {vid} → 제외\")\n",
    "                if removed_ids is not None:\n",
    "                    removed_ids.append(vid)\n",
    "                continue\n",
    "            info.update({\n",
    "                'frame_dir': vid,\n",
    "                'label': label['lbl'],\n",
    "                'img_shape': info['img_shape'],\n",
    "                'original_shape': info['original_shape'],\n",
    "                'metainfo': {'frame_dir': vid, 'img_shape': info['img_shape']}\n",
    "            })\n",
    "            annotations.append(info)\n",
    "            sorted_ids.append(vid)\n",
    "        except Exception as e:\n",
    "            print(f\"[❌] Failed to load {vid}: {e}\")\n",
    "\n",
    "    data = {'annotations': annotations, 'split': {'xsub_val': sorted_ids}}\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_path, 'wb') as f:\n",
    "        pickle.dump(data, f, protocol=4)\n",
    "    np.save(out_path.with_name(out_path.stem + '_ids.npy'), np.array(sorted_ids))\n",
    "    return len(annotations)\n",
    "\n",
    "def collect_ids(kp_dir, label):\n",
    "    # 각 폴더 내의 csv별로 (mp4 존재하면) id: {csv, lbl}로 기록\n",
    "    ids = dict()\n",
    "    video_dir = kp_dir.parent / \"crop_video\"\n",
    "    for csv in kp_dir.glob(\"*.csv\"):\n",
    "        vid = csv.stem\n",
    "        mp4 = video_dir / f\"{vid}.mp4\"\n",
    "        if not mp4.exists(): continue\n",
    "        ids[vid] = {'csv': csv, 'lbl': label}\n",
    "    return ids\n",
    "\n",
    "def main():\n",
    "    random.seed(SEED)\n",
    "\n",
    "    # -------------------------------\n",
    "    # [1] Train/Valid Pool (train 폴더 기준)\n",
    "    # -------------------------------\n",
    "    train_ids_map = dict()\n",
    "    for cat, lbl in [('balanced_true',1), ('false',0)]:\n",
    "        kp_dir = TRAIN_ROOT / cat / 'crop_keypoint'\n",
    "        train_ids_map.update(collect_ids(kp_dir, lbl))\n",
    "    all_train_ids = list(train_ids_map.keys())\n",
    "    random.shuffle(all_train_ids)\n",
    "    n_train = int(len(all_train_ids) * SPLIT_RATIO[0])\n",
    "    train_ids = all_train_ids[:n_train]\n",
    "    valid_ids = all_train_ids[n_train:]\n",
    "\n",
    "    # -------------------------------\n",
    "    # [2] Test Pool (test 폴더 기준)\n",
    "    # -------------------------------\n",
    "    test_ids_map = dict()\n",
    "    for cat, lbl in [('balanced_true',1), ('false',0)]:\n",
    "        kp_dir = TEST_ROOT / cat / 'crop_keypoint'\n",
    "        test_ids_map.update(collect_ids(kp_dir, lbl))\n",
    "    test_ids = list(test_ids_map.keys())\n",
    "\n",
    "    print(f\"[INFO] #Train={len(train_ids)} #Valid={len(valid_ids)} #Test={len(test_ids)}\")\n",
    "\n",
    "    IDS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    (IDS_DIR / 'train_ids.txt').write_text('\\n'.join(train_ids))\n",
    "    (IDS_DIR / 'valid_ids.txt').write_text('\\n'.join(valid_ids))\n",
    "    (IDS_DIR / 'test_ids.txt').write_text('\\n'.join(test_ids))\n",
    "\n",
    "    removed_train, removed_valid, removed_test = [], [], []\n",
    "\n",
    "    base_pkl = (ROOT / 'crop_pkl')\n",
    "    base_pkl.mkdir(exist_ok=True, parents=True)\n",
    "    make_pkl(train_ids, base_pkl / 'skeleton_dataset_train.pkl', train_ids_map, removed_train)\n",
    "    make_pkl(valid_ids, base_pkl / 'skeleton_dataset_valid.pkl', train_ids_map, removed_valid)\n",
    "    make_pkl(test_ids,  base_pkl / 'skeleton_dataset_test.pkl', test_ids_map, removed_test)\n",
    "\n",
    "    # All-zero 샘플이 제거된 id 리스트로 txt 파일 갱신\n",
    "    train_ids_final = [i for i in train_ids if i not in removed_train]\n",
    "    valid_ids_final = [i for i in valid_ids if i not in removed_valid]\n",
    "    test_ids_final  = [i for i in test_ids  if i not in removed_test]\n",
    "\n",
    "    IDS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    (IDS_DIR / 'train_ids.txt').write_text('\\n'.join(train_ids_final))\n",
    "    (IDS_DIR / 'valid_ids.txt').write_text('\\n'.join(valid_ids_final))\n",
    "    (IDS_DIR / 'test_ids.txt').write_text('\\n'.join(test_ids_final))\n",
    "\n",
    "    # 이후 Timesformer/TS, ST-GCN 추출 코드에서 이 id 리스트를 사용\n",
    "    per_video_dir = CUR_DIR / 'embedding_data' / 'timesformer' / 'per_video'\n",
    "    run(['python', '-u', str(CUR_DIR/'assemble_timesformer_embeddings.py'),\n",
    "         '--per-video-dir', str(per_video_dir),\n",
    "         '--id-list', str(IDS_DIR/'train_ids.txt'),\n",
    "         '--out-dir', str(CUR_DIR/'embedding_data/timesformer/train')], TS_ENV)\n",
    "    run(['python', '-u', str(CUR_DIR/'assemble_timesformer_embeddings.py'),\n",
    "         '--per-video-dir', str(per_video_dir),\n",
    "         '--id-list', str(IDS_DIR/'valid_ids.txt'),\n",
    "         '--out-dir', str(CUR_DIR/'embedding_data/timesformer/valid')], TS_ENV)\n",
    "    run(['python', '-u', str(CUR_DIR/'assemble_timesformer_embeddings.py'),\n",
    "         '--per-video-dir', str(per_video_dir),\n",
    "         '--id-list', str(IDS_DIR/'test_ids.txt'),\n",
    "         '--out-dir', str(CUR_DIR/'embedding_data/timesformer/test')], TS_ENV)\n",
    "\n",
    "    # --- ST-GCN: train/valid/test ---\n",
    "    run(['python', '-u', 'D:\\\\Jabez\\\\golf\\\\fusion\\\\extract_embedding_stgcn.py',\n",
    "         '--cfg',      'D:\\\\Jabez\\\\golf\\\\fusion\\\\mmaction_files\\\\my_stgcnpp.py',\n",
    "         '--ckpt',     MODEL,\n",
    "         '--device',   'cuda:0',\n",
    "         '--out-dir',  str(CUR_DIR/'embedding_data/stgcnpp'),\n",
    "         '--train-pkl', str(base_pkl / 'skeleton_dataset_train.pkl'),\n",
    "         '--valid-pkl', str(base_pkl / 'skeleton_dataset_valid.pkl'),\n",
    "         '--test-pkl',  str(base_pkl / 'skeleton_dataset_test.pkl'),\n",
    "         '--num-workers', '0'], STGCN_ENV)\n",
    "\n",
    "    print(\"\\n✅ 모든 작업 완료!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classifier_fusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
