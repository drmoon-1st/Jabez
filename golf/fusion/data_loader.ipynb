{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1fc0aae",
   "metadata": {},
   "source": [
    "## Train, valid 데이터 로드 & 임베딩 추출코드 호출(in conda env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2b734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  레이블 1: 훈련 480개, 검증 120개 할당\n",
      "  레이블 0: 훈련 326개, 검증 82개 할당\n",
      "\n",
      "▶ 최종 ID 리스트 저장: 806 훈련 ID / 202 검증 ID\n",
      "  훈련 ID 파일: D:\\Jabez\\golf\\fusion\\ids_txt\\train_ids.txt\n",
      "  검증 ID 파일: D:\\Jabez\\golf\\fusion\\ids_txt\\valid_ids.txt\n",
      "▶ PKL 생성 완료: 훈련 PKL=806개, 검증 PKL=202개\n",
      "D:\\golfDataset\\dataset\\train\\crop_pkl\\skeleton_dataset_train.pkl D:\\golfDataset\\dataset\\train\\crop_pkl\\skeleton_dataset_valid.pkl\n",
      "[RUN] conda run -n mmaction python -u D:\\Jabez\\golf\\fusion\\extract_embedding_stgcn.py --cfg D:\\mmaction2\\configs\\skeleton\\stgcnpp\\my_stgcnpp.py --ckpt D:\\mmaction2\\work_dirs\\my_stgcnpp\\epoch_5.pth --device cuda:0 --out-dir D:\\Jabez\\golf\\fusion\\embbeding_data\\stgcnpp --train-pkl D:\\golfDataset\\dataset\\train\\crop_pkl\\skeleton_dataset_train.pkl --valid-pkl D:\\golfDataset\\dataset\\train\\crop_pkl\\skeleton_dataset_valid.pkl --num-workers 0\n",
      "07/27 18:12:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: win32\n",
      "    Python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 2132247908\n",
      "    GPU 0: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "    CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.6\n",
      "    NVCC: Cuda compilation tools, release 12.6, V12.6.20\n",
      "    MSVC: Microsoft (R) C/C++ 최적화 컴파일러 버전 19.41.34120(x64)\n",
      "    GCC: n/a\n",
      "    PyTorch: 2.1.2+cu121\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 199711\n",
      "  - MSVC 192930151\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.8.1  (built against CUDA 12.0)\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.8.1, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /utf-8 /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.2+cu121\n",
      "    OpenCV: 4.12.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 2132247908\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "07/27 18:12:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "ann_file = 'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl'\n",
      "auto_scale_lr = dict(base_batch_size=128, enable=False)\n",
      "custom_hooks = [\n",
      "    dict(\n",
      "        min_delta=0.001,\n",
      "        monitor='val/top1_acc',\n",
      "        patience=5,\n",
      "        type='EarlyStoppingHook'),\n",
      "]\n",
      "dataset_type = 'PoseDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='VisualizationHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "fp16 = dict(loss_scale='dynamic', type='Fp16OptimizerHook')\n",
      "launcher = 'none'\n",
      "load_from = 'checkpoints\\\\stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d_20221228-86e1e77a.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        gcn_adaptive='init',\n",
      "        gcn_with_res=True,\n",
      "        graph_cfg=dict(layout='coco', mode='spatial'),\n",
      "        tcn_type='mstcn',\n",
      "        type='STGCN'),\n",
      "    cls_head=dict(dropout=0.7, in_channels=256, num_classes=2, type='GCNHead'),\n",
      "    type='RecognizerGCN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(\n",
      "        lr=0.005, momentum=0.9, nesterov=True, type='SGD',\n",
      "        weight_decay=0.0001))\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=10,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            3,\n",
      "            6,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_train.pkl',\n",
      "        pipeline=[\n",
      "            dict(type='PreNormalize2D'),\n",
      "            dict(dataset='coco', feats=[\n",
      "                'j',\n",
      "            ], type='GenSkeFeat'),\n",
      "            dict(\n",
      "                clip_len=100,\n",
      "                num_clips=10,\n",
      "                test_mode=True,\n",
      "                type='UniformSampleFrames'),\n",
      "            dict(type='PoseDecode'),\n",
      "            dict(num_person=2, type='FormatGCNInput'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        split='xsub_val',\n",
      "        test_mode=True,\n",
      "        type='PoseDataset'),\n",
      "    num_workers=0,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = [\n",
      "    dict(type='AccMetric'),\n",
      "    dict(out_file_path='result/result.pkl', type='DumpResults'),\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='PreNormalize2D'),\n",
      "    dict(dataset='coco', feats=[\n",
      "        'j',\n",
      "    ], type='GenSkeFeat'),\n",
      "    dict(\n",
      "        clip_len=100, num_clips=10, test_mode=True,\n",
      "        type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(num_person=2, type='FormatGCNInput'),\n",
      "    dict(type='PackActionInputs'),\n",
      "    dict(type='AddFrameDirToMeta'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=8, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        dataset=dict(\n",
      "            ann_file=\n",
      "            'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl',\n",
      "            pipeline=[\n",
      "                dict(type='PreNormalize2D'),\n",
      "                dict(dataset='coco', feats=[\n",
      "                    'j',\n",
      "                ], type='GenSkeFeat'),\n",
      "                dict(clip_len=100, type='UniformSampleFrames'),\n",
      "                dict(type='PoseDecode'),\n",
      "                dict(num_person=2, type='FormatGCNInput'),\n",
      "                dict(type='PackActionInputs'),\n",
      "            ],\n",
      "            split='xsub_train',\n",
      "            type='PoseDataset'),\n",
      "        times=1,\n",
      "        type='RepeatDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='PreNormalize2D'),\n",
      "    dict(dataset='coco', feats=[\n",
      "        'j',\n",
      "    ], type='GenSkeFeat'),\n",
      "    dict(clip_len=100, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(num_person=2, type='FormatGCNInput'),\n",
      "    dict(type='PackActionInputs'),\n",
      "    dict(type='AddFrameDirToMeta'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl',\n",
      "        pipeline=[\n",
      "            dict(type='PreNormalize2D'),\n",
      "            dict(dataset='coco', feats=[\n",
      "                'j',\n",
      "            ], type='GenSkeFeat'),\n",
      "            dict(\n",
      "                clip_len=100,\n",
      "                num_clips=1,\n",
      "                test_mode=True,\n",
      "                type='UniformSampleFrames'),\n",
      "            dict(type='PoseDecode'),\n",
      "            dict(num_person=2, type='FormatGCNInput'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        split='xsub_val',\n",
      "        test_mode=True,\n",
      "        type='PoseDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = [\n",
      "    dict(type='AccMetric'),\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(type='PreNormalize2D'),\n",
      "    dict(dataset='coco', feats=[\n",
      "        'j',\n",
      "    ], type='GenSkeFeat'),\n",
      "    dict(\n",
      "        clip_len=100, num_clips=1, test_mode=True, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(num_person=2, type='FormatGCNInput'),\n",
      "    dict(type='PackActionInputs'),\n",
      "    dict(type='AddFrameDirToMeta'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs\\\\my_stgcnpp'\n",
      "\n",
      "07/27 18:12:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "07/27 18:12:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOWEST      ) EarlyStoppingHook                  \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      "(LOWEST      ) EarlyStoppingHook                  \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "Loads checkpoint by local backend from path: D:\\mmaction2\\work_dirs\\my_stgcnpp\\epoch_5.pth\n",
      "07/27 18:12:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 806 videos remain after valid thresholding\n",
      "07/27 18:12:43 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class DumpResults.\n",
      "✅ train done: embeddings=(806, 10, 256), labels=(806, 1)\n",
      "07/27 18:13:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: win32\n",
      "    Python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1497251029\n",
      "    GPU 0: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "    CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.6\n",
      "    NVCC: Cuda compilation tools, release 12.6, V12.6.20\n",
      "    MSVC: Microsoft (R) C/C++ 최적화 컴파일러 버전 19.41.34120(x64)\n",
      "    GCC: n/a\n",
      "    PyTorch: 2.1.2+cu121\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 199711\n",
      "  - MSVC 192930151\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.8.1  (built against CUDA 12.0)\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.8.1, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /utf-8 /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.2+cu121\n",
      "    OpenCV: 4.12.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 1497251029\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "07/27 18:13:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "ann_file = 'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl'\n",
      "auto_scale_lr = dict(base_batch_size=128, enable=False)\n",
      "custom_hooks = [\n",
      "    dict(\n",
      "        min_delta=0.001,\n",
      "        monitor='val/top1_acc',\n",
      "        patience=5,\n",
      "        type='EarlyStoppingHook'),\n",
      "]\n",
      "dataset_type = 'PoseDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='VisualizationHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "fp16 = dict(loss_scale='dynamic', type='Fp16OptimizerHook')\n",
      "launcher = 'none'\n",
      "load_from = 'checkpoints\\\\stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d_20221228-86e1e77a.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        gcn_adaptive='init',\n",
      "        gcn_with_res=True,\n",
      "        graph_cfg=dict(layout='coco', mode='spatial'),\n",
      "        tcn_type='mstcn',\n",
      "        type='STGCN'),\n",
      "    cls_head=dict(dropout=0.7, in_channels=256, num_classes=2, type='GCNHead'),\n",
      "    type='RecognizerGCN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(\n",
      "        lr=0.005, momentum=0.9, nesterov=True, type='SGD',\n",
      "        weight_decay=0.0001))\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=10,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            3,\n",
      "            6,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_valid.pkl',\n",
      "        pipeline=[\n",
      "            dict(type='PreNormalize2D'),\n",
      "            dict(dataset='coco', feats=[\n",
      "                'j',\n",
      "            ], type='GenSkeFeat'),\n",
      "            dict(\n",
      "                clip_len=100,\n",
      "                num_clips=10,\n",
      "                test_mode=True,\n",
      "                type='UniformSampleFrames'),\n",
      "            dict(type='PoseDecode'),\n",
      "            dict(num_person=2, type='FormatGCNInput'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        split='xsub_val',\n",
      "        test_mode=True,\n",
      "        type='PoseDataset'),\n",
      "    num_workers=0,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = [\n",
      "    dict(type='AccMetric'),\n",
      "    dict(out_file_path='result/result.pkl', type='DumpResults'),\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='PreNormalize2D'),\n",
      "    dict(dataset='coco', feats=[\n",
      "        'j',\n",
      "    ], type='GenSkeFeat'),\n",
      "    dict(\n",
      "        clip_len=100, num_clips=10, test_mode=True,\n",
      "        type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(num_person=2, type='FormatGCNInput'),\n",
      "    dict(type='PackActionInputs'),\n",
      "    dict(type='AddFrameDirToMeta'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=8, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        dataset=dict(\n",
      "            ann_file=\n",
      "            'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl',\n",
      "            pipeline=[\n",
      "                dict(type='PreNormalize2D'),\n",
      "                dict(dataset='coco', feats=[\n",
      "                    'j',\n",
      "                ], type='GenSkeFeat'),\n",
      "                dict(clip_len=100, type='UniformSampleFrames'),\n",
      "                dict(type='PoseDecode'),\n",
      "                dict(num_person=2, type='FormatGCNInput'),\n",
      "                dict(type='PackActionInputs'),\n",
      "            ],\n",
      "            split='xsub_train',\n",
      "            type='PoseDataset'),\n",
      "        times=1,\n",
      "        type='RepeatDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='PreNormalize2D'),\n",
      "    dict(dataset='coco', feats=[\n",
      "        'j',\n",
      "    ], type='GenSkeFeat'),\n",
      "    dict(clip_len=100, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(num_person=2, type='FormatGCNInput'),\n",
      "    dict(type='PackActionInputs'),\n",
      "    dict(type='AddFrameDirToMeta'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl',\n",
      "        pipeline=[\n",
      "            dict(type='PreNormalize2D'),\n",
      "            dict(dataset='coco', feats=[\n",
      "                'j',\n",
      "            ], type='GenSkeFeat'),\n",
      "            dict(\n",
      "                clip_len=100,\n",
      "                num_clips=1,\n",
      "                test_mode=True,\n",
      "                type='UniformSampleFrames'),\n",
      "            dict(type='PoseDecode'),\n",
      "            dict(num_person=2, type='FormatGCNInput'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        split='xsub_val',\n",
      "        test_mode=True,\n",
      "        type='PoseDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = [\n",
      "    dict(type='AccMetric'),\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(type='PreNormalize2D'),\n",
      "    dict(dataset='coco', feats=[\n",
      "        'j',\n",
      "    ], type='GenSkeFeat'),\n",
      "    dict(\n",
      "        clip_len=100, num_clips=1, test_mode=True, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(num_person=2, type='FormatGCNInput'),\n",
      "    dict(type='PackActionInputs'),\n",
      "    dict(type='AddFrameDirToMeta'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs\\\\my_stgcnpp'\n",
      "\n",
      "07/27 18:13:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "07/27 18:13:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOWEST      ) EarlyStoppingHook                  \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      "(LOWEST      ) EarlyStoppingHook                  \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "Loads checkpoint by local backend from path: D:\\mmaction2\\work_dirs\\my_stgcnpp\\epoch_5.pth\n",
      "07/27 18:13:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 202 videos remain after valid thresholding\n",
      "07/27 18:13:03 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class DumpResults.\n",
      "✅ valid done: embeddings=(202, 10, 256), labels=(202, 1)\n",
      "\n",
      "\n",
      "✅ 모든 작업이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "parent_split_and_run.py\n",
    "\n",
    "1) D:\\golfDataset\\dataset\\train 내 CSV 이름으로 ID 수집 → 90:10 split (계층적 샘플링 적용)\n",
    "2) train_ids.txt / valid_ids.txt 생성\n",
    "3) train/valid 각각 PKL(annotations + split) 생성\n",
    "4) extract_embedding_timesformer.py, extract_embedding_stgcn.py 호출하여 임베딩 추출\n",
    "\n",
    "반드시 mmaction 환경에서 실행해야함,\n",
    "timesformer는 txt를 통해 데이터를 받기에 numpy, pands, pkle 모듈에 상관없지만,\n",
    "mmaction은 pkl 파일을 직접 읽어야 하므로 numpy._core ↔ numpy.core 호환 패치가 필요하다.\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "import subprocess\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import defaultdict # 새로 추가\n",
    "import sys\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# 설정\n",
    "ROOT       = Path(r\"D:\\golfDataset\\dataset\\train\")\n",
    "CUR_DIR    = Path(os.getcwd()).resolve()\n",
    "# .resolve()는 현재 작업 디렉토리를 절대경로로 변환\n",
    "IDS_DIR    = CUR_DIR / 'ids_txt'    # ID 리스트 저장 디렉토리\n",
    "TEST_RATIO = 0.2 # 훈련 80%, 테스트 20%\n",
    "SEED       = 42\n",
    "\n",
    "TS_ENV     = 'timesformer'\n",
    "STGCN_ENV  = 'mmaction'\n",
    "MODEL = 'D:\\\\mmaction2\\\\checkpoints\\\\stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d_20221228-86e1e77a.pth'\n",
    "# 'D:\\mmaction2\\work_dirs\\my_stgcnpp\\epoch_5.pth'\n",
    "# 'D:\\\\mmaction2\\\\checkpoints\\\\stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d_20221228-86e1e77a.pth'\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "\n",
    "# Body25 → COCO17 인덱스 매핑\n",
    "MAPPING_BODY25_TO_COCO17 = [\n",
    "    0,16,15,18,17,\n",
    "    5,2,6,3,7,\n",
    "    4,12,9,13,10,\n",
    "    14,11\n",
    "]\n",
    "\n",
    "\n",
    "def run(cmd, env):\n",
    "    full = ['conda', 'run', '-n', env] + cmd\n",
    "    print(\"[RUN]\", \" \".join(full))\n",
    "    # subprocess 에서 stdout/stderr 를 캡처\n",
    "    proc = subprocess.run(full, capture_output=True, text=True)\n",
    "    # 먼저 항상 출력\n",
    "    if proc.stdout:\n",
    "        print(proc.stdout)\n",
    "    if proc.stderr:\n",
    "        print(proc.stderr, file=sys.stderr)\n",
    "    # 종료 코드가 0이 아니면 에러로 처리\n",
    "    if proc.returncode != 0:\n",
    "        print(f\"[ERROR] `{env}` 환경 실행 실패 (exit code {proc.returncode})\", file=sys.stderr)\n",
    "        raise subprocess.CalledProcessError(\n",
    "            proc.returncode, proc.args, output=proc.stdout, stderr=proc.stderr\n",
    "        )\n",
    "\n",
    "\n",
    "def load_and_process(csv_path: Path,\n",
    "                     img_shape=(1080,1920),\n",
    "                     confidence_threshold=0.1,\n",
    "                     normalize_method='0to1') -> dict:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    T, cols = df.shape\n",
    "    V25 = 25\n",
    "    kp25 = np.zeros((1, T, V25, 2), dtype=np.float32)\n",
    "    score25 = np.zeros((1, T, V25), dtype=np.float32)\n",
    "    for t, row in enumerate(df.values):\n",
    "        vals = row.reshape(V25, 3)\n",
    "        kp25[0, t] = vals[:, :2]\n",
    "        score25[0, t] = vals[:, 2]\n",
    "    mask = score25 < confidence_threshold\n",
    "    kp25[mask] = 0\n",
    "    score25[mask] = 0\n",
    "    h, w = img_shape\n",
    "    if normalize_method == '0to1':\n",
    "        kp25[..., 0] /= w\n",
    "        kp25[..., 1] /= h\n",
    "    kp17 = kp25[:, :, MAPPING_BODY25_TO_COCO17, :]\n",
    "    score17 = score25[:, :, MAPPING_BODY25_TO_COCO17]\n",
    "    return {\n",
    "        'total_frames': T,\n",
    "        'img_shape': img_shape,\n",
    "        'original_shape': img_shape,\n",
    "        'keypoint': kp17,\n",
    "        'keypoint_score': score17\n",
    "    }\n",
    "\n",
    "\n",
    "def make_pkl(id_list, out_path: Path):\n",
    "    annotations = []\n",
    "    for vid in id_list:\n",
    "        csv_file = None\n",
    "        label = None\n",
    "        for cat in ['balanced_true','false']:\n",
    "            p = ROOT / cat / 'crop_keypoint' / f\"{vid}.csv\"\n",
    "            if p.exists():\n",
    "                csv_file = p\n",
    "                label = 1 if cat=='balanced_true' else 0\n",
    "                break\n",
    "        if csv_file is None:\n",
    "            print(f\"[WARN] CSV not found for id={vid}\")\n",
    "            continue\n",
    "        info = load_and_process(csv_file)\n",
    "        info.update({\n",
    "            'frame_dir': vid,\n",
    "            'label': label,\n",
    "            'img_shape': info['img_shape'],\n",
    "            'original_shape': info['original_shape'],\n",
    "            'metainfo': {'frame_dir':vid, 'img_shape':info['img_shape']}\n",
    "        })\n",
    "        annotations.append(info)\n",
    "    data = {'annotations':annotations, 'split':{'xsub_val':id_list}}\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_path, 'wb') as f:\n",
    "        pickle.dump(data, f, protocol=4)\n",
    "    return len(annotations)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 1) ID 수집 (레이블별로 분리하여 수집)\n",
    "    # '0': [id_for_false_cat_1, id_for_false_cat_2, ...],\n",
    "    # '1': [id_for_true_cat_1, id_for_true_cat_2, ...] 형태로 저장\n",
    "    ids_by_label = defaultdict(list)\n",
    "    all_ids_collected = False # 최소한 하나의 레이블에서 ID가 수집되었는지 확인\n",
    "\n",
    "    for cat in ['balanced_true','false']:\n",
    "        kp_dir = ROOT / cat / 'crop_keypoint'\n",
    "        vid_dirs = [ROOT/cat/'crop_video', ROOT/cat/'video']\n",
    "        current_label = 1 if cat=='balanced_true' else 0\n",
    "\n",
    "        if not kp_dir.exists(): continue\n",
    "\n",
    "        for csv_path in kp_dir.glob('*.csv'):\n",
    "            vid_id = csv_path.stem\n",
    "            # 해당 ID에 대한 비디오 파일이 실제로 존재하는지 확인 (원본 로직 유지)\n",
    "            video_found = False\n",
    "            for vd in vid_dirs:\n",
    "                # glob은 제너레이터를 반환하므로 list()로 감싸서 확인하거나 next()를 사용\n",
    "                if next(vd.glob(f\"{vid_id}*.mp4\"), None) is not None:\n",
    "                    video_found = True\n",
    "                    break\n",
    "            if video_found:\n",
    "                ids_by_label[current_label].append(vid_id) # 레이블을 int로 저장\n",
    "                all_ids_collected = True # ID가 수집되었음을 표시\n",
    "\n",
    "    if not all_ids_collected:\n",
    "        raise RuntimeError(f\"No matching CSV↔MP4 under {ROOT}. Please check `ROOT` path and data existence.\")\n",
    "\n",
    "    train_ids = []\n",
    "    valid_ids = []\n",
    "\n",
    "    # 2) 각 레이블별로 분할하여 train_ids와 valid_ids에 추가 (계층적 샘플링)\n",
    "    random.seed(SEED) # 각 레이블별 분할에 동일한 시드 적용\n",
    "\n",
    "    for label, ids_list in ids_by_label.items():\n",
    "        if not ids_list: # 해당 레이블에 ID가 없으면 건너뛰기\n",
    "            print(f\"[WARN] No IDs found for label {label}. Skipping split for this label.\")\n",
    "            continue\n",
    "\n",
    "        # 각 레이블별 ID 리스트를 섞음\n",
    "        random.shuffle(ids_list)\n",
    "\n",
    "        # 훈련/테스트 비율에 맞춰 분할\n",
    "        split_idx = int(len(ids_list) * (1 - TEST_RATIO))\n",
    "        train_ids.extend(ids_list[:split_idx])\n",
    "        valid_ids.extend(ids_list[split_idx:])\n",
    "\n",
    "        print(f\"  레이블 {label}: 훈련 {len(ids_list[:split_idx])}개, 검증 {len(ids_list[split_idx:])}개 할당\")\n",
    "\n",
    "\n",
    "    # 최종적으로 train_ids와 valid_ids도 한 번 더 섞어주는 것이 좋습니다.\n",
    "    # (나중에 학습 시 데이터 순서가 레이블별로 몰려있지 않도록)\n",
    "    random.shuffle(train_ids)\n",
    "    random.shuffle(valid_ids)\n",
    "\n",
    "    # 3) ID 리스트 저장\n",
    "    train_list = IDS_DIR/'train_ids.txt'\n",
    "    valid_list = IDS_DIR/'valid_ids.txt'\n",
    "    \n",
    "    # IDS_DIR이 없으면 생성\n",
    "    IDS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_list.write_text('\\n'.join(train_ids))\n",
    "    valid_list.write_text('\\n'.join(valid_ids))\n",
    "    print(f\"\\n▶ 최종 ID 리스트 저장: {len(train_ids)} 훈련 ID / {len(valid_ids)} 검증 ID\")\n",
    "    print(f\"  훈련 ID 파일: {train_list}\")\n",
    "    print(f\"  검증 ID 파일: {valid_list}\")\n",
    "\n",
    "    # 4) PKL 생성\n",
    "    base_pkl = ROOT/'crop_pkl'\n",
    "    train_pkl = base_pkl/'skeleton_dataset_train.pkl'\n",
    "    valid_pkl = base_pkl/'skeleton_dataset_valid.pkl'\n",
    "    tcnt = make_pkl(train_ids, train_pkl)\n",
    "    vcnt = make_pkl(valid_ids, valid_pkl)\n",
    "    print(f\"▶ PKL 생성 완료: 훈련 PKL={tcnt}개, 검증 PKL={vcnt}개\")\n",
    "\n",
    "    # 5) 임베딩 추출 (원본 코드의 주석 처리된 부분)\n",
    "    # timesformer는 너무 오래 걸려서 주석처리함\n",
    "    print(str(train_pkl), str(valid_pkl))\n",
    "    \"\"\"\n",
    "    run([\n",
    "        'python', '-u', 'extract_embedding_timesformer.py',\n",
    "        '--root',         str(ROOT),\n",
    "        '--train-list', str(train_list),\n",
    "        '--valid-list', str(valid_list),\n",
    "        '--num-frames','32',\n",
    "        '--clips-per-vid','5',\n",
    "        '--img-size','224',\n",
    "        '--batch-size','1',\n",
    "        '--num-workers','0',\n",
    "        '--pretrained', r\"D:\\TimeSformer\\pretrained\\TimeSformer_divST_96x4_224_K600.pyth\",\n",
    "        '--output-dir',r'embbeding_data\\timesformer'\n",
    "    ], TS_ENV)\n",
    "    \"\"\"\n",
    "    \n",
    "    # print(str(train_pkl), str(valid_pkl)) # 주석처리된 TimesFormer 실행 여부와 관계없이 PKL 경로 출력\n",
    "    # ST-GCN 임베딩 (PKL 경로 인수로 전달), stgcn의 경우 내부 경로 수정때문에 절대경로로 지정해 줘야한다\n",
    "    run([\n",
    "        'python', '-u', 'D:\\\\Jabez\\\\golf\\\\fusion\\\\extract_embedding_stgcn.py',\n",
    "        '--cfg',          'D:\\\\mmaction2\\\\configs\\\\skeleton\\\\stgcnpp\\\\my_stgcnpp.py',\n",
    "        '--ckpt',         MODEL,\n",
    "        '--device',       'cuda:0',\n",
    "        '--out-dir',      'D:\\\\Jabez\\\\golf\\\\fusion\\\\embbeding_data\\\\stgcnpp',\n",
    "        '--train-pkl',    str(train_pkl),\n",
    "        '--valid-pkl',    str(valid_pkl),\n",
    "        '--num-workers','0'\n",
    "    ], STGCN_ENV)\n",
    "\n",
    "\n",
    "    print(\"✅ 모든 작업이 완료되었습니다.\")\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561bb71b",
   "metadata": {},
   "source": [
    "## Test 데이터에 대해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "009bce81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ 275 test IDs saved to D:\\Jabez\\golf\\fusion\\ids_txt\\test_ids.txt\n",
      "▶ PKL created: test=275 entries at D:\\golfDataset\\dataset\\test\\crop_pkl\\skeleton_dataset_test.pkl\n",
      "[RUN] conda run -n mmaction python -u D:\\Jabez\\golf\\fusion\\extract_embedding_stgcn.py --cfg D:\\mmaction2\\configs\\skeleton\\stgcnpp\\my_stgcnpp.py --ckpt D:\\mmaction2\\work_dirs\\my_stgcnpp\\epoch_5.pth --device cuda:0 --out-dir D:\\Jabez\\golf\\fusion\\embbeding_data\\stgcnpp --test-pkl D:\\golfDataset\\dataset\\test\\crop_pkl\\skeleton_dataset_test.pkl --num-workers 0\n",
      "07/27 18:13:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: win32\n",
      "    Python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 869542203\n",
      "    GPU 0: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "    CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.6\n",
      "    NVCC: Cuda compilation tools, release 12.6, V12.6.20\n",
      "    MSVC: Microsoft (R) C/C++ 최적화 컴파일러 버전 19.41.34120(x64)\n",
      "    GCC: n/a\n",
      "    PyTorch: 2.1.2+cu121\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 199711\n",
      "  - MSVC 192930151\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.8.1  (built against CUDA 12.0)\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.8.1, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /utf-8 /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.2+cu121\n",
      "    OpenCV: 4.12.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 869542203\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "07/27 18:13:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "ann_file = 'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl'\n",
      "auto_scale_lr = dict(base_batch_size=128, enable=False)\n",
      "custom_hooks = [\n",
      "    dict(\n",
      "        min_delta=0.001,\n",
      "        monitor='val/top1_acc',\n",
      "        patience=5,\n",
      "        type='EarlyStoppingHook'),\n",
      "]\n",
      "dataset_type = 'PoseDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='VisualizationHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "fp16 = dict(loss_scale='dynamic', type='Fp16OptimizerHook')\n",
      "launcher = 'none'\n",
      "load_from = 'checkpoints\\\\stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d_20221228-86e1e77a.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        gcn_adaptive='init',\n",
      "        gcn_with_res=True,\n",
      "        graph_cfg=dict(layout='coco', mode='spatial'),\n",
      "        tcn_type='mstcn',\n",
      "        type='STGCN'),\n",
      "    cls_head=dict(dropout=0.7, in_channels=256, num_classes=2, type='GCNHead'),\n",
      "    type='RecognizerGCN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(\n",
      "        lr=0.005, momentum=0.9, nesterov=True, type='SGD',\n",
      "        weight_decay=0.0001))\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=10,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            3,\n",
      "            6,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'D:\\\\golfDataset\\\\dataset\\\\test\\\\crop_pkl\\\\skeleton_dataset_test.pkl',\n",
      "        pipeline=[\n",
      "            dict(type='PreNormalize2D'),\n",
      "            dict(dataset='coco', feats=[\n",
      "                'j',\n",
      "            ], type='GenSkeFeat'),\n",
      "            dict(\n",
      "                clip_len=100,\n",
      "                num_clips=10,\n",
      "                test_mode=True,\n",
      "                type='UniformSampleFrames'),\n",
      "            dict(type='PoseDecode'),\n",
      "            dict(num_person=2, type='FormatGCNInput'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        split='xsub_val',\n",
      "        test_mode=True,\n",
      "        type='PoseDataset'),\n",
      "    num_workers=0,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = [\n",
      "    dict(type='AccMetric'),\n",
      "    dict(out_file_path='result/result.pkl', type='DumpResults'),\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='PreNormalize2D'),\n",
      "    dict(dataset='coco', feats=[\n",
      "        'j',\n",
      "    ], type='GenSkeFeat'),\n",
      "    dict(\n",
      "        clip_len=100, num_clips=10, test_mode=True,\n",
      "        type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(num_person=2, type='FormatGCNInput'),\n",
      "    dict(type='PackActionInputs'),\n",
      "    dict(type='AddFrameDirToMeta'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=8, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        dataset=dict(\n",
      "            ann_file=\n",
      "            'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl',\n",
      "            pipeline=[\n",
      "                dict(type='PreNormalize2D'),\n",
      "                dict(dataset='coco', feats=[\n",
      "                    'j',\n",
      "                ], type='GenSkeFeat'),\n",
      "                dict(clip_len=100, type='UniformSampleFrames'),\n",
      "                dict(type='PoseDecode'),\n",
      "                dict(num_person=2, type='FormatGCNInput'),\n",
      "                dict(type='PackActionInputs'),\n",
      "            ],\n",
      "            split='xsub_train',\n",
      "            type='PoseDataset'),\n",
      "        times=1,\n",
      "        type='RepeatDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='PreNormalize2D'),\n",
      "    dict(dataset='coco', feats=[\n",
      "        'j',\n",
      "    ], type='GenSkeFeat'),\n",
      "    dict(clip_len=100, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(num_person=2, type='FormatGCNInput'),\n",
      "    dict(type='PackActionInputs'),\n",
      "    dict(type='AddFrameDirToMeta'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl',\n",
      "        pipeline=[\n",
      "            dict(type='PreNormalize2D'),\n",
      "            dict(dataset='coco', feats=[\n",
      "                'j',\n",
      "            ], type='GenSkeFeat'),\n",
      "            dict(\n",
      "                clip_len=100,\n",
      "                num_clips=1,\n",
      "                test_mode=True,\n",
      "                type='UniformSampleFrames'),\n",
      "            dict(type='PoseDecode'),\n",
      "            dict(num_person=2, type='FormatGCNInput'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        split='xsub_val',\n",
      "        test_mode=True,\n",
      "        type='PoseDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = [\n",
      "    dict(type='AccMetric'),\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(type='PreNormalize2D'),\n",
      "    dict(dataset='coco', feats=[\n",
      "        'j',\n",
      "    ], type='GenSkeFeat'),\n",
      "    dict(\n",
      "        clip_len=100, num_clips=1, test_mode=True, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(num_person=2, type='FormatGCNInput'),\n",
      "    dict(type='PackActionInputs'),\n",
      "    dict(type='AddFrameDirToMeta'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs\\\\my_stgcnpp'\n",
      "\n",
      "07/27 18:13:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "07/27 18:13:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOWEST      ) EarlyStoppingHook                  \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      "(LOWEST      ) EarlyStoppingHook                  \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "Loads checkpoint by local backend from path: D:\\mmaction2\\work_dirs\\my_stgcnpp\\epoch_5.pth\n",
      "07/27 18:13:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 275 videos remain after valid thresholding\n",
      "07/27 18:13:17 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class DumpResults.\n",
      "✅ test done: embeddings=(275, 10, 256), labels=(275, 1)\n",
      "\n",
      "✅ All done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "parent_make_test_and_run.py\n",
    "\n",
    "1) D:\\golfDataset\\dataset\\train 내 CSV 이름으로 ID 수집 → 전부 test\n",
    "2) test_ids.txt 생성\n",
    "3) test PKL(annotations + split:xsub_val) 생성\n",
    "4) extract_embedding_timesformer.py 호출하여 TimeSformer 임베딩\n",
    "5) extract_embedding_stgcn.py 호출하여 ST-GCN 임베딩\n",
    "\"\"\"\n",
    "\n",
    "import subprocess\n",
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# 설정\n",
    "ROOT        = Path(r\"D:\\golfDataset\\dataset\\test\")\n",
    "IDS_DIR     = Path(os.getcwd()).resolve() / 'ids_txt'\n",
    "TS_ENV      = 'timesformer'\n",
    "STGCN_ENV   = 'mmaction'\n",
    "TEST_LIST   = IDS_DIR / 'test_ids.txt'\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "\n",
    "# Body25 → COCO17 인덱스 매핑\n",
    "MAPPING_BODY25_TO_COCO17 = [\n",
    "    0,16,15,18,17,\n",
    "    5,2,6,3,7,\n",
    "    4,12,9,13,10,\n",
    "    14,11\n",
    "]\n",
    "\n",
    "def run(cmd, env):\n",
    "    full = ['conda', 'run', '-n', env] + cmd\n",
    "    print(\"[RUN]\", \" \".join(full))\n",
    "    proc = subprocess.run(full, capture_output=True, text=True)\n",
    "    if proc.stdout:\n",
    "        print(proc.stdout, end='')\n",
    "    if proc.stderr:\n",
    "        print(proc.stderr, file=sys.stderr, end='')\n",
    "    if proc.returncode != 0:\n",
    "        raise subprocess.CalledProcessError(\n",
    "            proc.returncode, proc.args, output=proc.stdout, stderr=proc.stderr\n",
    "        )\n",
    "\n",
    "def load_and_process(csv_path: Path,\n",
    "                     img_shape=(1080,1920),\n",
    "                     confidence_threshold=0.1,\n",
    "                     normalize_method='0to1') -> dict:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    T, _ = df.shape\n",
    "    V25 = 25\n",
    "    kp25    = np.zeros((1, T, V25, 2), dtype=np.float32)\n",
    "    score25 = np.zeros((1, T, V25),    dtype=np.float32)\n",
    "    for t, row in enumerate(df.values):\n",
    "        vals        = row.reshape(V25, 3)\n",
    "        kp25[0, t]  = vals[:, :2]\n",
    "        score25[0, t] = vals[:, 2]\n",
    "    mask = score25 < confidence_threshold\n",
    "    kp25[mask]    = 0\n",
    "    score25[mask] = 0\n",
    "    h, w = img_shape\n",
    "    if normalize_method == '0to1':\n",
    "        kp25[..., 0] /= w\n",
    "        kp25[..., 1] /= h\n",
    "    kp17    = kp25[:, :, MAPPING_BODY25_TO_COCO17, :]\n",
    "    score17 = score25[:, :, MAPPING_BODY25_TO_COCO17]\n",
    "    return {\n",
    "        'total_frames':   T,\n",
    "        'img_shape':      img_shape,\n",
    "        'original_shape': img_shape,\n",
    "        'keypoint':       kp17,\n",
    "        'keypoint_score': score17\n",
    "    }\n",
    "\n",
    "def make_pkl(id_list, out_path: Path):\n",
    "    annotations = []\n",
    "    for vid in id_list:\n",
    "        csv_file = None\n",
    "        label    = None\n",
    "        for cat in ['balanced_true', 'false']:\n",
    "            p = ROOT / cat / 'crop_keypoint' / f\"{vid}.csv\"\n",
    "            if p.exists():\n",
    "                csv_file = p\n",
    "                label    = 1 if cat == 'balanced_true' else 0\n",
    "                break\n",
    "        if csv_file is None:\n",
    "            print(f\"[WARN] CSV not found for id={vid}\")\n",
    "            continue\n",
    "\n",
    "        info = load_and_process(csv_file)\n",
    "        info.update({\n",
    "            'frame_dir':      vid,\n",
    "            'label':          label,\n",
    "            'img_shape':      info['img_shape'],\n",
    "            'original_shape': info['original_shape'],\n",
    "            'metainfo':       {'frame_dir': vid, 'img_shape': info['img_shape']}\n",
    "        })\n",
    "        annotations.append(info)\n",
    "\n",
    "    data = {\n",
    "        'annotations': annotations,\n",
    "        'split':       {'xsub_val': id_list}\n",
    "    }\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_path, 'wb') as f:\n",
    "        pickle.dump(data, f, protocol=4)\n",
    "    return len(annotations)\n",
    "\n",
    "def main():\n",
    "    # 1) ID 수집 (전체를 test)\n",
    "    ids = []\n",
    "    for cat in ['balanced_true', 'false']:\n",
    "        kp_dir   = ROOT / cat / 'crop_keypoint'\n",
    "        vid_dirs = [ROOT / cat / 'crop_video', ROOT / cat / 'video']\n",
    "        if not kp_dir.exists():\n",
    "            continue\n",
    "        for csv_path in kp_dir.glob('*.csv'):\n",
    "            vid_id = csv_path.stem\n",
    "            if any(vd.glob(f\"{vid_id}*.mp4\") for vd in vid_dirs):\n",
    "                ids.append(vid_id)\n",
    "\n",
    "    if not ids:\n",
    "        raise RuntimeError(f\"No matching CSV↔MP4 under {ROOT}\")\n",
    "\n",
    "    # 2) test ID 리스트 저장\n",
    "    IDS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    TEST_LIST.write_text('\\n'.join(ids))\n",
    "    print(f\"▶ {len(ids)} test IDs saved to {TEST_LIST}\")\n",
    "\n",
    "    # 3) test PKL 생성\n",
    "    base_pkl = ROOT / 'crop_pkl'\n",
    "    test_pkl = base_pkl / 'skeleton_dataset_test.pkl'\n",
    "    cnt = make_pkl(ids, test_pkl)\n",
    "    print(f\"▶ PKL created: test={cnt} entries at {test_pkl}\")\n",
    "    \"\"\"\n",
    "    # 4) TimeSformer 임베딩\n",
    "    run([\n",
    "        'python', '-u', 'extract_embedding_timesformer.py',\n",
    "        '--root',        str(ROOT),\n",
    "        '--test-list',   str(TEST_LIST),\n",
    "        '--num-frames',  '32',\n",
    "        '--clips-per-vid','5',\n",
    "        '--img-size',    '224',\n",
    "        '--batch-size',  '1',\n",
    "        '--num-workers', '0',\n",
    "        '--pretrained',  r\"D:\\TimeSformer\\pretrained\\TimeSformer_divST_96x4_224_K600.pyth\",\n",
    "        '--output-dir',  'embbeding_data\\\\timesformer'\n",
    "    ], TS_ENV)\n",
    "    \"\"\"\n",
    "    # 5) ST-GCN 임베딩\n",
    "    run([\n",
    "        'python', '-u', 'D:\\\\Jabez\\\\golf\\\\fusion\\\\extract_embedding_stgcn.py',\n",
    "        '--cfg',         'D:\\\\mmaction2\\\\configs\\\\skeleton\\\\stgcnpp\\\\my_stgcnpp.py',\n",
    "        '--ckpt',        MODEL,\n",
    "        '--device',      'cuda:0',\n",
    "        '--out-dir',     'D:\\\\Jabez\\\\golf\\\\fusion\\\\embbeding_data\\\\stgcnpp',\n",
    "        '--test-pkl',    str(test_pkl),\n",
    "        '--num-workers', '0'\n",
    "    ], STGCN_ENV)\n",
    "\n",
    "    print(\"✅ All done.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classifier_fusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
