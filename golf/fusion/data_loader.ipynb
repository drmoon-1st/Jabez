{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2b734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ 392 train / 44 valid IDs saved\n",
      "▶ PKL created: train=392, valid=44\n",
      "D:\\golfDataset\\dataset\\train\\crop_pkl\\skeleton_dataset_train.pkl D:\\golfDataset\\dataset\\train\\crop_pkl\\skeleton_dataset_valid.pkl\n",
      "[RUN] conda run -n mmaction --no-capture-output python -u D:\\Jabez\\golf\\fusion\\extract_embedding_stgcn.py --cfg D:\\mmaction2\\configs\\skeleton\\stgcnpp\\my_stgcnpp.py --ckpt D:\\mmaction2\\checkpoints\\stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d_20221228-86e1e77a.pth --device cuda:0 --out-dir D:\\Jabez\\golf\\fusion\\embbeding_data\\stgcnpp --train-pkl D:\\golfDataset\\dataset\\train\\crop_pkl\\skeleton_dataset_train.pkl --valid-pkl D:\\golfDataset\\dataset\\train\\crop_pkl\\skeleton_dataset_valid.pkl --num-workers 0\n",
      "✅ All done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "parent_split_and_run.py\n",
    "\n",
    "1) D:\\golfDataset\\dataset\\train 내 CSV 이름으로 ID 수집 → 90:10 split\n",
    "2) train_ids.txt / valid_ids.txt 생성\n",
    "3) train/valid 각각 PKL(annotations + split) 생성\n",
    "4) extract_embedding_timesformer.py, extract_embedding_stgcn.py 호출하여 임베딩 추출\n",
    "\n",
    "반드시 mmaction 환경에서 실행해야함,\n",
    "timesformer는 txt를 통해 데이터를 받기에 numpy, pands, pkle 모듈에 상관없지만,\n",
    "mmaction은 pkl 파일을 직접 읽어야 하므로 numpy._core ↔ numpy.core 호환 패치가 필요하다.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# ── NumPy pickle-호환 패치: numpy._core ↔ numpy.core ─────────────\n",
    "import numpy as np, sys\n",
    "sys.modules.setdefault('numpy._core', np.core)     # ← 핵심 한 줄\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "import random\n",
    "import subprocess\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# 설정\n",
    "ROOT       = Path(r\"D:\\golfDataset\\dataset\\train\")\n",
    "TEST_RATIO = 0.1\n",
    "SEED       = 42\n",
    "\n",
    "TS_ENV     = 'timesformer'\n",
    "STGCN_ENV  = 'mmaction'\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "\n",
    "# Body25 → COCO17 인덱스 매핑\n",
    "MAPPING_BODY25_TO_COCO17 = [\n",
    "    0,16,15,18,17,\n",
    "    5,2,6,3,7,\n",
    "    4,12,9,13,10,\n",
    "    14,11\n",
    "]\n",
    "\n",
    "\n",
    "def run(cmd, env):\n",
    "    full = ['conda', 'run', '-n', env, '--no-capture-output'] + cmd\n",
    "    print('[RUN]', *full)\n",
    "    subprocess.run(full, check=True)\n",
    "\n",
    "\n",
    "def load_and_process(csv_path: Path,\n",
    "                     img_shape=(1080,1920),\n",
    "                     confidence_threshold=0.1,\n",
    "                     normalize_method='0to1') -> dict:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    T, cols = df.shape\n",
    "    V25 = 25\n",
    "    kp25 = np.zeros((1, T, V25, 2), dtype=np.float32)\n",
    "    score25 = np.zeros((1, T, V25), dtype=np.float32)\n",
    "    for t, row in enumerate(df.values):\n",
    "        vals = row.reshape(V25, 3)\n",
    "        kp25[0, t] = vals[:, :2]\n",
    "        score25[0, t] = vals[:, 2]\n",
    "    mask = score25 < confidence_threshold\n",
    "    kp25[mask] = 0\n",
    "    score25[mask] = 0\n",
    "    h, w = img_shape\n",
    "    if normalize_method == '0to1':\n",
    "        kp25[..., 0] /= w\n",
    "        kp25[..., 1] /= h\n",
    "    kp17 = kp25[:, :, MAPPING_BODY25_TO_COCO17, :]\n",
    "    score17 = score25[:, :, MAPPING_BODY25_TO_COCO17]\n",
    "    return {\n",
    "        'total_frames': T,\n",
    "        'img_shape': img_shape,\n",
    "        'original_shape': img_shape,\n",
    "        'keypoint': kp17,\n",
    "        'keypoint_score': score17\n",
    "    }\n",
    "\n",
    "\n",
    "def make_pkl(id_list, out_path: Path):\n",
    "    annotations = []\n",
    "    for vid in id_list:\n",
    "        csv_file = None\n",
    "        label = None\n",
    "        for cat in ['balanced_true','false']:\n",
    "            p = ROOT / cat / 'crop_keypoint' / f\"{vid}.csv\"\n",
    "            if p.exists():\n",
    "                csv_file = p\n",
    "                label = 1 if cat=='balanced_true' else 0\n",
    "                break\n",
    "        if csv_file is None:\n",
    "            print(f\"[WARN] CSV not found for id={vid}\")\n",
    "            continue\n",
    "        info = load_and_process(csv_file)\n",
    "        info.update({\n",
    "            'frame_dir': vid,\n",
    "            'label': label,\n",
    "            'img_shape': info['img_shape'],\n",
    "            'original_shape': info['original_shape'],\n",
    "            'metainfo': {'frame_dir':vid, 'img_shape':info['img_shape']}\n",
    "        })\n",
    "        annotations.append(info)\n",
    "    data = {'annotations':annotations, 'split':{'xsub_val':id_list}}\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_path, 'wb') as f:\n",
    "        pickle.dump(data, f, protocol=4)\n",
    "    return len(annotations)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 1) ID 수집 및 split\n",
    "    ids = []\n",
    "    for cat in ['balanced_true','false']:\n",
    "        kp_dir = ROOT / cat / 'crop_keypoint'\n",
    "        vid_dirs = [ROOT/cat/'crop_video', ROOT/cat/'video']\n",
    "        if not kp_dir.exists(): continue\n",
    "        for csv_path in kp_dir.glob('*.csv'):\n",
    "            vid_id = csv_path.stem\n",
    "            if any(vd.glob(f\"{vid_id}*_crop.mp4\") for vd in vid_dirs):\n",
    "                ids.append(vid_id)\n",
    "    if not ids:\n",
    "        raise RuntimeError(f\"No matching CSV↔MP4 under {ROOT}\")\n",
    "    random.seed(SEED)\n",
    "    random.shuffle(ids)\n",
    "    idx = int(len(ids)*(1-TEST_RATIO))\n",
    "    train_ids, valid_ids = ids[:idx], ids[idx:]\n",
    "\n",
    "    # 2) ID 리스트 저장\n",
    "    train_list = Path('train_ids.txt').resolve()\n",
    "    valid_list = Path('valid_ids.txt').resolve()\n",
    "    train_list.write_text('\\n'.join(train_ids))\n",
    "    valid_list.write_text('\\n'.join(valid_ids))\n",
    "    print(f\"▶ {len(train_ids)} train / {len(valid_ids)} valid IDs saved\")\n",
    "\n",
    "    # 3) PKL 생성\n",
    "    base_pkl = ROOT/'crop_pkl'\n",
    "    train_pkl = base_pkl/'skeleton_dataset_train.pkl'\n",
    "    valid_pkl = base_pkl/'skeleton_dataset_valid.pkl'\n",
    "    tcnt = make_pkl(train_ids, train_pkl)\n",
    "    vcnt = make_pkl(valid_ids, valid_pkl)\n",
    "    print(f\"▶ PKL created: train={tcnt}, valid={vcnt}\")\n",
    "    \"\"\"\n",
    "    # 4) TimeSformer 임베딩\n",
    "    run([\n",
    "        'python', '-u', 'extract_embedding_timesformer.py',\n",
    "        '--root',       str(ROOT),\n",
    "        '--train-list', str(train_list),\n",
    "        '--valid-list', str(valid_list),\n",
    "        '--num-frames','32',\n",
    "        '--clips-per-vid','5',\n",
    "        '--img-size','224',\n",
    "        '--batch-size','1',\n",
    "        '--num-workers','0',\n",
    "        '--pretrained', r\"D:\\TimeSformer\\pretrained\\TimeSformer_divST_96x4_224_K600.pyth\",\n",
    "        '--output-dir','embbeding_data\\timesformer'\n",
    "    ], TS_ENV)\n",
    "    \"\"\"\n",
    "    # timesformer는 너무 오래 걸려서 주석처리함\n",
    "    \n",
    "    print(str(train_pkl), str(valid_pkl))\n",
    "    # 5) ST-GCN 임베딩 (PKL 경로 인수로 전달), stgcn의 경우 내부 경로 수정때문에 절대경로로 지정해 줘야한다\n",
    "    run([\n",
    "        'python', '-u', 'D:\\\\Jabez\\\\golf\\\\fusion\\\\extract_embedding_stgcn.py',\n",
    "        '--cfg',        'D:\\\\mmaction2\\\\configs\\\\skeleton\\\\stgcnpp\\\\my_stgcnpp.py',\n",
    "        '--ckpt',       'D:\\\\mmaction2\\\\checkpoints\\\\stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d_20221228-86e1e77a.pth',\n",
    "        '--device',     'cuda:0',\n",
    "        '--out-dir',    'D:\\\\Jabez\\\\golf\\\\fusion\\\\embbeding_data\\\\stgcnpp',\n",
    "        '--train-pkl',  str(train_pkl),\n",
    "        '--valid-pkl',  str(valid_pkl),\n",
    "        '--num-workers','0'\n",
    "    ], STGCN_ENV)\n",
    "\n",
    "\n",
    "    print(\"✅ All done.\")\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmaction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
