{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83923be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/100] train_loss=0.7691, train_acc=0.4770, val_loss=0.6963, val_acc=0.5227\n",
      "[02/100] train_loss=0.7547, train_acc=0.4668, val_loss=0.6829, val_acc=0.6136\n",
      "[03/100] train_loss=0.7206, train_acc=0.5485, val_loss=0.6574, val_acc=0.6364\n",
      "[04/100] train_loss=0.6809, train_acc=0.5765, val_loss=0.6225, val_acc=0.6591\n",
      "[05/100] train_loss=0.6605, train_acc=0.5434, val_loss=0.5912, val_acc=0.6818\n",
      "[06/100] train_loss=0.6334, train_acc=0.6480, val_loss=0.5614, val_acc=0.7500\n",
      "[07/100] train_loss=0.6100, train_acc=0.5995, val_loss=0.5324, val_acc=0.7500\n",
      "[08/100] train_loss=0.6254, train_acc=0.6633, val_loss=0.5181, val_acc=0.7500\n",
      "[09/100] train_loss=0.5715, train_acc=0.6403, val_loss=0.5069, val_acc=0.7955\n",
      "[10/100] train_loss=0.5491, train_acc=0.7628, val_loss=0.5003, val_acc=0.7727\n",
      "[11/100] train_loss=0.5736, train_acc=0.6250, val_loss=0.4931, val_acc=0.8182\n",
      "[12/100] train_loss=0.5093, train_acc=0.7143, val_loss=0.4827, val_acc=0.8182\n",
      "[13/100] train_loss=0.5235, train_acc=0.6964, val_loss=0.4783, val_acc=0.8182\n",
      "[14/100] train_loss=0.5205, train_acc=0.6964, val_loss=0.4742, val_acc=0.8182\n",
      "[15/100] train_loss=0.5074, train_acc=0.7372, val_loss=0.4700, val_acc=0.8409\n",
      "[16/100] train_loss=0.5073, train_acc=0.6862, val_loss=0.4730, val_acc=0.8409\n",
      "[17/100] train_loss=0.4715, train_acc=0.7168, val_loss=0.4749, val_acc=0.8409\n",
      "[18/100] train_loss=0.5360, train_acc=0.6429, val_loss=0.4804, val_acc=0.8182\n",
      "[19/100] train_loss=0.5263, train_acc=0.6352, val_loss=0.4767, val_acc=0.8182\n",
      "[20/100] train_loss=0.5076, train_acc=0.7423, val_loss=0.4730, val_acc=0.8182\n",
      "[21/100] train_loss=0.5086, train_acc=0.7372, val_loss=0.4682, val_acc=0.8636\n",
      "[22/100] train_loss=0.5169, train_acc=0.6148, val_loss=0.4754, val_acc=0.8636\n",
      "[23/100] train_loss=0.4980, train_acc=0.7398, val_loss=0.4764, val_acc=0.8409\n",
      "[24/100] train_loss=0.4423, train_acc=0.8061, val_loss=0.4761, val_acc=0.8409\n",
      "[25/100] train_loss=0.4662, train_acc=0.7296, val_loss=0.4740, val_acc=0.8636\n",
      "[26/100] train_loss=0.5360, train_acc=0.6531, val_loss=0.4661, val_acc=0.8636\n",
      "[27/100] train_loss=0.4765, train_acc=0.8495, val_loss=0.4591, val_acc=0.8636\n",
      "[28/100] train_loss=0.4676, train_acc=0.6250, val_loss=0.4520, val_acc=0.8636\n",
      "[29/100] train_loss=0.4886, train_acc=0.6556, val_loss=0.4493, val_acc=0.8409\n",
      "[30/100] train_loss=0.4520, train_acc=0.7117, val_loss=0.4645, val_acc=0.8182\n",
      "[31/100] train_loss=0.5121, train_acc=0.7577, val_loss=0.4506, val_acc=0.8182\n",
      "⏹ Early stopping triggered!\n",
      "✅ All metrics saved in D:\\Jabez\\golf\\fusion\\fusion_ckpt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# train_and_evaluate.py\n",
    "\n",
    "from pathlib import Path\n",
    "import json, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------- 하이퍼파라미터 ----------------------\n",
    "DATA_ROOT     = Path(\"embbeding_data\")\n",
    "AGG_METHOD    = \"mean\"\n",
    "BATCH         = 64\n",
    "EPOCHS        = 100\n",
    "LR            = 1e-4\n",
    "WEIGHT_DECAY  = 1e-4\n",
    "HIDDEN_DIMS   = (1024, 256)\n",
    "DROPOUT_P     = 0.5\n",
    "DEVICE        = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "SAVE_DIR      = Path(\"fusion_ckpt\")\n",
    "EARLY_STOP    = 10     # 조기 종료 patience\n",
    "MIXUP_ALPHA   = 0.2    # Mixup 적용 강도\n",
    "WARMUP_EPOCHS = 10     # Warmup 에폭 수\n",
    "\n",
    "# ----------------- 데이터 로딩 및 정규화 -------------------\n",
    "def load_split(split: str, model: str):\n",
    "    base = DATA_ROOT / model / split\n",
    "    emb  = np.load(base / \"embeddings.npy\")\n",
    "    lbl  = np.load(base / \"labels.npy\").ravel()\n",
    "    return emb, lbl\n",
    "\n",
    "def reduce_stgcn(arr):\n",
    "    if AGG_METHOD == \"mean\":\n",
    "        return np.nanmean(arr, axis=1)\n",
    "    if AGG_METHOD == \"max\":\n",
    "        return np.nanmax(arr, axis=1)\n",
    "    if AGG_METHOD == \"flatten\":\n",
    "        return arr.reshape(arr.shape[0], -1)\n",
    "    raise ValueError(f\"AGG_METHOD={AGG_METHOD}\")\n",
    "# ------------------ Mixup 함수 ----------------------\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "# ------------------ Warmup scheduler ------------------\n",
    "def linear_warmup_scheduler(optimizer, warmup_epochs, total_epochs, base_lr):\n",
    "    def lr_lambda(current_epoch):\n",
    "        if current_epoch < warmup_epochs:\n",
    "            return float(current_epoch + 1) / float(max(1, warmup_epochs))\n",
    "        return 1.0\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "# ------------------ MLP 모델 정의 ----------------------\n",
    "class FusionMLP(nn.Module):\n",
    "    def __init__(self, in_dim, n_cls, hidden, p_drop):\n",
    "        super().__init__()\n",
    "        layers, dims = [], [in_dim, *hidden]\n",
    "        for d_in, d_out in zip(dims[:-1], dims[1:]):\n",
    "            layers += [\n",
    "                nn.Linear(d_in, d_out),\n",
    "                nn.BatchNorm1d(d_out),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p_drop)\n",
    "            ]\n",
    "        layers += [nn.Linear(dims[-1], n_cls)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# ------------------ 데이터 결합 및 정규화 ------------------\n",
    "ts_tr, y_tr = load_split(\"train\", \"timesformer\")\n",
    "st_tr, _    = load_split(\"train\", \"stgcnpp\")\n",
    "ts_va, y_va = load_split(\"valid\", \"timesformer\")\n",
    "st_va, _    = load_split(\"valid\", \"stgcnpp\")\n",
    "\n",
    "st_tr = reduce_stgcn(st_tr)\n",
    "st_va = reduce_stgcn(st_va)\n",
    "\n",
    "X_tr = np.concatenate([ts_tr, st_tr], axis=1)\n",
    "X_va = np.concatenate([ts_va, st_va], axis=1)\n",
    "\n",
    "# ▶ StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_tr = scaler.fit_transform(X_tr).astype(np.float32)\n",
    "X_va = scaler.transform(X_va).astype(np.float32)\n",
    "y_tr = y_tr.astype(np.int64)\n",
    "y_va = y_va.astype(np.int64)\n",
    "\n",
    "# ------------------ DataLoaders ------------------\n",
    "dl_tr = DataLoader(TensorDataset(torch.from_numpy(X_tr), torch.from_numpy(y_tr)),\n",
    "                   batch_size=BATCH, shuffle=True)\n",
    "dl_va = DataLoader(TensorDataset(torch.from_numpy(X_va), torch.from_numpy(y_va)),\n",
    "                   batch_size=BATCH, shuffle=False)\n",
    "\n",
    "# ------------------ 모델, 옵티마이저, 스케줄러 ------------------\n",
    "model = FusionMLP(in_dim=X_tr.shape[1], n_cls=2,\n",
    "                  hidden=HIDDEN_DIMS, p_drop=DROPOUT_P).to(DEVICE)\n",
    "opt   = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = linear_warmup_scheduler(opt, warmup_epochs=5, total_epochs=EPOCHS, base_lr=LR)\n",
    "\n",
    "# Label Smoothing\n",
    "crit = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# ------------------ EarlyStopping ------------------\n",
    "early_stop_patience = 10\n",
    "early_stop_counter = 0\n",
    "best_val_acc = 0.0\n",
    "best_state = None\n",
    "\n",
    "# ------------------ 학습 루프 ------------------\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    sum_loss, sum_correct, total = 0.0, 0, 0\n",
    "\n",
    "    for x, y in dl_tr:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        x, y_a, y_b, lam = mixup_data(x, y, alpha=1.0)\n",
    "        opt.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = mixup_criterion(crit, pred, y_a, y_b, lam)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        sum_loss += loss.item() * y.size(0)\n",
    "        sum_correct += (pred.argmax(1) == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    tr_loss = sum_loss / total\n",
    "    tr_acc  = sum_correct / total\n",
    "\n",
    "    model.eval()\n",
    "    v_loss_sum, correct, total = 0.0, 0, 0\n",
    "    all_probs, all_preds, all_trues = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dl_va:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            out = model(x)\n",
    "            loss = crit(out, y)\n",
    "            v_loss_sum += loss.item() * y.size(0)\n",
    "            total += y.size(0)\n",
    "            preds = out.argmax(1)\n",
    "            all_probs.extend(torch.softmax(out, 1)[:, 1].cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_trues.extend(y.cpu().numpy())\n",
    "\n",
    "    val_loss = v_loss_sum / total\n",
    "    val_acc = accuracy_score(all_trues, all_preds)\n",
    "\n",
    "    train_losses.append(tr_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(tr_acc)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    print(f\"[{epoch:02d}/{EPOCHS}] \"\n",
    "          f\"train_loss={tr_loss:.4f}, train_acc={tr_acc:.4f}, \"\n",
    "          f\"val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_state = model.state_dict()\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:\n",
    "            print(\"⏹ Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "# ------------------ 평가 및 저장 ------------------\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "torch.save(best_state, SAVE_DIR / \"fusion_mlp_best.pth\")\n",
    "model.load_state_dict(best_state)\n",
    "model.eval()\n",
    "\n",
    "# 최종 예측\n",
    "with torch.no_grad():\n",
    "    x_tensor = torch.from_numpy(X_va).to(DEVICE)\n",
    "    out = model(x_tensor)\n",
    "    probs = torch.softmax(out, dim=1)[:,1].cpu().numpy()\n",
    "    preds = out.argmax(1).cpu().numpy()\n",
    "    trues = y_va\n",
    "\n",
    "fpr, tpr, _ = roc_curve(trues, probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "cm = confusion_matrix(trues, preds)\n",
    "report = classification_report(trues, preds, digits=4, output_dict=True)\n",
    "\n",
    "# 저장\n",
    "with open(SAVE_DIR / \"metrics.json\", \"w\", encoding=\"utf-8\") as jf:\n",
    "    json.dump({\n",
    "        \"accuracy\": accuracy_score(trues, preds),\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "        \"classification_report\": report\n",
    "    }, jf, indent=2)\n",
    "\n",
    "# 시각화\n",
    "plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.2f}\")\n",
    "plt.plot([0,1],[0,1],'--'); plt.xlabel('FPR'); plt.ylabel('TPR')\n",
    "plt.title('ROC Curve'); plt.legend(); plt.grid(True)\n",
    "plt.savefig(SAVE_DIR / \"roc_curve.png\"); plt.close()\n",
    "\n",
    "plt.matshow(cm, cmap='Blues')\n",
    "for (i,j),v in np.ndenumerate(cm):\n",
    "    plt.text(j,i,str(v),ha='center',va='center')\n",
    "plt.xlabel('Pred'); plt.ylabel('True'); plt.title('Confusion Matrix')\n",
    "plt.savefig(SAVE_DIR / \"confusion_matrix.png\"); plt.close()\n",
    "\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Valid Loss\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\"); plt.legend(); plt.grid(True)\n",
    "plt.savefig(SAVE_DIR / \"loss_curve.png\"); plt.close()\n",
    "\n",
    "plt.plot(train_accs, label=\"Train Acc\")\n",
    "plt.plot(val_accs, label=\"Valid Acc\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Curve\"); plt.legend(); plt.grid(True)\n",
    "plt.savefig(SAVE_DIR / \"accuracy_curve.png\"); plt.close()\n",
    "\n",
    "print(f\"✅ All metrics saved in {SAVE_DIR.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c8a4ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FusionMLP:\n\tMissing key(s) in state_dict: \"net.3.weight\", \"net.3.bias\", \"net.6.weight\", \"net.6.bias\". \n\tUnexpected key(s) in state_dict: \"net.8.weight\", \"net.8.bias\", \"net.1.weight\", \"net.1.bias\", \"net.1.running_mean\", \"net.1.running_var\", \"net.1.num_batches_tracked\", \"net.4.weight\", \"net.4.bias\", \"net.5.weight\", \"net.5.bias\", \"net.5.running_mean\", \"net.5.running_var\", \"net.5.num_batches_tracked\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 67\u001b[0m\n\u001b[0;32m     65\u001b[0m model  \u001b[38;5;241m=\u001b[39m FusionMLP(in_dim, n_cls, HIDDEN_DIMS, DROPOUT_P)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     66\u001b[0m state  \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(MODEL_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfusion_mlp_best.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mDEVICE)\n\u001b[1;32m---> 67\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# ---------- 평가 --------------------------------------------------------\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\qqppq\\anaconda3\\envs\\classifier_fusion\\lib\\site-packages\\torch\\nn\\modules\\module.py:2593\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2585\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2586\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2587\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2588\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[0;32m   2589\u001b[0m             ),\n\u001b[0;32m   2590\u001b[0m         )\n\u001b[0;32m   2592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   2594\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2595\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[0;32m   2596\u001b[0m         )\n\u001b[0;32m   2597\u001b[0m     )\n\u001b[0;32m   2598\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FusionMLP:\n\tMissing key(s) in state_dict: \"net.3.weight\", \"net.3.bias\", \"net.6.weight\", \"net.6.bias\". \n\tUnexpected key(s) in state_dict: \"net.8.weight\", \"net.8.bias\", \"net.1.weight\", \"net.1.bias\", \"net.1.running_mean\", \"net.1.running_var\", \"net.1.num_batches_tracked\", \"net.4.weight\", \"net.4.bias\", \"net.5.weight\", \"net.5.bias\", \"net.5.running_mean\", \"net.5.running_var\", \"net.5.num_batches_tracked\". "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np, torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------- 환경 설정 --------------------------------------------\n",
    "DATA_ROOT   = Path(\"embbeding_data\")\n",
    "AGG_METHOD  = \"mean\"\n",
    "BATCH       = 64\n",
    "HIDDEN_DIMS = (1024, 256)\n",
    "DROPOUT_P   = 0.5\n",
    "DEVICE      = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_DIR   = Path(\"fusion_ckpt\")\n",
    "SAVE_DIR    = Path(\"fusion_ckpt/test\")\n",
    "\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----------------- 데이터 로드 --------------------------------------------\n",
    "def load_split(split: str, model: str):\n",
    "    base = DATA_ROOT / model / split\n",
    "    emb  = np.load(base / \"embeddings.npy\")\n",
    "    lbl  = np.load(base / \"labels.npy\").ravel()\n",
    "    return emb, lbl\n",
    "\n",
    "def reduce_stgcn(arr):\n",
    "    if AGG_METHOD == \"mean\":\n",
    "        return np.nanmean(arr, axis=1)\n",
    "    elif AGG_METHOD == \"max\":\n",
    "        return np.nanmax(arr, axis=1)\n",
    "    elif AGG_METHOD == \"flatten\":\n",
    "        return arr.reshape(arr.shape[0], -1)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid AGG_METHOD: {AGG_METHOD}\")\n",
    "\n",
    "# ----------------- 테스트 데이터 준비 --------------------------------------\n",
    "ts_te, y_te = load_split(\"test\", \"timesformer\")\n",
    "st_te, _    = load_split(\"test\", \"stgcnpp\")\n",
    "st_te_flat  = reduce_stgcn(st_te)\n",
    "\n",
    "X_te = np.concatenate([ts_te, st_te_flat], axis=1).astype(np.float32)\n",
    "y_te = y_te.astype(np.int64)\n",
    "\n",
    "ds_te = TensorDataset(torch.from_numpy(X_te), torch.from_numpy(y_te))\n",
    "dl_te = DataLoader(ds_te, batch_size=BATCH, shuffle=False)\n",
    "\n",
    "# ----------------- 모델 정의 -----------------------------------------------\n",
    "class FusionMLP(nn.Module):\n",
    "    def __init__(self, in_dim, n_cls, hidden_dims, p_drop):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        dims = [in_dim] + list(hidden_dims)\n",
    "\n",
    "        for d_in, d_out in zip(dims[:-1], dims[1:]):\n",
    "            layers += [\n",
    "                nn.Linear(d_in, d_out),\n",
    "                nn.BatchNorm1d(d_out),       # BatchNorm 추가\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p_drop)\n",
    "            ]\n",
    "        layers.append(nn.Linear(dims[-1], n_cls))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# ----------------- 모델 로드 및 평가 -----------------------------------------\n",
    "in_dim = X_te.shape[1]\n",
    "n_cls  = int(y_te.max()) + 1\n",
    "\n",
    "model = FusionMLP(in_dim, n_cls, HIDDEN_DIMS, DROPOUT_P).to(DEVICE)\n",
    "state = torch.load(MODEL_DIR / \"fusion_mlp_best.pth\", map_location=DEVICE)\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "# ----------------- 예측 및 메트릭 출력 ---------------------------------------\n",
    "y_true, y_pred, probs = [], [], []\n",
    "with torch.no_grad():\n",
    "    for x, y in dl_te:\n",
    "        x = x.to(DEVICE)\n",
    "        out = model(x)\n",
    "        probs.extend(torch.softmax(out, dim=1)[:,1].cpu().numpy())\n",
    "        y_true.extend(y.numpy())\n",
    "        y_pred.extend(out.argmax(1).cpu().numpy())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "print(f\"Test Accuracy: {accuracy_score(y_true, y_pred)*100:.2f}%\")\n",
    "\n",
    "# ----------------- 시각화 저장 -----------------------------------------------\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_true, probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
    "plt.plot([0,1],[0,1],'--', color='orange')\n",
    "plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('Test ROC'); plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(SAVE_DIR / \"test_roc.png\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure()\n",
    "plt.matshow(cm, cmap='Blues')\n",
    "for (i, j), val in np.ndenumerate(cm):\n",
    "    plt.text(j, i, str(val), ha='center', va='center')\n",
    "plt.title('Test Confusion Matrix')\n",
    "plt.xlabel('Predicted'); plt.ylabel('True')\n",
    "plt.colorbar()\n",
    "plt.savefig(SAVE_DIR / \"test_cm.png\")\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classifier_fusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
