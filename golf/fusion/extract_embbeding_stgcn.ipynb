{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d3fe96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/20 01:11:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: win32\n",
      "    Python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 423575249\n",
      "    GPU 0: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "    CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.6\n",
      "    NVCC: Cuda compilation tools, release 12.6, V12.6.20\n",
      "    MSVC: n/a, reason: fileno\n",
      "    PyTorch: 2.1.2+cu121\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 199711\n",
      "  - MSVC 192930151\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.8.1  (built against CUDA 12.0)\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.8.1, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /utf-8 /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.2+cu121\n",
      "    OpenCV: 4.12.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 423575249\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "07/20 01:11:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "ann_file = 'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl'\n",
      "auto_scale_lr = dict(base_batch_size=128, enable=False)\n",
      "custom_hooks = [\n",
      "    dict(\n",
      "        min_delta=0.001,\n",
      "        monitor='val/top1_acc',\n",
      "        patience=5,\n",
      "        type='EarlyStoppingHook'),\n",
      "]\n",
      "dataset_type = 'PoseDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='VisualizationHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "fp16 = dict(loss_scale='dynamic', type='Fp16OptimizerHook')\n",
      "launcher = 'none'\n",
      "load_from = 'work_dirs/my_stgcnpp/best_acc_top1_epoch_5.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        gcn_adaptive='init',\n",
      "        gcn_with_res=True,\n",
      "        graph_cfg=dict(layout='coco', mode='spatial'),\n",
      "        tcn_type='mstcn',\n",
      "        type='STGCN'),\n",
      "    cls_head=dict(dropout=0.7, in_channels=256, num_classes=2, type='GCNHead'),\n",
      "    type='RecognizerGCN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(\n",
      "        lr=0.005, momentum=0.9, nesterov=True, type='SGD',\n",
      "        weight_decay=0.0001))\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=10,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            3,\n",
      "            6,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl',\n",
      "        pipeline=[\n",
      "            dict(type='PreNormalize2D'),\n",
      "            dict(dataset='coco', feats=[\n",
      "                'j',\n",
      "            ], type='GenSkeFeat'),\n",
      "            dict(\n",
      "                clip_len=100,\n",
      "                num_clips=10,\n",
      "                test_mode=True,\n",
      "                type='UniformSampleFrames'),\n",
      "            dict(type='PoseDecode'),\n",
      "            dict(num_person=2, type='FormatGCNInput'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        split='xsub_val',\n",
      "        test_mode=True,\n",
      "        type='PoseDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = [\n",
      "    dict(type='AccMetric'),\n",
      "    dict(out_file_path='result/result.pkl', type='DumpResults'),\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='PreNormalize2D'),\n",
      "    dict(dataset='coco', feats=[\n",
      "        'j',\n",
      "    ], type='GenSkeFeat'),\n",
      "    dict(\n",
      "        clip_len=100, num_clips=10, test_mode=True,\n",
      "        type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(num_person=2, type='FormatGCNInput'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=8, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        dataset=dict(\n",
      "            ann_file=\n",
      "            'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl',\n",
      "            pipeline=[\n",
      "                dict(type='PreNormalize2D'),\n",
      "                dict(dataset='coco', feats=[\n",
      "                    'j',\n",
      "                ], type='GenSkeFeat'),\n",
      "                dict(clip_len=100, type='UniformSampleFrames'),\n",
      "                dict(type='PoseDecode'),\n",
      "                dict(num_person=2, type='FormatGCNInput'),\n",
      "                dict(type='PackActionInputs'),\n",
      "            ],\n",
      "            split='xsub_train',\n",
      "            type='PoseDataset'),\n",
      "        times=1,\n",
      "        type='RepeatDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='PreNormalize2D'),\n",
      "    dict(dataset='coco', feats=[\n",
      "        'j',\n",
      "    ], type='GenSkeFeat'),\n",
      "    dict(clip_len=100, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(num_person=2, type='FormatGCNInput'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'D:\\\\golfDataset\\\\dataset\\\\train\\\\crop_pkl\\\\skeleton_dataset_90_10.pkl',\n",
      "        pipeline=[\n",
      "            dict(type='PreNormalize2D'),\n",
      "            dict(dataset='coco', feats=[\n",
      "                'j',\n",
      "            ], type='GenSkeFeat'),\n",
      "            dict(\n",
      "                clip_len=100,\n",
      "                num_clips=1,\n",
      "                test_mode=True,\n",
      "                type='UniformSampleFrames'),\n",
      "            dict(type='PoseDecode'),\n",
      "            dict(num_person=2, type='FormatGCNInput'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        split='xsub_val',\n",
      "        test_mode=True,\n",
      "        type='PoseDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = [\n",
      "    dict(type='AccMetric'),\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(type='PreNormalize2D'),\n",
      "    dict(dataset='coco', feats=[\n",
      "        'j',\n",
      "    ], type='GenSkeFeat'),\n",
      "    dict(\n",
      "        clip_len=100, num_clips=1, test_mode=True, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(num_person=2, type='FormatGCNInput'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs\\\\my_stgcnpp'\n",
      "\n",
      "07/20 01:11:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "07/20 01:11:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOWEST      ) EarlyStoppingHook                  \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      "(LOWEST      ) EarlyStoppingHook                  \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "Loads checkpoint by local backend from path: checkpoints/stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d_20221228-86e1e77a.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for cls_head.fc.weight: copying a param with shape torch.Size([60, 256]) from checkpoint, the shape in current model is torch.Size([2, 256]).\n",
      "size mismatch for cls_head.fc.bias: copying a param with shape torch.Size([60]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "07/20 01:11:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 44 videos remain after valid thresholding\n",
      "07/20 01:11:21 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class DumpResults.\n",
      "✅ Saved embeddings: (44, 10, 2) → D:\\Jabez\\golf\\fusion\\embbeding_data\\stgcnpp\\train_embeddings.npy\n",
      "✅ Saved labels:     (44,) → D:\\Jabez\\golf\\fusion\\embbeding_data\\stgcnpp\\train_labels.npy\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os, sys\n",
    "\n",
    "# (필요시) 중복 OpenMP 런타임 허용\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "\n",
    "# 1) mmaction2 루트로 이동 & 모듈 경로 등록\n",
    "BASE_DIR = r\"D:\\mmaction2\"\n",
    "os.chdir(BASE_DIR)\n",
    "sys.path.insert(0, BASE_DIR)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner, load_checkpoint\n",
    "\n",
    "# 2) 설정\n",
    "CFG_PATH      = \"configs/skeleton/stgcnpp/my_stgcnpp.py\"\n",
    "CKPT_PATH     = \"checkpoints/stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d_20221228-86e1e77a.pth\"\n",
    "INPUT_PKL     = r\"D:\\golfDataset\\dataset\\train\\crop_pkl\\skeleton_dataset_90_10.pkl\"\n",
    "OUTPUT_EMB    = r\"D:\\Jabez\\golf\\fusion\\embbeding_data\\stgcnpp\\train_embeddings.npy\"\n",
    "OUTPUT_LABELS = r\"D:\\Jabez\\golf\\fusion\\embbeding_data\\stgcnpp\\train_labels.npy\"\n",
    "DEVICE        = \"cuda:0\"\n",
    "# ---------------------------------------------\n",
    "\n",
    "# 3) Config 로드 & ann_file 덮어쓰기\n",
    "cfg = Config.fromfile(CFG_PATH)\n",
    "if hasattr(cfg, \"test_dataloader\"):\n",
    "    cfg.test_dataloader.dataset.ann_file = INPUT_PKL\n",
    "else:\n",
    "    cfg.data.test.ann_file = INPUT_PKL\n",
    "\n",
    "# 4) Runner 생성 & 모델만 로드 (헤드 매칭 무시)\n",
    "runner = Runner.from_cfg(cfg)\n",
    "load_checkpoint(runner.model, CKPT_PATH, map_location=\"cpu\", strict=False)\n",
    "runner.model.to(DEVICE).eval()\n",
    "\n",
    "# 5) cls_head 마지막 Linear 모듈 찾기\n",
    "last_lin = None\n",
    "for m in runner.model.cls_head.modules():\n",
    "    if isinstance(m, nn.Linear):\n",
    "        last_lin = m\n",
    "if last_lin is None:\n",
    "    raise RuntimeError(\"cls_head에 nn.Linear 레이어가 없습니다.\")\n",
    "\n",
    "# 6) test loop: 비디오 당 하나의 embedding & label 수집\n",
    "final_embs = []\n",
    "final_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in runner.test_dataloader:\n",
    "        # 6-1) GT 라벨\n",
    "        data_samples = batch[\"data_samples\"]\n",
    "        gt_label = int(data_samples[0].gt_label)\n",
    "        final_labels.append(gt_label)\n",
    "\n",
    "        # 6-2) raw_inputs 추출 (리스트 또는 Tensor)\n",
    "        raw_inputs = batch[\"inputs\"]\n",
    "\n",
    "        # 클립별 임베딩을 모아줄 임시 리스트\n",
    "        clip_embs = []\n",
    "\n",
    "        # 6-3) hook: 마지막 Linear의 입력(inp[0])을 저장\n",
    "        def _hook_fn(module, inp, out):\n",
    "            # inp[0] shape == (batch_size, in_channels=256)\n",
    "            clip_embs.append(inp[0].detach().cpu().squeeze(0))\n",
    "        handle = last_lin.register_forward_hook(_hook_fn)\n",
    "\n",
    "        # 6-4) 클립별 forward\n",
    "        if isinstance(raw_inputs, list):\n",
    "            for clip in raw_inputs:\n",
    "                inp = clip.unsqueeze(0).to(DEVICE)  # (1, C, T, V, M)\n",
    "                runner.model.forward(inp, data_samples, mode=\"predict\")\n",
    "        else:\n",
    "            # dict 혹은 Tensor 형태\n",
    "            inp = raw_inputs\n",
    "            if torch.is_tensor(inp):\n",
    "                inp = inp.unsqueeze(0).to(DEVICE)\n",
    "            else:\n",
    "                # dict of tensors\n",
    "                inp = {k: v.unsqueeze(0).to(DEVICE) if torch.is_tensor(v) and v.dim()==4 \n",
    "                       else v.to(DEVICE) if torch.is_tensor(v) \n",
    "                       else v\n",
    "                       for k, v in inp.items()}\n",
    "            runner.model.forward(inp, data_samples, mode=\"predict\")\n",
    "\n",
    "        # hook 해제\n",
    "        handle.remove()\n",
    "\n",
    "        # 6-5) 클립별 임베딩 평균 → (256,)\n",
    "        video_emb = torch.stack(clip_embs, dim=0).mean(dim=0)\n",
    "        final_embs.append(video_emb.numpy())\n",
    "\n",
    "# 7) 결과 저장\n",
    "emb_array   = np.stack(final_embs, axis=0)       # (N, 256)\n",
    "label_array = np.array(final_labels, dtype=np.int64)  # (N,)\n",
    "\n",
    "np.save(OUTPUT_EMB, emb_array)\n",
    "np.save(OUTPUT_LABELS, label_array)\n",
    "\n",
    "print(f\"✅ Saved embeddings: {emb_array.shape} → {OUTPUT_EMB}\")\n",
    "print(f\"✅ Saved labels:     {label_array.shape} → {OUTPUT_LABELS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761c05b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os, sys\n",
    "\n",
    "# (필요시) 중복 OpenMP 런타임 허용\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "\n",
    "# 1) mmaction2 루트로 이동 & 모듈 경로 등록\n",
    "BASE_DIR = r\"D:\\mmaction2\"\n",
    "os.chdir(BASE_DIR)\n",
    "sys.path.insert(0, BASE_DIR)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner, load_checkpoint\n",
    "\n",
    "# 2) 설정\n",
    "CFG_PATH      = \"configs/skeleton/stgcnpp/my_stgcnpp.py\"\n",
    "CKPT_PATH     = \"checkpoints/stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d_20221228-86e1e77a.pth\"\n",
    "INPUT_PKL     = r\"D:\\golfDataset\\dataset\\train\\crop_pkl\\skeleton_dataset_90_10.pkl\"\n",
    "OUTPUT_EMB    = r\"D:\\Jabez\\golf\\fusion\\embbeding_data\\stgcnpp\\train_embeddings.npy\"\n",
    "OUTPUT_LABELS = r\"D:\\Jabez\\golf\\fusion\\embbeding_data\\stgcnpp\\train_labels.npy\"\n",
    "DEVICE        = \"cuda:0\"\n",
    "# ---------------------------------------------\n",
    "\n",
    "# 3) Config 로드 & ann_file 덮어쓰기\n",
    "cfg = Config.fromfile(CFG_PATH)\n",
    "if hasattr(cfg, \"test_dataloader\"):\n",
    "    cfg.test_dataloader.dataset.ann_file = INPUT_PKL\n",
    "else:\n",
    "    cfg.data.test.ann_file = INPUT_PKL\n",
    "\n",
    "# 4) Runner 생성 & 모델만 로드 (헤드 매칭 무시)\n",
    "runner = Runner.from_cfg(cfg)\n",
    "load_checkpoint(runner.model, CKPT_PATH, map_location=\"cpu\", strict=False)\n",
    "runner.model.to(DEVICE).eval()\n",
    "\n",
    "# 5) cls_head 마지막 Linear 모듈 찾기\n",
    "last_lin = None\n",
    "for m in runner.model.cls_head.modules():\n",
    "    if isinstance(m, nn.Linear):\n",
    "        last_lin = m\n",
    "if last_lin is None:\n",
    "    raise RuntimeError(\"cls_head에 nn.Linear 레이어가 없습니다.\")\n",
    "\n",
    "# 6) test loop: 비디오 당 하나의 embedding & label 수집\n",
    "final_embs = []\n",
    "final_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in runner.test_dataloader:\n",
    "        # 6-1) GT 라벨\n",
    "        data_samples = batch[\"data_samples\"]\n",
    "        gt_label = int(data_samples[0].gt_label)\n",
    "        final_labels.append(gt_label)\n",
    "\n",
    "        # 6-2) raw_inputs 추출 (리스트 또는 Tensor)\n",
    "        raw_inputs = batch[\"inputs\"]\n",
    "\n",
    "        # 6-3) 클립별로 hook → 임베딩 수집 → 평균\n",
    "        clip_embs = []\n",
    "        # 클립 임베딩을 모아줄 임시 리스트\n",
    "        def _hook_fn(_, __, out):\n",
    "            # out: (1, D)\n",
    "            clip_embs.append(out.detach().cpu().squeeze(0))\n",
    "        handle = last_lin.register_forward_hook(_hook_fn)\n",
    "\n",
    "        # 리스트인 경우 클립별로, 아니면 한 번만\n",
    "        if isinstance(raw_inputs, list):\n",
    "            for clip in raw_inputs:\n",
    "                inp = clip.unsqueeze(0).to(DEVICE)  # (1, C, T, V, M)\n",
    "                runner.model.forward(inp, data_samples, mode=\"predict\")\n",
    "        else:\n",
    "            inp = raw_inputs.unsqueeze(0).to(DEVICE) if raw_inputs.dim()==4 else raw_inputs.to(DEVICE)\n",
    "            runner.model.forward(inp, data_samples, mode=\"predict\")\n",
    "\n",
    "        handle.remove()\n",
    "\n",
    "        # 클립별 임베딩 평균 → (D,)\n",
    "        video_emb = torch.stack(clip_embs, dim=0).mean(dim=0)\n",
    "        final_embs.append(video_emb.numpy())\n",
    "\n",
    "# 7) 결과 저장\n",
    "emb_array = np.stack(final_embs, axis=0)  # (N, D)\n",
    "label_array = np.array(final_labels, dtype=np.int64)  # (N,)\n",
    "\n",
    "np.save(OUTPUT_EMB, emb_array)\n",
    "np.save(OUTPUT_LABELS, label_array)\n",
    "\n",
    "print(f\"✅ Saved embeddings: {emb_array.shape} → {OUTPUT_EMB}\")\n",
    "print(f\"✅ Saved labels:     {label_array.shape} → {OUTPUT_LABELS}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmaction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
